{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the CyVerse Learning Center \u00b6 CyVerse provides life scientists with powerful computational infrastructure to handle huge datasets and complex analyses, thus enabling data-driven discovery. In the Learning Center, you can find information about CyVerse platforms and documentation on how to use features and services, quick starts for data management and analysis tasks, tutorials, and more. Use the navigation bar on the left side of the screen or the search bar at the top to explore the learning materials. First Steps \u00b6 These are some good places to start learning about what CyVerse has to offer: What is CyVerse? \u00b6 Get a quick overview of CyVerse's platforms, services, and infrastructure. Creating a CyVerse account \u00b6 Create an account and get started using CyVerse. Self-Guided Tour \u00b6 Take a self-guided course on using CyVerse to manage data and run analyses. Funding and Citations: CyVerse is funded entirely by the National Science Foundation under Award Numbers: The CyVerse Zenodo Community has published, citable versions of CyVerse materials. Please cite CyVerse appropriately when you make use of our resources; see CyVerse citation policy .","title":"Index"},{"location":"#welcome-to-the-cyverse-learning-center","text":"CyVerse provides life scientists with powerful computational infrastructure to handle huge datasets and complex analyses, thus enabling data-driven discovery. In the Learning Center, you can find information about CyVerse platforms and documentation on how to use features and services, quick starts for data management and analysis tasks, tutorials, and more. Use the navigation bar on the left side of the screen or the search bar at the top to explore the learning materials.","title":"Welcome to the CyVerse Learning Center"},{"location":"#first-steps","text":"These are some good places to start learning about what CyVerse has to offer:","title":"First Steps"},{"location":"#what-is-cyverse","text":"Get a quick overview of CyVerse's platforms, services, and infrastructure.","title":"What is CyVerse?"},{"location":"#creating-a-cyverse-account","text":"Create an account and get started using CyVerse.","title":"Creating a CyVerse account"},{"location":"#self-guided-tour","text":"Take a self-guided course on using CyVerse to manage data and run analyses. Funding and Citations: CyVerse is funded entirely by the National Science Foundation under Award Numbers: The CyVerse Zenodo Community has published, citable versions of CyVerse materials. Please cite CyVerse appropriately when you make use of our resources; see CyVerse citation policy .","title":"Self-Guided Tour"},{"location":"account/","text":"Set Up a CyVerse Account \u00b6 To use CyVerse's platforms, you will need to create an account. Here's how to do so: Follow the signup link to begin the registration process. You will be asked to enter some information about yourself, your contact info, and what you want to use CyVerse for. We highly recommended that you use an institutional email address (.edu, .org, or .gov) if possible. This will speed up the approval process for access to certain CyVerse platforms. Complete the registration process. Check your email for an account confirmation link and follow the confirmation instructions. Once you have confirmed your email address, you can start using your CyVerse account immediately! Pop-up-blockers When signing up for an account, be sure that Java Script is enabled on your web browser and that any pop-up blockers are disabled. Check-your-spam Check your SPAM folder for the confirmation email if it does not arrive within a few minutes. Register for Services \u00b6 To register for VICE or other services, login to the user portal's dashboard . Under \"My Services\" click the 'Request Access' button next to the service(s) you would like to access. You will receive an email notification when the service is added; this may take up to 24 hours. Getting VICE Access \u00b6 Since VICE (Visual Interactive Compute Environment) is a target for cryptocurrency miners, CyVerse requires an additional verification. When requesting VICE access, you will be asked to describe your intended use of VICE; please give non-technical scientific details, and if you can, link an external resource (like a workshop or lab website) and funding agency. An institutional email address is required (e.g., .org, .gov, .edu.). We will reject commercial addresses (e.g., @gmail .com, @yahoo .com, @qq .com., etc.). Also, please add your ORCID https://orcid.org to your CyVerse User Profile . If you don't have an ORCID get one today!","title":"Set Up an Account"},{"location":"account/#set-up-a-cyverse-account","text":"To use CyVerse's platforms, you will need to create an account. Here's how to do so: Follow the signup link to begin the registration process. You will be asked to enter some information about yourself, your contact info, and what you want to use CyVerse for. We highly recommended that you use an institutional email address (.edu, .org, or .gov) if possible. This will speed up the approval process for access to certain CyVerse platforms. Complete the registration process. Check your email for an account confirmation link and follow the confirmation instructions. Once you have confirmed your email address, you can start using your CyVerse account immediately! Pop-up-blockers When signing up for an account, be sure that Java Script is enabled on your web browser and that any pop-up blockers are disabled. Check-your-spam Check your SPAM folder for the confirmation email if it does not arrive within a few minutes.","title":"Set Up a CyVerse Account"},{"location":"account/#register-for-services","text":"To register for VICE or other services, login to the user portal's dashboard . Under \"My Services\" click the 'Request Access' button next to the service(s) you would like to access. You will receive an email notification when the service is added; this may take up to 24 hours.","title":"Register for Services"},{"location":"account/#getting-vice-access","text":"Since VICE (Visual Interactive Compute Environment) is a target for cryptocurrency miners, CyVerse requires an additional verification. When requesting VICE access, you will be asked to describe your intended use of VICE; please give non-technical scientific details, and if you can, link an external resource (like a workshop or lab website) and funding agency. An institutional email address is required (e.g., .org, .gov, .edu.). We will reject commercial addresses (e.g., @gmail .com, @yahoo .com, @qq .com., etc.). Also, please add your ORCID https://orcid.org to your CyVerse User Profile . If you don't have an ORCID get one today!","title":"Getting VICE Access"},{"location":"dna_subway_guide/","text":"DNA Subway \u00b6 Goal \u00b6 DNA Subway is an educational bioinformatics platform developed by CyVerse. It bundles research-grade bioinformatics tools, high-performance computing, and databases into workflows with an easy-to-use interface. \"Riding\" DNA Subway lines, students can predict and annotate genes in up to 150kb of DNA (Red Line), identify homologs in sequenced genomes (Yellow Line), identify species using DNA barcodes and phylogenetic trees (Blue Line), examine RNA-Seq datasets for differential transcript abundance (Green Line), and analyze metabarcoding and eDNA samples using QIIME (Purple Line). Prerequisites \u00b6 In order to complete this tutorial you will need access to the following services/software Prerequisite Preparation/Notes Link/Download CyVerse account You will need a CyVerse account to complete this exercise Register DNA Subway Access DNA Subway access is by request access Check or request access: CyVerse User Portal DNA Subway Basics and Logging in to Subway \u00b6 DNA Subway is designed to be a classroom-friendly approach to bioinformatics. Unlike most CyVerse platforms, you can even use Subway without registering for a CyVerse account. We do encourage you to register however, only work from registered users can be saved. DNA Subway uses the same open-source bioinformatics tools used by researchers. See a complete list of the tools provided in the Subway pipelines. Some things to remember about the platform Registered user and Guest user account types DNA Subway access must be requested through the CyVerse user portal. You can check if you already have access, or request access by logging into the portal and visiting the My Services page. If DNA Subway is not listed, click on Available services to request access. Guest users will not have their worked saved beyond a single DNA Subway session. They are also disallowed from using one of the gene predictors (FGenesH) in the genomic annotation pipeline (Red Line). We suggest that every student using DNA Subway obtain their own account. Sample Datasets and reference data All Subway lines accept user data and also have sample data that can be immediately used to create a project. Red Line - Genome Annotation: Samples of plant and animal genomes that can be used in annotation projects Yellow Line - TARGeT Search for transposons and other DNA Sequences: Several model plant genomes Blue Line - DNA Barcoding and Phylogenetics: Sample sequence from plant, animal, fungal, and bacterial barcoding regions; human mitochondrial DNA sequence Green Line - RNA-Seq for differential expression: Sample high-throughput reads from RNA-Seq experiments If there is a reference data set or sample sequence you would like added, you can contact CyVerse using the DNA Subway Contact page Public and private projects - DNA Subway projects are private by default, but can be shared by making them public. Public projects are searchable and are a great way to share data or present analysis for grading in a classroom project. Logging into DNA Subway as a registered user \u00b6 Access the DNA Subway website at https://dnasubway.cyverse.org/ If you wish to use DNA Subway as a guest click 'Enter As Guest' Note When using DNA Subway as a guest, you will be able to work only on the Red, Yellow, and Blue lines. Additionally, some Red Line functionalities will be disabled. Finally, after logging out, or a period of inactivity (>~ 30 min) you work will be discarded. Enter your CyVerse username and CyVerse password. Logging into DNA Subway as a guest user \u00b6 Access the DNA Subway website at https://dnasubway.cyverse.org/ ; click 'Enter as Guest' Accessing Saved Private and Public DNA Subway Projects \u00b6 DNA Subway projects are automatically saved for registered users. By default, Subway projects are private upon creation and visible only to you. You may make project public, in which case users will have the ability to view those projects, but may not edit those projects. Accessing Private Projects \u00b6 Access the DNA Subway website at https://dnasubway.cyverse.org/ Upon login, you will see a listing of your private projects. Access the project by clicking the project title. From any DNA Subway page, you may access private projects by clicking the 'My Projects' button on the navigation menu on the left side of the page. Distinguishing Lines All projects in DNA Subway are associated with the color of their respective DNA Subway lines, and with a project ID number. You may see the comments and species associated with the project Deleting a project To delete a project, click the 'trash can' icon. Once deleted, all data related to that project will be lost and unrecoverable. Accessing Public Projects \u00b6 Access the DNA Subway website at https://dnasubway.cyverse.org/ ; login to Subway or enter as a guest user. On the navigation menu on the left side of the screen, click 'Public Projects' Sorting and Search You can sort by project date or type, and you can search for a project by title, organism, or the name of the project owner. When searching, click the double arrow `` to search by your selected term. Make a DNA Subway Project Private or Public \u00b6 Access the DNA Subway website at https://dnasubway.cyverse.org/ ; login to Subway. Access your selected project by clicking the project title. Under the 'Project Information' tab, toggle the project setting to 'Public' or 'Private' as desired. Walkthrough of DNA Subway Red Line - Genome Annotation \u00b6 Annotation adds features and information to a DNA sequence -- such as genes and their locations, structures, and functions. A good introduction to annotation can be found in the paper A beginner's guide to eukaryotic genome annotation . We'll also suggest the DNA Subway's primer on annotation evidence . This guide contains an explanation of basic functions for this line, as wellas exercises that might be used in the classroom. Some things to remember about the platform @@ -205,156 +164,115 @@ as exercises that might be used in the classroom. DNA Subway Red Line - Create an Annotation Project with Apollo \u00b6 transition away from Java DNA Subway is transitioning away from the original Java-based Apollo software as most popular web browsers will no longer support Java. The new Apollo is Java-free. Log-in to DNA Subway - unregistered users may 'Enter as Guest' Click 'Annotate a genomic sequence.' (Red Square); select the 'Web Apollo' version For 'Select Organism type' choose 'Animal' or 'Plant' and then select the appropriate subtype. The 'Select Organism' step will load appropriate sample sequences and will also adjust the models used in the de novo gene finding process. For 'Select Sequence Source' select a sample sequence. Apollo support Currently, the Java-free Apollo version of Subway does not support upload of a custom DNA Sequence. This feature is coming soon, but we will help you upload custom genomes/regions for your use in the classroom (Optional) If you have a GFF file of annotated features, you may load these import these annotations from the Green Line, or from a custom GFF file. Name your project and organism (required) and give a description if desired. Click 'Continue' to proceed. Example Exercise - Project Creation: Arabidopsis ChrI \u00b6 In this and subsequent steps, we will annotate a 75KB section of Arabidopsis chromosome I. 1. Log-in to DNA Subway - unregistered users may 'Enter as Guest'. 2. Click 'Annotate a genomic sequence.' (Red Square); select the 'Web Apollo' version. 3. For 'Select Organism type' choose 'Plant' and then 'Dicotyledon'. 4. from 'Select a sample sequence' chose 'Arabidopsis thaliana (mouse-ear cress) chr1, 75.00 kb'. 5. Provide your project with a title, then Click 'Continue.' Sequence You can view your DNA sequence by clicking the 'Sequence' link in the 'Project Information' tab at the bottom of the page. DNA Subway Red Line - Find and Mask Repetitive DNA \u00b6 One you have created a Red Line Project, you may begin the process of generating and assembling predictions and evidence that can be used to annotate genes. 1. Click 'RepeatMasker' 2. When 'RepeatMasker' turns 'green' and the icon displays a 'V' (view); click 'RepeatMasker' again to view results. ![repeat_results](./assets/dna_subway/repeat_results.png){width=\"300px\" height=\"200px\"} Example Exercise - Repeat Masking: Arabodopsis ChrI \u00b6 Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI, 75 kb Tool(s): RepeatMasker Concept(s): Non-coding DNA, sequence repeats, mobile genetic elements (transposons) Following the RepeatMasking steps for the Arabidopsis ChrI sample above, answer the following discussion questions : 1. How many hits were detected in your sample? 2. RepeatMasker reports the length of the repetitive sequences (Length) as well as the class (Attributes). - What is the average length of sequences identified as \"simple repeats\"? - What is the average length of sequences identified as \"low complexity\"? 3. What is the total percentage of repetitive DNA in your sequence? (Sum of the length of all repetitive sequence / sequence length (75 kb) Some Useful Definitions for Repetitive Sequences Simple repeats: 1-5bp repeats (e.g. repetitive dinucleotides 'AT' etc.) Low Complexity DNA: Poly-purine/ poly-pyrimidine stretches, or regions of extremely high AT or GC content. Processed Pseudogenes, SINES, Retrotranscripts: Non-functional RNAs present within genomic sequence. Transposons (DNA, Retroviral, LINES): Genetic elements which have the ability to be amplified and redistributed within a genome. Additional Investigation: In the results table under 'Attributes' each repeat sequence is labeled \"RepeatMasker#-XXX\" The '#' is the ordinal number of the hit, the XXX is the class of DNA element (e.g. \"Simple_repeat\" or \"Low_complexity\"). There are other types of repetitive elements such as transposons and pseudogenes (e.g. Helitron and COPIA) Use online resources to learn more: ( http://gydb.org/index.php/Main_Page ). DNA Subway Red Line - Making Gene Predictions \u00b6 De novo gene predictors can be run on a sample sequence to generate predictions of gene structure and location based solely on the sequence nucleotides. Click on one or more gene prediction tools under the 'Gene Prediction' stop. to view the results table, click the gene predictor again once the indicator displays 'V' (view). Example Exercise - Predict Genes: Arabidopsis ChrI \u00b6 Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI, 75 kb Tool(s): Augustus, FGenesH, Snap, tRNA Scan Concept(s): Genomic DNA, Gene Structure, Canonical sequences Following the gene prediction steps for the Arabidopsis ChrI sample above, answer the following discussion questions : Look at the 'Type' column in the gene prediction report. Considering the Augustus results, find the 6 th gene prediction (hint: AUGUSTUS006;ID=g6) and then locate the first mention of the term 'gene' and copy down the gene's 'start' (i.e. the starting basepair). Note the number of times you see the term 'exon' (i.e. number of exons predicted). Gene Predictor Exon Start (bp) Exon Stop (bp) Augustus 23456 23684 Augustus Augustus Augustus Augustus Based on the chart, did all the gene predictors yield genes starting at the same location? Did all the gene predictions have the same number of exons? Looking at the number of results returned by tRNA Scan, why are they so different from results made by other predictors? Are their places in the genome where tRNAs are more or less densely concentrated? Additional Investigation: Look for the background link at the bottom of the DNA Subway home page and review the section entitled 'Gene Finding'. DNA Subway Red Line - Visualize predicted genes in a Genome Browser \u00b6 A genome browser is an essential tool for visualization genomic data in context. The integrated JBrowse genome browser will allow you to see the visualized gene predictions generated so far. Click 'JBrowse' and allow browser to load. Zoom into a region (for example, paste the region 1:3740638..3749063 into the location window. Tip JBrowse will load multiple tracks of data. Since the entire genome is loaded, we recommend using the 'highlight a region' feature to help keep your place. You may also wish to record the coordinates you are viewing as shown in the coordinates window. You may also adjust the settings for a particular track by clicking on the track name. Right-click on any gene to view additional details about that gene. Examine gene details by double-clicking on a gene to select; then right-click to open the 'View Details' menu. To view more tracks, click on 'Full-Screen View' in the upper-left of the JBrowse window to see any additional tracks available. Useful Definitions Genome Browser: A GUI (Graphical User Interface) for viewing biological information. GBrowse (DNA Subway's Browser) is \"designed to view genomes. It displays a graphical representation of a section of a genome, and shows the positions of genes and other functional elements. It can be configured to show both qualitative data such as the splicing structure of a gene, and quantitative data such as microarray expression levels.\" [citation] Track: The individual regions of the display where information imported into the browser. For each type (or source) of information, there is usually an associated track. Example Exercise - Visualize predicted genes: Arabidopsis ChrI \u00b6 Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI, 75 kb Tool(s): Local Browser (JBrowse) Concept(s): Gene orientation/structure, transposons, chromosome organization Following the gene browser steps for the Arabidopsis ChrI sample above, answer the following discussion questions (the locations of the genes are given in parentheses and can be pasted into the browser): Considering the following genes: BFN1-201 (1:3748591..3753070) SCAMP5-201 (1:3744556..3749035) STP1-201 (1:3776366..3780845) At1G11270.2 (1:3780041..3789000) Do all the gene predictors agree with each other? Which gene predictions seem to match the Ensemble genes most closely? DNA Subway Red Line - Search Databases using BLAST \u00b6 DNA Subway searches customized versions of UniGene and UniProt that contain only validated plant proteins, and are free of predicted or hypothetical proteins. Click 'BLASTN'; wait until the flashing icon displays 'V' (view) Click 'BLASTN' again to view the results. Click 'BLASTX'; wait until the flashing icon displays 'V' (view). Click 'BLASTX' again to view the results. Click on 'JBrowse' and then click 'Full-screen View' in the upper-left. In the 'Available Tracks' menu, add the Blastn and Blastx tracks. Useful Definitions **Some Useful Definitions** BLAST: Basic Local Alignment Search Tool (BLAST) is an algorithm that search databases of biological sequence information (e.g. DNA, RNA, or Protein sequence) and return matches. The BLASTN program is specific to nucleotide data, and the BLASTX algorithm works with sequence data translated into amino acid sequences. UniGene: A database of transcript data, \"each UniGene entry is a set of transcript sequences that appear to come from the same transcription locus (gene or expressed pseudogene), together with information on protein similarities, gene expression, cDNA clone reagents, and genomic location.\" [citation] cDNA: DNA produced by reverse transcribing mRNA using reverse transcriptase. cDNAs are used to investigate mRNA within a biological sample. ESTs: \"Small pieces of DNA sequence (usually 200 to 500 nucleotides long) that are generated by sequencing either one or both ends of an expressed gene. The idea is to sequence bits of DNA that represent genes expressed in certain cells, tissues, or organs from different organisms.\" [citation] Example Exercise - Search Databases using BLAST: Arabidopsis ChrI \u00b6 Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI, 75 kb Tool(s): BLASTN, BLASTX, Upload Data Concept(s): RNA, cDNAs, ESTs, Biological Databases Following the BLAST steps for the Arabidopsis ChrI sample above, answer the following discussion questions (the locations of the genes are given in parentheses and can be pasted into the browser): Both BLASTN and BLASTX returns the 'Length' of your resulting matches. Do you notice differences in the average lengths of BLASTN and BLASTX matches? Explain. Under 'Type' both BLASTN and BLASTX returns 'match' and 'match_part.' 'Match' is describing the overall length of a single match, but individual significant matches may be fragmented, i.e. 'match_part.' Do BLASTN and BLASTX return 'match' and 'match_part' results in different frequencies? Explain. DNA Subway Red Line - Build Gene Models using Apollo \u00b6 Apollo is an extension of JBrowse which allows the user to build and edit gene models. Apollo has a number of features but in this tutorial, we will give brief intro covering the conceptual steps. A. Import Blastn model to match for transcript length Blast searches are matched against UniGene(blastn) and UniProt(blasts). UniGen models are derived from cDNA and ESTs (transcriptome evidence) produced by experiment. Open Apollo and zoom into a region of interest (e.g. 1:3793981..3802033 ) Ensure at least the following tracks are selected (on): Augustus (and other gene predictors: FGenesH, SNAP, etc.) Blastn Double-click on the Blastn result, and drag this transcript into the yellow 'User-created Annotations' section. {width=\"400px\" height=\"250px\"} B. Select a scaffold model Use transcriptome evidence (UniGene - BLASTN) to select the best possible gene model for a scaffold. If no gene model exists or significantly reflects the UniGene model, use the UniGene model itself as a scaffold. Drag a plausible model into the yellow 'User-created Annotations' - in this case we will choose the Augustus model; double-click the Augustus model to select the entire model and drag into 'User-created Annotations'. Adjust the Augustus model to match the 5' and 3' configuration of the blastn model Delete the extraneous 5' exon (single-click to select; right-click to delete) Adjust the new 5' end to match the length of the blastn-derived transcript Adjust the 3' end of the Augustus-derived model (single-click to select; use your cursor/mouse to adjust the model length) C. Edit model for splice sites and variants Protein and EST data can be used to examine possible alternative transcripts. Proteins give clues to the actual length of the translated protein at that locus and its reading frame. Like full length cDNAs, ESTs give valuable information on transcript diversity. ESTs are generated by high throughput methods, and although the data may be fragmentary, it may capture biologically relevant information about splice variants. Turn on the blastx track Examine the additional evidence to consider making adjustments to your Augustus-derived model. If you wish to make additional isoforms of your gene: Double-click to select the entire Augustus-derived model Right-click on the model to duplicate Make adjustments to the model as desired You also have the option of adding additional EST evidence . For the Arabodopsis 75KB section, we have prepared a selection of EST data. You will need to close Apollo to load this data . Download the Arabidopsis ESTs for this region to your computer from this link Click on 'Upload Data'; under \"Add DNA data in FASTA format\" upload the EST file from the link in step 1. Click on 'User BLASTN' to align the ESTs to this section of the Arabidopsis genome Open 'Web Apollo'. The \"Blastn User\" track should be loaded. You may move this track to a convenient position on the browser While EST evidence is always incomplete, these sequences can help you determine features of the gene model. Learn More about Gene Evidence J.Craig Venter on ESTs \"Dynamic Gene\" Evidence animation (requires Flash) D. Determine translation start/stop sites After making your adjustments, you can confirm that your gene model(s) represents the longest possible transcripts: Double-click the model; right-click and select 'Set longest ORF' E. Compare gene model(s) with existing annotations After making your gene models you can compare them with existing annotations by turning on the 'Ensemble genes' track. In this case, our work confirms the first gene model made, but a potential isoform supported by blastx data is likely incorrect. Example Exercise - Build Gene Models using Apollo: Arabodopsis ChrI \u00b6 Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI, 75 kb Tool(s): Apollo Concept(s): Synthesizing multiple lines of evidence Following the Apollo steps for the Arabidopsis ChrI sample above, answer the following discussion questions (the locations of the genes are given in parentheses and can be pasted into the browser): Try annotation of the following genes and take notes on your annotation ( right-click on the gene model, open the 'Information Editor' and scroll down to the comments section to enter comments). How do your annotations compare with the Ensembl annotations? Genes to try: AT1G11270.2 (1:3781511..3790520) STP1-201 (1:3776261..3785270) T28P6.11-201 (1:3762877..3764678) Walkthrough of DNA Subway Yellow Line - Sequence Detection \u00b6 Genome prospecting uses a query sequence (DNA or protein of up to 10,000 base pairs/amino acids) to find related sequences in specific genomes or in a database. A major purpose of genome prospecting is to identify members of gene or transposon families. DNA Subway uses the TARGeT workflow, which integrates BLAST searches, multiple sequence alignments, and tree-drawing utilities. Yellow line uses TARGeT (Tree Analysis of Related Genes and Transposons) uses either a DNA or amino acid 'seed' query to: (i) automatically identify and retrieve gene family homologs from a genomic database, (ii) characterize gene structure and (iii) perform phylogenetic analysis. Due to its high speed, TARGeT is also able to characterize very large gene families, including transposable elements (TEs). [citation] Some things to remember about the platform Yellow Line will return sequences that would normally be excluded from a BLAST search of a genome (e.g. repetitive sequences, transposons). Yellow Line is implemented only for plant genomes DNA Subway Yellow Line - Create a Yellow Line Project \u00b6 Log-in to DNA Subway - unregistered users may 'Enter as Guest' Click 'Prospect Genomes using TARGeT' (Yellow Square) Select a sample sequence, or paste in a sequence to search for. Note DNA Subway Yellow Line is only implemented to search a limited set of plant genomes. Provide your project with a title, then Click 'Continue' Example Exercise - Project Creation: mPing Mite element to search plant genomes for an active transposon \u00b6 The mPing MITE element is an example of an active transposon in rice. Transposons are a major class of DNA elements that impact the function of the genome. Create a Yellow Line project following the steps above and using the mPing Mite Element (Oryza sativa/Rice) DNA Subway Yellow Line - Search Plant Genomes with TARGeT \u00b6 Click and select the genome(s) you wish to search and the click; 'Run' to search those genomes. Click the 'Alignment Viewer' button to view the results of the search as a multiple alignment. Click the 'Tree Viewer' button to view a tree that will group results by similarity. Viewer Tips Alignment Viewer Generates an alignment of all search results Tree Viewer Displays the results of sequence matches as a tree, grouped by sequence similarity yellow_tree Useful Definitions Transposons (DNA, Retroviral, LINES): Genetic elements which have the ability to be amplified and redistributed within a genome. Non-autonomous transposons: Transposons which lack an active transposase gene, thus requiring help from another transposon to move. Autonomous transposons: Transposons which have a functional transposase and can move within the genome. Example Exercise - Search Plant Genomes: mPing Mite element \u00b6 After loading the mPing Mite Element as the query, search the Oryza Sativa genome, and examine the results in the Alignment and Tree Viewers. Repeat this analysis with a new project using the Ping transposase gene and the Ping Transposase protein. Walkthrough of DNA Subway Blue Line - DNA Barcoding and Phylogenetics \u00b6 You can analyze relationships between DNA sequences by comparing them to a set of sequences you have compiled yourself, or by comparing your sequences to other that have been published in database such as GenBank (National Center for Biotechnology Information). Generating a phylogenetic tree from DNA sequences derived from related species can also allow you to draw inferences about how these species may be related. By sequencing variable sections of DNA (barcode regions) you can also use the Blue Line to help you identify an unknown species, or publish a DNA barcode for a species you have identified, but which is not represented in published databases like GenBank. Some things to remember about the platform Wet lab protocols and other resources are available at http://dnabarcoding101.org/ The DNA Barcoding 101 site also contains information on low-cost sequencing for U.S.-based educators. Sample Data How to use provided sample data In this guide, we will use a mosquito dataset that includes DNA sequences isolated from mosquito larvae collected from Virginia's Shenandoah Valley ( \"Mosquito dataset\" ). There is a complete two-hour classroom bioinformatics lab with detailed instructions for instructors and students on QUBES hub here . Where appropriate, a note (in this orange colored background) in the instructions will indicate which options to select to make use of this provided dataset. Sample data citation : Williams, J., Enke, R. A., Hyman, O., Lescak, E., Donovan, S. S., Tapprich, W., Ryder, E. F. (2018). Using DNA Subway to Analyze Sequence Relationships. (Version 2.0). QUBES Educational Resources. doi:10.25334/Q4J111 Video Course Here is a video series on analyzing data with DNA Subway using the above mosquito dataset and lesson: Tip See a Course Source paper with protocols and recommendations for implementing a Barcoding CURE (course-based undergraduate research experience): CURE-all: Large Scale Implementation of Authentic DNA Barcoding Research into First-Year Biology Curriculum . DNA Subway Blue Line - Create a Barcoding Project \u00b6 Log-in to DNA Subway - unregistered users may 'Enter as Guest'. !!! Note Only registered users submitting novel, high-quality sequences will be able to submit sequence to GenBank Choose a project type: - Phylogenetics : build phylogenetic trees from any DNA, protein, or mtDNA sequence) - Barcoding : DNA Barcoding for plants (rbcL), animals (COI), bacteria (16S), and fungi (ITS). Sample Data \"Mosquito\" dataset: Select COI . 3. Under 'Select Sequence Source' select a sequence buy uploading either a FASTA file or AB1 Sanger sequencing tracefile; pasting in a sequence in FASTA format, or selecting and importing a trace file from DNALC. If you do not have a file, you may select any of the available sample sequences. Sample Data \"Mosquito\" dataset: From Select a set of sample sequences select Intro to Barcoding Bioinformatics: Mosquitoes . 4. Name your project, and give a description if desired; click 'Continue.' DNA Subway Blue Line - View and Clean Barcoding Sequence Data \u00b6 A. View Sequencing Trace File If you provided AB1 trace files, or imported files from DNALC, you will be able to view the sequence electropherogram. Click 'Sequence Viewer' to show a list of your sequences. Click on a sequence name to show the sequences' trace file. B. Trim sequence, reverse complement and pair By default, DNA Subway assumes that all reads are in the forward orientation, and displays an 'F' to the right of the sequence. If any sequence is not in that orientation, click the \"F\" to reverse compliment the sequence. The sequence will display an \"R\" to indicate the change. Click 'Sequence Trimmer.' Click 'Sequence Trimmer' again to examine to changes made in the sequence Click 'Pair Builder.' Select the check boxes next to the sequences that represent bidirectional reads of the same sequence set. Alternatively Select the 'Auto Pair' function and verify the pairs generated. Sample Data \"Mosquito\" dataset: Click Try Auto Pairing . One pair of horsefly sequences and 4 pairs of mosquito sequences will be created. Finally, click Save . As necessary, Reverse Compliment sequences that were sequenced in the reverse orientation by clicking the 'F' next to the sequence name. The 'F' will become an 'R' to indicate the sequence has been reverse complimented. Click Save to save the created pairs. C. Build a consensus sequence This step remove poor quality areas at the 5' and/or 3' ends of the consensus sequence. Click on \"Trim Consensus.\" Once the job is ready to view, click \"Trim Consensus\" again to view the results. Scroll left and right in the consensus editor window to identify what string of nucleotides from the consensus sequence you want to trim. Click on the last consensus sequence nucleotide that you want to trim. A red line will indicate what nucleotides will be removed from the consensus sequences. Click Trim . A new \"Consensus Editor\" window will pop up displaying the trimmed sequences. Sample Data \"Mosquito\" dataset: All of the sequences in this dataset benefit from trimming. Follow the steps above to trim sequences. We recommending trimming at the first and last \"grey\" (lower quality) nucleotide on the right and left ends. DNA Subway Blue Line - Find Matches with BLAST \u00b6 DNA Subway Blue Line will search a local copy of a BLAST databases to check for published matches in GenBank. Tip At the end of the BLAST results page, you can see the latest update to the DNA Subway BLAST database. Click 'BLASTN' then click the 'BLAST' link to BLAST the sequence of interest. When the search is completed a 'View' link will appear. Examine the BLAST matches for candidate identification. Clicking the species name given in the BLAST hit will also give additional information/photos of the listed species. If desired, select the check box next to any hit, and click &Add BLAST hits to project to add selected sequences to your project. Sample Data \"Mosquito\" dataset: We recommend performing a BLASTN search for all samples and saving the top 2 matches to your project for additional analysis (as in Step 3). DNA Subway Blue Line - Add Reference Data \u00b6 Depending on the project type you have created, you will have access to additional sequence data that may be of interest. For example, if you are doing a DNA barcoding project using the rbcL gene, samples of rbcL sequence from major plant groups (Angiosperms, Gymnosperms, etc.) will be provided. Choose any data set to add it to your analysis; you will be able to include or exclude individual sequences within the set in the next step. Click 'Reference Data.' Select sequences of your choice. Click Add ref data to add the data to your project. Sample Data \"Mosquito\" dataset: Select Common insects and then click &Add ref data . DNA Subway Blue Line - Build a Multiple Sequence Alignment and Phylogenetic Tree \u00b6 A. Build a multiple sequence alignment and phylogenetic tree Click 'Select Data.' Select any and all sequences you wish to add to your tree. Sample Data \"Mosquito\" dataset: We suggest first adding your \\\"user data\\\" and building an alignment and tree. You can return to this step later to build additional trees. Once Selected, click Save Selections . Follow the rest of the steps in this section and section B to create your tree. Click Save Selections to select data Click 'MUSCLE.' to run the MUSCLE program. Click 'MUSCLE' again to open the sequence alignment window. Examine the alignment and then select the Trim Alignment button in the upper-left of the Alignment viewer'. B. Build phylogenetic tree Click 'PHYLIP NJ' and then click again to examine a neighbor-joining tree Click 'PHYLIP ML' and then click again to examine a maximum-likelihood tree Sample Data \"Mosquito\" dataset: We suggest setting \"horsefly\" as outgroup for both trees. Walkthrough of DNA Subway Green Line: Kallisto/Sleuth RNA-Seq \u00b6 The Green Line runs within CyVerse DNA Subway and leverages powerful computing and data storage infrastructure and uses the supercomputer cluster to provide a high performance analytical platform with a simple user interface suitable for both teaching and research. is a quick, highly-efficient software for quantifying transcript abundances in an RNA-Seq experiment. Even on a typical laptop, Kallisto can quantify 30 million reads in less than 3 minutes. Integrated into CyVerse, you can take advantage of CyVerse DNA Subway to process your reads, do the Kallisto quantification, and analyze reads with the Kallisto companion software in an R-Shiny app. Some things to remember about the platform You must be a registered CyVerse user to use Green Line. The Green Line was designed to make RNA-Seq data analysis \"simple\". However, we ask that users thoughtfully decide what \"jobs\" they want to submit. Each user is limited to a maximum of 4 concurrent jobs running on Green Line . A single Green Line project may take a week to process since HPC computing is subject to queues which hundreds of other jobs may be staging for. Additionally these systems undergo regular maintenance and are subject to periodic disruption. Note New, faster Green Line Green Line is now running on Jestream Cloud . This should greatly reduce queue times (The entire running time for this tutorial is about 60 minutes). We have designed Green Line for a lower number of concurrent users (<50), and still recommend teaching using jobs you have made public, and only running the entire workflow when you are working with novel data. Please let us know about your experience: send feedback . Important: Discontinued Support for Tuxedo Workflow The Tuxedo workflow previously implemented for the Green Line will has been removed in June 2019 . Data and previously analyzed results will still be available on the CyVerse Data Store, however it is not possible to execute new analyses which include Tuxuedo. Sample Data How to use provided sample data In this guide, we will use an RNA-Seq dataset ( \"Zika infected hNPCs\" ). This experiment compared human neuroprogenetor cells (hNPCs) infected with the Zika virus to non-infected hNPCs. You can read more about the experimental conditions and methods in this reference . Where appropriate, a note (in this orange colored background) in the instructions will indicate which options to select to make use of this provided dataset. Sample data citation : Yi L, Pimentel H, Pachter L (2017) Zika infection of neural progenitor cells perturbs transcription in neurodevelopmental pathways. PLOS ONE 12(4): e0175744. reference . Video Course Here is a video series on analyzing data with DNA Subway using the above Zika dataset and lesson: DNA Subway Green Line: Kallisto/Sleuth - Create an RNA-Seq Project to Examine Differential Abundance \u00b6 A. Create a project in Subway Log-in to - unregistered users may NOT use Green Line. Click on the Green \"Next Generation Sequencing\" square to start a Green Line project. For 'Select Project Type' select either \"Single End Reads\" or \"Paired End Reads\". Sample Data \"Zika infected hNPCs\" dataset: Select Paired End Reads 4. For 'Select an Organism' select a species and genome build. Sample Data \"Zika infected hNPCs\" dataset: Select Homo sapiens - Ensembl 78 GrCh38 5. Enter a project title, and description; click 'Continue'. Tip If you don't see a desired species/genome contact us to have it added. B. Upload Read Data to CyVerse Data Store The sequence read files used in these experiments are too large to upload using the Subway internet interface. You must upload your files (either .fastq or .fastq.gz) directly to the CyVerse Data Store. Upload your reads to the CyVerse Data Store using Cyberduck. See instructions: Data Store Guide . Note This step is not directly connected with DNA Subway. You can use any data uploaded to the CyVerse Data Store. Data Limit There is a limit of 6GB per file for samples on Green Line. For larger file sizes, you may wish to use the Kallisto tools in the CyVerse Discovery Environment. See the for more information. DNA Subway Green Line: Kallisto/Sleuth - Manage Data and Check Quality with FASTQC \u00b6 A. Select and pair files Click on the \"Manage Data\" step: this opens a Data store window that says \"Select your FASTQ files from the Data Store\" (if you are not logged in to CyVerse, it will ask you to do so). Click on the folder that matches your CyVerse username and Navigate to the folder where your sequencing files are located. Sample Data \"Zika infected hNPCs\" dataset: Select Sample Data . Select the sequencing files you want to analyze (either .fastq or .fastq.gz format). Sample Data \"Zika infected hNPCs\" dataset: You will be presented with the following 8 files; check-select all of the files and click the + Add files button: SRR3191542_1.fastq.gz SRR3191542_2.fastq.gz SRR3191543_1.fastq.gz SRR3191543_2.fastq.gz SRR3191544_1.fastq.gz SRR3191544_2.fastq.gz SRR3191545_1.fastq.gz SRR3191545_2.fastq.gz The SRR3191542 and SRR3191543 files are 2 replicates (paired-end) of the uninfected cells and the SRR3191544 and SRR3191545 file are from the Zika infected cells. If working with paired-end reads, click the Pair Mode OFF button to toggle to on; check each pair of sequencing files to pair them. Sample Data \"Zika infected hNPCs\" dataset: Right reads end in \"_1\" and left reads end in \"_2\". Click the Pair Mode OFF button to turn pairing on, and check-select each of the paired samples (e.g. SRR3191543_1.fastq.gz and SRR3191543_2.fastq.gz). B. Check sequencing quality with FastQC It is important to only work with high quality data. is a popular tool for determining sequencing quality. Tip This step takes place in the same Manage data window as the steps above. Once files have been loaded, in the 'Manage Data' window, click the 'Run' link in the 'QC' column to run FastQC. Note There is a limit of 4 concurrent jobs. These jobs should take less than 20 minutes to complete (depending on file size) and you may need to let several jobs finish before proceeding. If you have previously processed reads for quality, you can skip the FastQC step. 2. One the jobs are complete, click the 'View' link to view the results. Tip You can see a description and explanation of the FastQC report on the CyVerse Learning Center and a more detailed set of explanations on the website. DNA Subway Green Line: Kallisto/Sleuth - Trim and Filter Reads with FastX Toolkit \u00b6 Raw reads are first \"quality trimmed\" (remove poor quality bases off the end(s) of a read) and then are \"quality filtered\" (filter out entire poor quality reads) prior to aligning to the transcriptome. After trimming and filtering, FastQC is run on the trimmed/filtered files. Click \"FastX ToolKit\" to open the FastX Toolkit panel for all your data. For each file, under 'Basic', Click 'Run' to filter the reads using default parameters or click 'Advanced' to run with desired parameters; repeat this process for all the FASTQ files in your dataset. Sample Data \"Zika infected hNPCs\" dataset: The quality of the reads in this dataset is relatively good. You can skip the FastX Toolkit step for this dataset . Tip The 'Basic' setting for FastX Toolkit uses the same settings as the defaults in the 'Advanced' run: quality_trimmer: minimum quality : 20 quality_trimmer: minimum trimmed read length : 20 quality_filter: minimum quality : 20 quality_filter: minimum quality : 50 Once the job completes, click the 'View' link to view a generated FastQC report. Since you may trim reads multiple times to achieve the desired quality of data record the job IDs (e.g. fx####) that you wish to use in the subsequent steps. DNA Subway Green Line: Kallisto/Sleuth - Quantify reads with Kallisto \u00b6 Kallisto uses a 'hash-based' pseudo alignment to deliver extremely fast matching of RNA-Seq reads against the transcriptome index (which was selected when you created your Green Line project). A Kallisto analysis must be run for each mapping of RNA-Seq reads to the index. In this tutorial, we have 12 fastQ files (6 pairs), so you will need to launch 6 Kallisto analyses. The Science Behind Kallisto You can find a detailed video series on the science behind the Kallisto software and pseudoalignment: [YouTube](https://www.youtube.com/playlist?list=PL-0S9LiUi0vhjynujVZw34RKmUo6vPmVd). Click the \"Quantification\" step and enter a sample and condition name for each of your samples. You will typically have several replicates (at least 3 minimum) for each sample. For your condition, our implementation of the Kallisto/Sleuth workflow supports two conditions . Warning When naming your samples and conditions, avoid spaces and special characters (e.g. !#$%^&/, etc.). Also be sure to be consistent with spelling. Sample Data \"Zika infected hNPCs\" dataset: We suggest the following names for this dataset: Left/Right Pair Sample name Condition SRR3191542_1.fastq.gz SRR3191542_2.fastq.gz Mock1-1 Mock SRR3191543_1.fastq.gz SRR3191543_1.fastq.gz Mock2-1 Mock SRR3191544_1.fastq.gz SRR3191544_2.fastq.gz ZIKV1-1 Zika SRR3191545_1.fastq.gz SRR3191545_2.fastq.gz ZIKV2-1 Zika After naming the samples and conditions, click the Submit button to submit a job. Typically, within ~1 minute you will be provided with a job number. The job will be entered into the queue at the TACC Stampede supercomputing system. You can come back and click the Quantification stop to see the status of the job. The indication for the quantification stop will show \"R\" (running) while the job is running. Sample Data \"Zika infected hNPCs\" dataset: Under parameters uncheck the Build pseudo-bam files option. Tip You can select some of the advanced options for your Kallisto job by clicking the \"Parameters\" link in the Quantification stop. See more about these advanced parameters in the Kallisto manual . DNA Subway Green Line: Kallisto/Sleuth- Visualize data using IGV \u00b6 In the \"View Results\" steps you have access to alignment visualizations, data download, and interactive visualization of your differential expression results. Click the \"View results\" step and choose one of the following options: IVG - Integrated Genome Viewer Tip IGV visualization will only be possible if you have built pseudo-bam files in the Kallisto step. Click the icon in the \"IGV\" column to view a visualization of your reads pseudoaligned to the reference transcriptome. You will need to click the Make it public button (and possibly be re-directed to the CyVerse Discovery Environment). After making the data \"public\" which allows DNA Subway to access your files on the CyVerse Data Store, you must also select a memory size to launch this Java application. If you are not sure of which value to select, use the default 750MB option. Warning Using IGV requires Java software. Java is increasingly unsupported for security reasons on the internet. Java Help Java must be available and enabled in your Internet browser to use the IGV function. Java frequently is the source of security vulnerabilities and so its not uncommon to experience configuration issues due to safety. Follow the tips below to configure Java for your computer. Alternatively, you can use the Download link (see instructions in the section below) to download your data (you will need the .bam and .bam.bai files) and download and install yourself. Internet Browser We highly recommend using Firefox as your browser for DNA Subway. - Verify your Java availability for your browser: Java test - Java must be enabled in your browser Java Configuration Open the Java control panel on your computer. (On Mac, open System Preferences > Java. On PC, open Control Panel > Programs > Java.) Click the Security tab and check \"Enable Java in the browser\" and set the security level for applications to \"high\". Add \" http://dnasubway.cyverse.org \" and \" http://gfx.dnalc.org \" to the \"Exception Site List\" in the Java Security tab. Download Data - Abundance Click the folder icon to be redirected to the CyVerse Discovery Environment (you may be required to log in). You will be directed to all outputs from you Kallisto analysis. You may preview them in the Discovery Environment or use the path listed to download the files using Cyberduck (see Data Store Guide ). A tab-separated file of abundances for each sequence pair is available at the download link. DNA Subway Green Line: Kallisto/Sleuth- Visualize data using Sleuth \u00b6 Differential analysis - Shiny App Click the \"Sleuth R Shiny\" link to launch an interactive window which contains data and graphics from your analysis. R Shiny App Walkthrough The R Shiny App allows you to explore your differential expression results as generated by the . We will cover highlights to for each menu in the app. Data Transfer Timings It can take a few minutes for data to be transferred to the R Shiny server after the quantification step completes. If R Shiny does not load, try again in a few minutes. If you still have an issue, use the link and include your project number in the feedback form. Results Menu This menu is an interactive table of your results. You can choose which columns to display in the table using the checkboxes on the left of the screen. Several important values selected by default include: Target_id : This is the name of the transcript (gene) from the selected reference transcriptome. qval : This is a corrected (for multiple testing) p-value indicating the significance test of differential abundance. Lower numbers indicate greater significance. b : This is an estimate of the fold change between the conditions ext_gene : If available, these are gene names pulled from Ensemble Tip Click the Download button to download these results. Bootstrap This menu will display a box plot that indicates the difference in expression between conditions. The box plots themselves indicate variation between replicates as estimated by bootstrap sampling of the reads. A dropbox enables you to select any transcript. Clicking the \"Show genes\" will load alternative gene names if available. Tip Right-click a graph to download this and other images. PCA This graph displays principle components of each of the conditions/replicates. In general replicates of the same condition should cluster closely together. Volcano Plot This scatter plot displays all transcripts colored by significance of differential abundance. You may also use menu on the left of the screen to highlight specific genes/transcripts or previously set filters from the results menu. Loadings This barplot indicates which genes/transcripts explain most of the variance computed in the principle components analysis. Heatmap This heatmap gives a measure of the similarity between the possible comparison of the samples and their replicates. Summary : Together, Kallisto and Sleuth are quick, powerful ways to analyze RNA-Seq data. Walkthrough of DNA Subway Purple Line (beta testing documentation) \u00b6 BETA RELEASE The Purple line is in beta release. Please send feedback to DNALC Admin . The Purple Line provides the capability for analysis of microbiome and eDNA (environmental DNA) by implementing a simplified version of the QIIME 2 (pronounced \"chime two\") workflow. Using the Purple Line, you can analyze uploaded high throughput sequencing reads to identify species in microbial or environmental DNA samples. Metabarcoding uses high-throughput sequencing to analyze hundreds of thousands of DNA barcodes from complex mixtures of DNA. In a typical experiment, DNA is isolated from sterile swabs or material taken from different environmental locations or conditions. PCR is used to amplify a variable region, such as COI, or 12S or 16S ribosomal RNA genes, and sequence reads identify the variety and abundance of species from different samples. The analysis requires specialized software, such as QIIME 2. The Purple Line integrates sequence data and metadata imported from CyVerse's Data Store, demultiplexing of samples, quality control, and taxonomic identification and quantitation. Once sequences are analyzed, the results can be visualized to allow comparisons between samples and different conditions summarized in the metadata. Some things to remember about the platform You must be a registered CyVerse user to use Purple Line (register for a CyVerse account at user.cyverse.org ). The Purple line was designed to make microbiome/eDNA data analysis \"simple\". However, we ask that users very carefully and thoughtfully decide what \"jobs\" they want to submit. A single Purple Line project may take hours to process since HPC computing is subject to queues which may support hundreds of other jobs. These systems also undergo regular maintenance and are subject to periodic disruption. DNA Subway implements the QIIME 2 software. This software is in continual development. Our version may not be the most current, and our documentation and explanation is not meant to replace the full QIIME 2 documentation . We have made design decisions to create a straightforward classroom-friendly workflow. While this Subway Line does not have all possible features of QIIME 2, we purpose to cover important concepts behind microbiome and eDNA analysis. You may work with up to 96 samples (e.g. 192 paired files or 96 single read files) in a Purple line project. Sample Data: How to use provided sample data In this guide, we will use a microbiome dataset ( \"ubiome-test-data\" ) collected from various water sources in Montana (down-sampled and de-identified).Where appropriate, a note (in this orange colored background) in the instructions will indicate which options to select to make use of this provided dataset. DNA Subway Purple Line - Metadata file and Sequencing Prerequisites \u00b6 If you are generating data for a project (i.e. sequencing samples), you will need to provide the sequencing data (fastq files) as well as a metadata file that describes the data contained in these sequencing files. This metadata must conform to strict guidelines, or analyses will fail. QIIME 2 metadata is stored in a TSV (tab-separated values) file. These files typically have a .tsv or .txt file extension, though it doesn't matter to QIIME 2 what file extension is used. TSV files are simple text files used to store tabular data, and the format is supported by many types of software, such as editing, importing, and exporting from spreadsheet programs and databases. Thus, it's usually straightforward to manipulate QIIME 2 metadata using the software of your choosing. If in doubt, we recommend using a spreadsheet program such as Microsoft Excel or Google Sheets to edit and export your metadata files. Handling Project Metadata Before you create your project, you will have generated metadata (as described above) for your project. You have two options for preparing this metadata to ensure that it conforms to the required QIIME2 parameters. The file must be validated (which you can do on your own or using Subway). If there are errors in your file (this is common), they must be fixed. Formatting Your Metadata Leading and trailing whitespace characters If any cell in the metadata contains leading or trailing whitespace characters (e.g. spaces, tabs), those characters will be ignored when the file is loaded. Thus, leading and trailing whitespace characters are not significant, so cells containing the values 'gut' and ' gut' are equivalent. This rule is applied before any other rules described below ID column The first column MUST be the ID column name (i.e. ID header) and the first line of this column should be #SampleID or one of a few alternative. - Case-insensitive: id; sampleid; sample id; sample-id; featureid; feature id; feature-id. - Case-sensitive: #SampleID; #Sample ID; #OTUID; #OTU ID; sample_name Sample IDs For the sample IDs, there are some simple rules to comply with QIIME 2 requirements: IDs may consist of any Unicode characters, with the exception that IDs must not start with the pound sign (#), as those rows would be interpreted as comments and ignored. IDs cannot be empty (i.e. they must consist of at least one character). IDs must be unique (exact string matching is performed to detect duplicates). At least one ID must be present in the file. IDs cannot use any of the reserved ID column names (the sample ID names, above). The ID column can optionally be followed by additional columns defining metadata associated with each sample or feature ID. Metadata files are not required to have additional metadata columns, so a file containing only an ID column is a valid QIIME 2 metadata file. Column names May consist of any Unicode characters. Cannot be empty (i.e. column names must consist of at least one character). Must be unique (exact string matching is performed to detect duplicates). Column names cannot use any of the reserved ID column names. Column values May consist of any Unicode characters. Empty cells represent missing data. Note that cells consisting solely of whitespace characters are also interpreted as missing data. QIIME 2 currently supports categorical and numeric metadata columns. By default, QIIME 2 will attempt to infer the type of each metadata column: if the column consists only of numbers or missing data, the column is inferred to be numeric. Otherwise, if the column contains any non-numeric values, the column is inferred to be categorical. Missing data (i.e. empty cells) are supported in categorical columns as well as numeric columns. For more details, and for how to define the nature of the data when needed, see the QIIME 2 metadata documentation . Working with an existing metadata file Tip If you have your own metadata file, it will still need to be validated once uploaded to DNA Subway. Using a spreadsheet editor, create a metadata sheet that provides descriptions of the sequencing files used in your experiment. Export this file as a tab-delimited .txt or .tsv file. following the QIIME 2 metadata documentation]( https://docs.qiime2.org/2019.10/tutorials/metadata/ ) recommendations. (Optional: if you using your own metadata file you can validate it using DNA Subway and or online QIIME2 validator Keemei ). Tip See an example metadata file used for our sample data here: metadata file . Click the Download button on the linked page to download and examine the file. ( Note : This is an Excel version of the metadata file, you must save Excel files as .TSV (tab-separated) to be compatible with the QIIME 2 workflow.) Creating a metadata file using DNA Subway See DNA Subway Purple Line - Metadata and QC section C. DNA Subway Purple Line - Create a Microbiome Analysis Project \u00b6 A. Create a project in Subway Log-in to DNA Subway (unregistered users may NOT use Purple Line, register for a CyVerse account at user.cyverse.org . Click the purple square (\"Microbiome Analysis\") to begin a project. For 'Select Project Type' select either Single End Reads or Paired End Reads Sample Data \"ubiome-test-data\" dataset: Select Single End Reads For 'Select File Format' select the format the corresponds to your sequence metadata. Sample Data \"ubiome-test-data\" dataset: Select Illumina Casava 1.8 Tip Typically, microbiome/eDNA will be in the form of multiplexed FastQ sequences. We support the following formats: Illumina Casava 1.8 Enter a project title, and description; click Continue . B. Upload read data to CyVerse Data Store The sequence read files used in these experiments are too large to upload using the Subway interface. You must upload your files ( Note : Only .fastq.gz files are accepted) directly to the CyVerse Data Store: Upload your FASTQ sequence reads; Note : Only .fastq.gz files are accepted. Sample metadata file (.tsv or .txt formatted according to QIIME 2 Metadata documentation ) to the CyVerse Data Store using Cyberduck. See instructions: CyVerse Data Store Guide . (Optional: You can edit and change metadata using the Subway interface in the [Manage data]step once the project is created.) DNA Subway Purple Line - Metadata and QC \u00b6 A. Select files using Manage Data Click on the 'Manage data stop: this opens a window where you can add your FASTQ (up to 192 paired files or 96 single read files) and metadata files. Click +Add from CyVerse to add the FASTQ files uploaded to the CyVerse Data Store. Select your files and then click Add selected files {.interpreted-text role=\"guilabel\"} or Add all FASTQ files in this directory {.interpreted-text role=\"guilabel\"} as appropriate. Note : Only .fastq.gz files are accepted. Sample Data \"ubiome-test-data\" dataset: Navigate to: Shared Data > SEPA_microbiome_2016 > ubiome-test-data and click Add all FASTQ files in this directory 2. To add your metadata file you may use one of three options: - Add from CyVerse : Add a metadata file you have uploaded to CyVerse Data store - Upload locally : Directly upload a metadata file from your local computer - Create New : Create a new metadata file using DNA Subway Creating a metadata file using DNA Subway You can create a metadata file using DNA Subway. Creating the file step-by-step will help you to avoid metadata errors. Be sure you have consulted the QIIME 2 documentation so you can anticipate what the required fields are. To use this feature under in the 'Manage data' step under 'Metadata Files' click Create new Sample IDs and adding/removing samples These are unique IDs for each of your samples. All metadata files must have a column called #SampleID . Click +Add samples to add additional rows. In the Subway form, these will be unique, arbitrary names (roughly corresponding to well-positions on a 96-well microplate). You can change these (including pasting in sample names from an existing spreadsheet). Right-clicking on a row number allows you to remove or insert rows. Adding columns, managing sample descriptions and data types The very last column must be a sample description. You can click the arrow on the right of this column to add a new column (which will be added to the left). Column names must be unique, must not be empty, cannot contain whitespace, can contain a maximum of 32 characters, cannot match a reserved column name. Notice that when you click on a column name it is colored -pink for columns that have numeric data (e.g. measurements) and cyan for everything else (e.g. categorical descriptions in the form of words (i.e. strings)). Clicking a column name will allow you to change its type. Handling errors If you violate one of the rules for metadata formatting, the entry will turn red. Consult the help and or the QIIME 2 documentation to correct the error. Click Save to save your metadata file, and close the window. Sample Data \"ubiome-test-data\" dataset: Click Add from CyVerse Navigate to: Shared Data > SEPA_microbiome_2016 > ubiome-test-data Select the mappingfile_MT_corrected.tsv and then click Add selected files . 3. As needed, you can edit or rename your metadata file. Before proceeding, you must validate your metadata file. To validate, click the \"validate\" link to the right of the metadata file you wish to check. Once the validation completed, click Run to proceed. If you have errors, you will be presented with an Edit button so that you can return to the file and edit. B. Demultiplex reads At this step, reads will be grouped according to the sample metadata. This includes separating reads according to their index sequences if this was not done prior to running the Purple Line. For demultiplexing based on index sequences, the index sequences must be defined in the metadata file. Note Even if your files were previously demultimplexed (as will generally be the case with Illumina data) you must still complete this step to have your sequence read files appropriately associated with metadata. 1. Click the 'Demultiplex reads' and choose a number of reads to sample. When the job has completed click Demultiplexing Summary to view your results. In 'Random sequences to sample for QC', enter a value (1000 is recommended), Sample Data \"ubiome-test-data\" dataset: Use the default of 1000 sequences 2. When demultiplexing is complete, you will generate a file (.qzv) click this link to view a visualization and statistics on the sequence and metadata for this project. Tip Several jobs on Purple Line will take several minutes to an hour to complete. Each time you launch one of these steps you will get a Job ID. You can click the View job info {.interpreted-text role=\"guilabel\"} button to see a detailed status and diagnostic/error messages. If needed There is a [stop this job]{.title-ref} link at the bottom of the info page to cancel a job. Note QIIME2 Visualizations One of the features of QIIME 2 are the variety of visualizations provided at several analysis steps. Although this guide will not cover every feature of every visualization, here are some important points to note. QIIME2 View : DNA Subway uses the QIIME 2 View plugin to display visualizations. Like the standalone QIIME 2 software, you can navigate menus, and interact with several visualizations. Importantly, many files and visualizations can be directly download for your use outside of DNA Subway, including in report generation, or in your custom QIIME 2 analyses. You can view downloaded .qza or .qzv files at view.qiime2.org . Quality Graphs Explained After demultiplexing, you will be presented with a visualization that displays the following tables and graphs: Overview Tab Demultiplexed sequence counts summary : For each of the fastq files (each of which may generally correspond to a single sample), you are presented with comparative statistics on the number of sequences present. This is followed by a histogram that plots number of sequences by the number of samples. Per-sample sequence counts : These are the actual counts of sequences per sample as indicated by the sample names you provided in your metadata sheet. Interactive Quality Plot This is an interactive plot that gives you an average quality (y-axis) by the position along the read (x-axis). This box plot is derived from a random sampling of a subset of sequences. The number of sequences sampled will be indicated in the plot caption. You can use your mouse drag and zoom in to regions on the plot. Double-click your mouse to zoom out. 3. Click the \"Interactive Quality Plot\" tab to view a histogram of sequence quality. Use this plot at the tip below to determine a location to trim. Tips on trimming for sequence quality On the Interactive Quality Plot you are shown an histogram, plotting the average quality (x axis) Phred score vs. the position on the read (y axis) in base pairs for a subsample of reads. Zooming to determine 3' trim location Click and drag your mouse around a collection of base pair positions you wish to examine. Clicking on a given histogram bar will also generate a text report and metrics in the table below the chart. Using these metrics, you can choose a position to trim on the right side (e.g. 3' end of the sequence read). The 5' (left trim) is specific to your choice of primers and sequencing adaptors (e.g. the sum of the adaptor sequence you expect to be attached to the 5' end of the read). Poor quality metrics will generate a table colored in red, and those base positions will also be colored red in the histogram. Double-clicking will return the histogram to its original level of zoom. Example plots It is important to maximize the length of the reads while minimizing the use of low quality base calls. To this end, a good guideline is to trim the right end of reads to a length where the 25 th percentile is at a quality score of 25 or more. However, the length of trimming will depend on the quality of the sequence, so you may have to use a lower quality threshold to retain enough sequence for informative sequence searches and alignments. This may require multiple runs of the analysis to find the optimal trim length for your data. Quality drops significantly at base 35 Improved quality sequence C. Use DADA2 for Trimming and Error-correction of Reads It is important to only work with high quality data. This step will generate a sequence quality histogram which can be used to determine parameter for trimming. Click 'DADA2' and choose the metadata file corresponding to the samples you wish to analyze. Then choose values for trimming of the reads. For \"trimLeft\" (the position starting from the left you wish to trim) and \"TruncLen\" (this is the position where reads should be trimmed, truncating the 3' end of the read. Reads shorter than this length will be discarded). Finally, click Trim reads . Sample Data \"ubiome-test-data\" dataset: Based on the histogram for our sample, we recommend the following parameters: trimLeft: 17 (this is specific to primers and adaptors in this experiment) TruncLen: 200 (this is where low quality sequence begins, in this case because our sequence length is lower than the expected read length) D. Check Results of Trimming Once trimming is complete, the following outputs are expected: Click on DADA2 and then click on the links in the Results table to examine results. Trim Table ( Metric summary , Frequency per sample , Frequency per feature ): Summarizes the dataset post-trimming including the number of samples and the number of features per sample. The \"Interactive Sample Detail\" tab contains a sampling depth tool that will be used in computation of the core matrix. Note You will use the maximum frequency value for the Alpha rarefaction step So you may wish to record this value now for the DNA Subway 'Clustering sequences' step. Stats : Sequencing statistics for each of the sample IDs described in the original metadata file. Representative Sequences ( Sequence Length Statistics , Seven-Number Summary of Sequence Lengths , Sequence Table ): This table contains a listing of features observed in the sequence data, as well as the DNA sequence that defines a feature. Clicking on the DNA sequence will submit that sequence for BLAST at NCBI in a separate browser tab. The feature table contains two columns output by DADA2. DADA2 (Divisive Amplicon Denoising Algorithm 2) determines what sequences are in the samples. DADA2 filters the sequences and identifies probable amplification or sequencing errors, filters out chimeric reads, and can pair forward and reverse reads to create the best representation of the sequences actually found in the samples and eliminating erroneous sequences. Feature ID : A unique identifier for sequences. Sequence : A DNA Sequence associated with each identifier. Clicking on any given sequence will initiate at BLAST search on the NCBI website. Click \"View report\" on the BLAST search that opens in a new web browser tab to obtain your results. Keep in mind that if your sequences are short (due to read length or trimming) many BLAST searches may not return significant results. Tip Although the term \"feature\" can (unfortunately) have many meanings as used by the QIIME2 documentation, unless otherwise noted in this documentation it can be thought of as an OTU ( Operational Taxonomic Unit ); another substitution for the word species. OTU is a convenient and common terminology for referring to an unclassified or undetermined species. Ultimately, we are attempting to identify an organism from a sample of DNA which may not be informative enough to reach a definitive conclusion. Tip If you want to redo the DADA2 step with different parameters, click the \"New Job\" tab on the upper left of a DADA2 window to submit a new job. New jobs appear as tabs on Subway steps that are typically run several times. You can go back an see these jobs which are labeled with a job number. DNA Subway Purple Line - Alpha Rarefaction/Clustering Sequences \u00b6 A. Alpha rarefaction At this step, you can visualize summaries of the data. A feature table will generate summary statistics, including how many sequences are associated with each sample. Note that sample depth is limited to 100,000. Click on 'Alpha rarefaction'. Select \"run\" and designate the minimum and maximum rarefaction depth. A minimum value should be set at 1. The maximum value is specific to your data set. The maximum value is specific to your data set. To determine what the maximum value should be set to, open the \"Trim Table\" from the \"DADA2\" step. You may not choose a value that is greater than the maximum frequency per sample. In general, choosing a value that is somewhere around the median frequency seems to work well, but you may want to increase that value if the lines in the resulting rarefaction plot don't appear to be leveling out, or decrease that value if you seem to be losing many of your samples due to low total frequencies closer to the minimum sampling depth than the maximum sampling depth. Identify the maximum Sequence Count value and enter that number as the maximum value. Click Submit Job . Note Since you may want to try Alpha rarefaction using different combinations of results from DADA2 trimming and your choice of rarefaction depths, your trim (DADA2) jobs are displayed on the left, and each new Alpha rarefaction setting will appear as a tab on the top. Sample Data \"ubiome-test-data\" dataset: We recommend the following parameters: Min. rarefaction depth : 1 Max. rarefaction depth : 2938 Under 'Results' click on Alpha Rarefaction Plot to view the results. Navigating Alpha Rarefaction graphs Alpha rarefaction generates an interactive plot of species diversity by sampling depth by the categorical samplings described in your sample metadata. You can use dropdown menus to change metrics/conditions displayed and also export data as a CSV file. DNA Subway Purple Line - Calculate Core Metrics/Alpha and Beta Diversity \u00b6 At this stop, you will examine Alpha Diversity (the diversity of species/taxa present within a single sample) and Beta Diversity (a comparison of species/taxa diversity between two or more samples). Alpha diversity answers the question - \"How many species are in a sample?\" Beta diversity answer the question - \"What are the differences in species between samples?\" A. Calculate core metrics Click on 'Core metrics' and then click the \"run\" link. Choose a sampling depth based upon the \"Sampling depth\" tool (described in Section D Step 1, in the Trim Table output; Interactive Sample Detail tab). Choose an appropriate classifier (see comments in the tip below) and click Submit job . Choosing Core metrics parameters Sampling Depth In downstream steps, you will need to choose a sampling depth for your sample comparisons. You can choose by examining the table generated at the Trim reads step. In the Trim Table output, Interactive Sample Detail tab, use the \"Sampling depth\" tool to explore how many sequences can be sampled during the Core matrix computation. As you slide the bar to the right, more sequences are sampled, but samples that do not have this many sequences will be removed during analysis. The sampling depth affects the number of sequences that will be analyzed for taxonomy in later steps: as the sampling depth increases, a greater representation of the sequences will be analyzed. However, high sampling depth could exclude important samples, so a balance between depth and retaining samples in the analysis must be found. Classifier Choose a classifier pertaining to your experiment type. Microbiome choose Greengenes (515F/806R) or Greengenes (full sequences) or Sliva (16S rRNA) classifier eDNA experiment with marine fishes you may elect to choose the Fish 12S/ecoPrimer classifier Sample Data \"ubiome-test-data\" dataset: We recommend the following parameters: Sampling Depth : 3000 Classifier : Grenegenes (full sequences) B. Examine alpha and beta diversity When core metrics is complete, you should generate several visualization results. Click each of the following to get access: Alpha Diversity: Pielou's Evenness Alpha Correlation: Measure of community evenness using correlation tests Group Significance: Analysis of differences between features across group Faith's Phylogenetic Diversity Alpha Correlation: Faith Phylogenetic Diversity (a measure of community richness) with correlation tests Group Significance: Faith Phylogenetic Diversity ( a measure of community richness) Beta Diversity: Bray-Curtis Distance Bray-Curtis is a metric for describing the dissimilarity of species in an ecological sampling. - Bioenv: Bray-Curtis test metrics Emperor: Interactive PCoA plot of Bray-Curtis metrics Jaccard Distance Emperor: Interactive PCoA plot calculated by Jaccard similarity index. Unweighted UniFrac Distance UniFrac is a metric for describing the similarity of a biological community, taking into account the relatedness of community members. Bioenv: UniFrac test metrics Emperor: Unweighted interactive PCoA plot Weighted UniFrac Distance Unweighted UniFrac removes the effect of low-abundance features in the calculation of principal components. Emperor: Weighted interactive PCoA plot of UniFrac. Tip Emperor Plots These plots are all interactive three-dimensional plots of an analysis using principal components . Customization You can customize Emperor plots, including altering the color of and shape points, axes, and other parameters. You can also export images from this visualization. Bioenv These plots are tables of tests and descriptive metrics. C. Taxonomic Diversity: Taxonomic diversity is at the heart of many analyses. We suggest consulting the QIIME taxonomy overview for a detailed explanation of how QIIME2 calculates taxonomy and additional features of QIIME2 you may wish to explore beyond the functionalities DNA Subway has included. Bar Plots An interactive stacked bar plot of species diversity. Dropdown menus allow you to color by seven taxonomic levels 1) kingdom, 2) phylum, 3) class, 4) order, 5), family, 6) genus, 7) species. Plots can be further arranged/filtered/sorted accoridng to characteristics in the sample metadata. You may also download images and data used to create the barpot visualization. Taxonomy A table indicating the identified \"features\", their taxa, and an indication of confidence. You can download and interact with any of the available plots. D. Calculate differential abundance Click on the 'Differential abundance' stop. Then click on the \"Submit new \"Differential abundance\" job\" link. Choose a metadata category to group by, and a level of taxonomy to summarize by. Then click &submit job {.interpreted-text role=\"guilabel\"}. Sample Data \"ubiome-test-data\" dataset: We recommend the following parameters: Group data by : CollectionMethod Level of taxonomy to summarize : 5 Tip Download the provided CSV files so that you can generate customized plots. DNA Subway Purple Line - Visualize data with PiCrust and PhyloSeq \u00b6 Under Development","title":"DNA Subway"},{"location":"dna_subway_guide/#dna-subway","text":"","title":"DNA Subway"},{"location":"dna_subway_guide/#goal","text":"DNA Subway is an educational bioinformatics platform developed by CyVerse. It bundles research-grade bioinformatics tools, high-performance computing, and databases into workflows with an easy-to-use interface. \"Riding\" DNA Subway lines, students can predict and annotate genes in up to 150kb of DNA (Red Line), identify homologs in sequenced genomes (Yellow Line), identify species using DNA barcodes and phylogenetic trees (Blue Line), examine RNA-Seq datasets for differential transcript abundance (Green Line), and analyze metabarcoding and eDNA samples using QIIME (Purple Line).","title":"Goal"},{"location":"dna_subway_guide/#prerequisites","text":"In order to complete this tutorial you will need access to the following services/software Prerequisite Preparation/Notes Link/Download CyVerse account You will need a CyVerse account to complete this exercise Register DNA Subway Access DNA Subway access is by request access Check or request access: CyVerse User Portal","title":"Prerequisites"},{"location":"dna_subway_guide/#dna-subway-basics-and-logging-in-to-subway","text":"DNA Subway is designed to be a classroom-friendly approach to bioinformatics. Unlike most CyVerse platforms, you can even use Subway without registering for a CyVerse account. We do encourage you to register however, only work from registered users can be saved. DNA Subway uses the same open-source bioinformatics tools used by researchers. See a complete list of the tools provided in the Subway pipelines. Some things to remember about the platform Registered user and Guest user account types DNA Subway access must be requested through the CyVerse user portal. You can check if you already have access, or request access by logging into the portal and visiting the My Services page. If DNA Subway is not listed, click on Available services to request access. Guest users will not have their worked saved beyond a single DNA Subway session. They are also disallowed from using one of the gene predictors (FGenesH) in the genomic annotation pipeline (Red Line). We suggest that every student using DNA Subway obtain their own account. Sample Datasets and reference data All Subway lines accept user data and also have sample data that can be immediately used to create a project. Red Line - Genome Annotation: Samples of plant and animal genomes that can be used in annotation projects Yellow Line - TARGeT Search for transposons and other DNA Sequences: Several model plant genomes Blue Line - DNA Barcoding and Phylogenetics: Sample sequence from plant, animal, fungal, and bacterial barcoding regions; human mitochondrial DNA sequence Green Line - RNA-Seq for differential expression: Sample high-throughput reads from RNA-Seq experiments If there is a reference data set or sample sequence you would like added, you can contact CyVerse using the DNA Subway Contact page Public and private projects - DNA Subway projects are private by default, but can be shared by making them public. Public projects are searchable and are a great way to share data or present analysis for grading in a classroom project.","title":"DNA Subway Basics and Logging in to Subway"},{"location":"dna_subway_guide/#logging-into-dna-subway-as-a-registered-user","text":"Access the DNA Subway website at https://dnasubway.cyverse.org/ If you wish to use DNA Subway as a guest click 'Enter As Guest' Note When using DNA Subway as a guest, you will be able to work only on the Red, Yellow, and Blue lines. Additionally, some Red Line functionalities will be disabled. Finally, after logging out, or a period of inactivity (>~ 30 min) you work will be discarded. Enter your CyVerse username and CyVerse password.","title":"Logging into DNA Subway as a registered user"},{"location":"dna_subway_guide/#logging-into-dna-subway-as-a-guest-user","text":"Access the DNA Subway website at https://dnasubway.cyverse.org/ ; click 'Enter as Guest'","title":"Logging into DNA Subway as a guest user"},{"location":"dna_subway_guide/#accessing-saved-private-and-public-dna-subway-projects","text":"DNA Subway projects are automatically saved for registered users. By default, Subway projects are private upon creation and visible only to you. You may make project public, in which case users will have the ability to view those projects, but may not edit those projects.","title":"Accessing Saved Private and Public DNA Subway Projects"},{"location":"dna_subway_guide/#accessing-private-projects","text":"Access the DNA Subway website at https://dnasubway.cyverse.org/ Upon login, you will see a listing of your private projects. Access the project by clicking the project title. From any DNA Subway page, you may access private projects by clicking the 'My Projects' button on the navigation menu on the left side of the page. Distinguishing Lines All projects in DNA Subway are associated with the color of their respective DNA Subway lines, and with a project ID number. You may see the comments and species associated with the project Deleting a project To delete a project, click the 'trash can' icon. Once deleted, all data related to that project will be lost and unrecoverable.","title":"Accessing Private Projects"},{"location":"dna_subway_guide/#accessing-public-projects","text":"Access the DNA Subway website at https://dnasubway.cyverse.org/ ; login to Subway or enter as a guest user. On the navigation menu on the left side of the screen, click 'Public Projects' Sorting and Search You can sort by project date or type, and you can search for a project by title, organism, or the name of the project owner. When searching, click the double arrow `` to search by your selected term.","title":"Accessing Public Projects"},{"location":"dna_subway_guide/#make-a-dna-subway-project-private-or-public","text":"Access the DNA Subway website at https://dnasubway.cyverse.org/ ; login to Subway. Access your selected project by clicking the project title. Under the 'Project Information' tab, toggle the project setting to 'Public' or 'Private' as desired.","title":"Make a DNA Subway Project Private or Public"},{"location":"dna_subway_guide/#walkthrough-of-dna-subway-red-line-genome-annotation","text":"Annotation adds features and information to a DNA sequence -- such as genes and their locations, structures, and functions. A good introduction to annotation can be found in the paper A beginner's guide to eukaryotic genome annotation . We'll also suggest the DNA Subway's primer on annotation evidence . This guide contains an explanation of basic functions for this line, as wellas exercises that might be used in the classroom. Some things to remember about the platform @@ -205,156 +164,115 @@ as exercises that might be used in the classroom.","title":"Walkthrough of DNA Subway Red Line - Genome Annotation"},{"location":"dna_subway_guide/#dna-subway-red-line-create-an-annotation-project-with-apollo","text":"transition away from Java DNA Subway is transitioning away from the original Java-based Apollo software as most popular web browsers will no longer support Java. The new Apollo is Java-free. Log-in to DNA Subway - unregistered users may 'Enter as Guest' Click 'Annotate a genomic sequence.' (Red Square); select the 'Web Apollo' version For 'Select Organism type' choose 'Animal' or 'Plant' and then select the appropriate subtype. The 'Select Organism' step will load appropriate sample sequences and will also adjust the models used in the de novo gene finding process. For 'Select Sequence Source' select a sample sequence. Apollo support Currently, the Java-free Apollo version of Subway does not support upload of a custom DNA Sequence. This feature is coming soon, but we will help you upload custom genomes/regions for your use in the classroom (Optional) If you have a GFF file of annotated features, you may load these import these annotations from the Green Line, or from a custom GFF file. Name your project and organism (required) and give a description if desired. Click 'Continue' to proceed.","title":"DNA Subway Red Line - Create an Annotation Project with Apollo"},{"location":"dna_subway_guide/#example-exercise-project-creation-arabidopsis-chri","text":"In this and subsequent steps, we will annotate a 75KB section of Arabidopsis chromosome I. 1. Log-in to DNA Subway - unregistered users may 'Enter as Guest'. 2. Click 'Annotate a genomic sequence.' (Red Square); select the 'Web Apollo' version. 3. For 'Select Organism type' choose 'Plant' and then 'Dicotyledon'. 4. from 'Select a sample sequence' chose 'Arabidopsis thaliana (mouse-ear cress) chr1, 75.00 kb'. 5. Provide your project with a title, then Click 'Continue.' Sequence You can view your DNA sequence by clicking the 'Sequence' link in the 'Project Information' tab at the bottom of the page.","title":"Example Exercise - Project Creation: Arabidopsis ChrI"},{"location":"dna_subway_guide/#dna-subway-red-line-find-and-mask-repetitive-dna","text":"One you have created a Red Line Project, you may begin the process of generating and assembling predictions and evidence that can be used to annotate genes. 1. Click 'RepeatMasker' 2. When 'RepeatMasker' turns 'green' and the icon displays a 'V' (view); click 'RepeatMasker' again to view results. ![repeat_results](./assets/dna_subway/repeat_results.png){width=\"300px\" height=\"200px\"}","title":"DNA Subway Red Line - Find and Mask Repetitive DNA"},{"location":"dna_subway_guide/#example-exercise-repeat-masking-arabodopsis-chri","text":"Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI, 75 kb Tool(s): RepeatMasker Concept(s): Non-coding DNA, sequence repeats, mobile genetic elements (transposons) Following the RepeatMasking steps for the Arabidopsis ChrI sample above, answer the following discussion questions : 1. How many hits were detected in your sample? 2. RepeatMasker reports the length of the repetitive sequences (Length) as well as the class (Attributes). - What is the average length of sequences identified as \"simple repeats\"? - What is the average length of sequences identified as \"low complexity\"? 3. What is the total percentage of repetitive DNA in your sequence? (Sum of the length of all repetitive sequence / sequence length (75 kb) Some Useful Definitions for Repetitive Sequences Simple repeats: 1-5bp repeats (e.g. repetitive dinucleotides 'AT' etc.) Low Complexity DNA: Poly-purine/ poly-pyrimidine stretches, or regions of extremely high AT or GC content. Processed Pseudogenes, SINES, Retrotranscripts: Non-functional RNAs present within genomic sequence. Transposons (DNA, Retroviral, LINES): Genetic elements which have the ability to be amplified and redistributed within a genome. Additional Investigation: In the results table under 'Attributes' each repeat sequence is labeled \"RepeatMasker#-XXX\" The '#' is the ordinal number of the hit, the XXX is the class of DNA element (e.g. \"Simple_repeat\" or \"Low_complexity\"). There are other types of repetitive elements such as transposons and pseudogenes (e.g. Helitron and COPIA) Use online resources to learn more: ( http://gydb.org/index.php/Main_Page ).","title":"Example Exercise - Repeat Masking: Arabodopsis ChrI"},{"location":"dna_subway_guide/#dna-subway-red-line-making-gene-predictions","text":"De novo gene predictors can be run on a sample sequence to generate predictions of gene structure and location based solely on the sequence nucleotides. Click on one or more gene prediction tools under the 'Gene Prediction' stop. to view the results table, click the gene predictor again once the indicator displays 'V' (view).","title":"DNA Subway Red Line - Making Gene Predictions"},{"location":"dna_subway_guide/#example-exercise-predict-genes-arabidopsis-chri","text":"Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI, 75 kb Tool(s): Augustus, FGenesH, Snap, tRNA Scan Concept(s): Genomic DNA, Gene Structure, Canonical sequences Following the gene prediction steps for the Arabidopsis ChrI sample above, answer the following discussion questions : Look at the 'Type' column in the gene prediction report. Considering the Augustus results, find the 6 th gene prediction (hint: AUGUSTUS006;ID=g6) and then locate the first mention of the term 'gene' and copy down the gene's 'start' (i.e. the starting basepair). Note the number of times you see the term 'exon' (i.e. number of exons predicted). Gene Predictor Exon Start (bp) Exon Stop (bp) Augustus 23456 23684 Augustus Augustus Augustus Augustus Based on the chart, did all the gene predictors yield genes starting at the same location? Did all the gene predictions have the same number of exons? Looking at the number of results returned by tRNA Scan, why are they so different from results made by other predictors? Are their places in the genome where tRNAs are more or less densely concentrated? Additional Investigation: Look for the background link at the bottom of the DNA Subway home page and review the section entitled 'Gene Finding'.","title":"Example Exercise - Predict Genes: Arabidopsis ChrI"},{"location":"dna_subway_guide/#dna-subway-red-line-visualize-predicted-genes-in-a-genome-browser","text":"A genome browser is an essential tool for visualization genomic data in context. The integrated JBrowse genome browser will allow you to see the visualized gene predictions generated so far. Click 'JBrowse' and allow browser to load. Zoom into a region (for example, paste the region 1:3740638..3749063 into the location window. Tip JBrowse will load multiple tracks of data. Since the entire genome is loaded, we recommend using the 'highlight a region' feature to help keep your place. You may also wish to record the coordinates you are viewing as shown in the coordinates window. You may also adjust the settings for a particular track by clicking on the track name. Right-click on any gene to view additional details about that gene. Examine gene details by double-clicking on a gene to select; then right-click to open the 'View Details' menu. To view more tracks, click on 'Full-Screen View' in the upper-left of the JBrowse window to see any additional tracks available. Useful Definitions Genome Browser: A GUI (Graphical User Interface) for viewing biological information. GBrowse (DNA Subway's Browser) is \"designed to view genomes. It displays a graphical representation of a section of a genome, and shows the positions of genes and other functional elements. It can be configured to show both qualitative data such as the splicing structure of a gene, and quantitative data such as microarray expression levels.\" [citation] Track: The individual regions of the display where information imported into the browser. For each type (or source) of information, there is usually an associated track.","title":"DNA Subway Red Line - Visualize predicted genes in a Genome Browser"},{"location":"dna_subway_guide/#example-exercise-visualize-predicted-genes-arabidopsis-chri","text":"Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI, 75 kb Tool(s): Local Browser (JBrowse) Concept(s): Gene orientation/structure, transposons, chromosome organization Following the gene browser steps for the Arabidopsis ChrI sample above, answer the following discussion questions (the locations of the genes are given in parentheses and can be pasted into the browser): Considering the following genes: BFN1-201 (1:3748591..3753070) SCAMP5-201 (1:3744556..3749035) STP1-201 (1:3776366..3780845) At1G11270.2 (1:3780041..3789000) Do all the gene predictors agree with each other? Which gene predictions seem to match the Ensemble genes most closely?","title":"Example Exercise - Visualize predicted genes: Arabidopsis ChrI"},{"location":"dna_subway_guide/#dna-subway-red-line-search-databases-using-blast","text":"DNA Subway searches customized versions of UniGene and UniProt that contain only validated plant proteins, and are free of predicted or hypothetical proteins. Click 'BLASTN'; wait until the flashing icon displays 'V' (view) Click 'BLASTN' again to view the results. Click 'BLASTX'; wait until the flashing icon displays 'V' (view). Click 'BLASTX' again to view the results. Click on 'JBrowse' and then click 'Full-screen View' in the upper-left. In the 'Available Tracks' menu, add the Blastn and Blastx tracks. Useful Definitions **Some Useful Definitions** BLAST: Basic Local Alignment Search Tool (BLAST) is an algorithm that search databases of biological sequence information (e.g. DNA, RNA, or Protein sequence) and return matches. The BLASTN program is specific to nucleotide data, and the BLASTX algorithm works with sequence data translated into amino acid sequences. UniGene: A database of transcript data, \"each UniGene entry is a set of transcript sequences that appear to come from the same transcription locus (gene or expressed pseudogene), together with information on protein similarities, gene expression, cDNA clone reagents, and genomic location.\" [citation] cDNA: DNA produced by reverse transcribing mRNA using reverse transcriptase. cDNAs are used to investigate mRNA within a biological sample. ESTs: \"Small pieces of DNA sequence (usually 200 to 500 nucleotides long) that are generated by sequencing either one or both ends of an expressed gene. The idea is to sequence bits of DNA that represent genes expressed in certain cells, tissues, or organs from different organisms.\" [citation]","title":"DNA Subway Red Line - Search Databases using BLAST"},{"location":"dna_subway_guide/#example-exercise-search-databases-using-blast-arabidopsis-chri","text":"Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI, 75 kb Tool(s): BLASTN, BLASTX, Upload Data Concept(s): RNA, cDNAs, ESTs, Biological Databases Following the BLAST steps for the Arabidopsis ChrI sample above, answer the following discussion questions (the locations of the genes are given in parentheses and can be pasted into the browser): Both BLASTN and BLASTX returns the 'Length' of your resulting matches. Do you notice differences in the average lengths of BLASTN and BLASTX matches? Explain. Under 'Type' both BLASTN and BLASTX returns 'match' and 'match_part.' 'Match' is describing the overall length of a single match, but individual significant matches may be fragmented, i.e. 'match_part.' Do BLASTN and BLASTX return 'match' and 'match_part' results in different frequencies? Explain.","title":"Example Exercise - Search Databases using BLAST: Arabidopsis ChrI"},{"location":"dna_subway_guide/#dna-subway-red-line-build-gene-models-using-apollo","text":"Apollo is an extension of JBrowse which allows the user to build and edit gene models. Apollo has a number of features but in this tutorial, we will give brief intro covering the conceptual steps. A. Import Blastn model to match for transcript length Blast searches are matched against UniGene(blastn) and UniProt(blasts). UniGen models are derived from cDNA and ESTs (transcriptome evidence) produced by experiment. Open Apollo and zoom into a region of interest (e.g. 1:3793981..3802033 ) Ensure at least the following tracks are selected (on): Augustus (and other gene predictors: FGenesH, SNAP, etc.) Blastn Double-click on the Blastn result, and drag this transcript into the yellow 'User-created Annotations' section. {width=\"400px\" height=\"250px\"} B. Select a scaffold model Use transcriptome evidence (UniGene - BLASTN) to select the best possible gene model for a scaffold. If no gene model exists or significantly reflects the UniGene model, use the UniGene model itself as a scaffold. Drag a plausible model into the yellow 'User-created Annotations' - in this case we will choose the Augustus model; double-click the Augustus model to select the entire model and drag into 'User-created Annotations'. Adjust the Augustus model to match the 5' and 3' configuration of the blastn model Delete the extraneous 5' exon (single-click to select; right-click to delete) Adjust the new 5' end to match the length of the blastn-derived transcript Adjust the 3' end of the Augustus-derived model (single-click to select; use your cursor/mouse to adjust the model length) C. Edit model for splice sites and variants Protein and EST data can be used to examine possible alternative transcripts. Proteins give clues to the actual length of the translated protein at that locus and its reading frame. Like full length cDNAs, ESTs give valuable information on transcript diversity. ESTs are generated by high throughput methods, and although the data may be fragmentary, it may capture biologically relevant information about splice variants. Turn on the blastx track Examine the additional evidence to consider making adjustments to your Augustus-derived model. If you wish to make additional isoforms of your gene: Double-click to select the entire Augustus-derived model Right-click on the model to duplicate Make adjustments to the model as desired You also have the option of adding additional EST evidence . For the Arabodopsis 75KB section, we have prepared a selection of EST data. You will need to close Apollo to load this data . Download the Arabidopsis ESTs for this region to your computer from this link Click on 'Upload Data'; under \"Add DNA data in FASTA format\" upload the EST file from the link in step 1. Click on 'User BLASTN' to align the ESTs to this section of the Arabidopsis genome Open 'Web Apollo'. The \"Blastn User\" track should be loaded. You may move this track to a convenient position on the browser While EST evidence is always incomplete, these sequences can help you determine features of the gene model. Learn More about Gene Evidence J.Craig Venter on ESTs \"Dynamic Gene\" Evidence animation (requires Flash) D. Determine translation start/stop sites After making your adjustments, you can confirm that your gene model(s) represents the longest possible transcripts: Double-click the model; right-click and select 'Set longest ORF' E. Compare gene model(s) with existing annotations After making your gene models you can compare them with existing annotations by turning on the 'Ensemble genes' track. In this case, our work confirms the first gene model made, but a potential isoform supported by blastx data is likely incorrect.","title":"DNA Subway Red Line - Build Gene Models using Apollo"},{"location":"dna_subway_guide/#example-exercise-build-gene-models-using-apollo-arabodopsis-chri","text":"Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI, 75 kb Tool(s): Apollo Concept(s): Synthesizing multiple lines of evidence Following the Apollo steps for the Arabidopsis ChrI sample above, answer the following discussion questions (the locations of the genes are given in parentheses and can be pasted into the browser): Try annotation of the following genes and take notes on your annotation ( right-click on the gene model, open the 'Information Editor' and scroll down to the comments section to enter comments). How do your annotations compare with the Ensembl annotations? Genes to try: AT1G11270.2 (1:3781511..3790520) STP1-201 (1:3776261..3785270) T28P6.11-201 (1:3762877..3764678)","title":"Example Exercise - Build Gene Models using Apollo: Arabodopsis ChrI"},{"location":"dna_subway_guide/#walkthrough-of-dna-subway-yellow-line-sequence-detection","text":"Genome prospecting uses a query sequence (DNA or protein of up to 10,000 base pairs/amino acids) to find related sequences in specific genomes or in a database. A major purpose of genome prospecting is to identify members of gene or transposon families. DNA Subway uses the TARGeT workflow, which integrates BLAST searches, multiple sequence alignments, and tree-drawing utilities. Yellow line uses TARGeT (Tree Analysis of Related Genes and Transposons) uses either a DNA or amino acid 'seed' query to: (i) automatically identify and retrieve gene family homologs from a genomic database, (ii) characterize gene structure and (iii) perform phylogenetic analysis. Due to its high speed, TARGeT is also able to characterize very large gene families, including transposable elements (TEs). [citation] Some things to remember about the platform Yellow Line will return sequences that would normally be excluded from a BLAST search of a genome (e.g. repetitive sequences, transposons). Yellow Line is implemented only for plant genomes","title":"Walkthrough of DNA Subway Yellow Line - Sequence Detection"},{"location":"dna_subway_guide/#dna-subway-yellow-line-create-a-yellow-line-project","text":"Log-in to DNA Subway - unregistered users may 'Enter as Guest' Click 'Prospect Genomes using TARGeT' (Yellow Square) Select a sample sequence, or paste in a sequence to search for. Note DNA Subway Yellow Line is only implemented to search a limited set of plant genomes. Provide your project with a title, then Click 'Continue'","title":"DNA Subway Yellow Line - Create a Yellow Line Project"},{"location":"dna_subway_guide/#example-exercise-project-creation-mping-mite-element-to-search-plant-genomes-for-an-active-transposon","text":"The mPing MITE element is an example of an active transposon in rice. Transposons are a major class of DNA elements that impact the function of the genome. Create a Yellow Line project following the steps above and using the mPing Mite Element (Oryza sativa/Rice)","title":"Example Exercise - Project Creation: mPing Mite element to search plant genomes for an active transposon"},{"location":"dna_subway_guide/#dna-subway-yellow-line-search-plant-genomes-with-target","text":"Click and select the genome(s) you wish to search and the click; 'Run' to search those genomes. Click the 'Alignment Viewer' button to view the results of the search as a multiple alignment. Click the 'Tree Viewer' button to view a tree that will group results by similarity. Viewer Tips Alignment Viewer Generates an alignment of all search results Tree Viewer Displays the results of sequence matches as a tree, grouped by sequence similarity yellow_tree Useful Definitions Transposons (DNA, Retroviral, LINES): Genetic elements which have the ability to be amplified and redistributed within a genome. Non-autonomous transposons: Transposons which lack an active transposase gene, thus requiring help from another transposon to move. Autonomous transposons: Transposons which have a functional transposase and can move within the genome.","title":"DNA Subway Yellow Line - Search Plant Genomes with TARGeT"},{"location":"dna_subway_guide/#example-exercise-search-plant-genomes-mping-mite-element","text":"After loading the mPing Mite Element as the query, search the Oryza Sativa genome, and examine the results in the Alignment and Tree Viewers. Repeat this analysis with a new project using the Ping transposase gene and the Ping Transposase protein.","title":"Example Exercise - Search Plant Genomes: mPing Mite element"},{"location":"dna_subway_guide/#walkthrough-of-dna-subway-blue-line-dna-barcoding-and-phylogenetics","text":"You can analyze relationships between DNA sequences by comparing them to a set of sequences you have compiled yourself, or by comparing your sequences to other that have been published in database such as GenBank (National Center for Biotechnology Information). Generating a phylogenetic tree from DNA sequences derived from related species can also allow you to draw inferences about how these species may be related. By sequencing variable sections of DNA (barcode regions) you can also use the Blue Line to help you identify an unknown species, or publish a DNA barcode for a species you have identified, but which is not represented in published databases like GenBank. Some things to remember about the platform Wet lab protocols and other resources are available at http://dnabarcoding101.org/ The DNA Barcoding 101 site also contains information on low-cost sequencing for U.S.-based educators. Sample Data How to use provided sample data In this guide, we will use a mosquito dataset that includes DNA sequences isolated from mosquito larvae collected from Virginia's Shenandoah Valley ( \"Mosquito dataset\" ). There is a complete two-hour classroom bioinformatics lab with detailed instructions for instructors and students on QUBES hub here . Where appropriate, a note (in this orange colored background) in the instructions will indicate which options to select to make use of this provided dataset. Sample data citation : Williams, J., Enke, R. A., Hyman, O., Lescak, E., Donovan, S. S., Tapprich, W., Ryder, E. F. (2018). Using DNA Subway to Analyze Sequence Relationships. (Version 2.0). QUBES Educational Resources. doi:10.25334/Q4J111 Video Course Here is a video series on analyzing data with DNA Subway using the above mosquito dataset and lesson: Tip See a Course Source paper with protocols and recommendations for implementing a Barcoding CURE (course-based undergraduate research experience): CURE-all: Large Scale Implementation of Authentic DNA Barcoding Research into First-Year Biology Curriculum .","title":"Walkthrough of DNA Subway Blue Line - DNA Barcoding and Phylogenetics"},{"location":"dna_subway_guide/#dna-subway-blue-line-create-a-barcoding-project","text":"Log-in to DNA Subway - unregistered users may 'Enter as Guest'. !!! Note Only registered users submitting novel, high-quality sequences will be able to submit sequence to GenBank Choose a project type: - Phylogenetics : build phylogenetic trees from any DNA, protein, or mtDNA sequence) - Barcoding : DNA Barcoding for plants (rbcL), animals (COI), bacteria (16S), and fungi (ITS). Sample Data \"Mosquito\" dataset: Select COI . 3. Under 'Select Sequence Source' select a sequence buy uploading either a FASTA file or AB1 Sanger sequencing tracefile; pasting in a sequence in FASTA format, or selecting and importing a trace file from DNALC. If you do not have a file, you may select any of the available sample sequences. Sample Data \"Mosquito\" dataset: From Select a set of sample sequences select Intro to Barcoding Bioinformatics: Mosquitoes . 4. Name your project, and give a description if desired; click 'Continue.'","title":"DNA Subway Blue Line - Create a Barcoding Project"},{"location":"dna_subway_guide/#dna-subway-blue-line-view-and-clean-barcoding-sequence-data","text":"A. View Sequencing Trace File If you provided AB1 trace files, or imported files from DNALC, you will be able to view the sequence electropherogram. Click 'Sequence Viewer' to show a list of your sequences. Click on a sequence name to show the sequences' trace file. B. Trim sequence, reverse complement and pair By default, DNA Subway assumes that all reads are in the forward orientation, and displays an 'F' to the right of the sequence. If any sequence is not in that orientation, click the \"F\" to reverse compliment the sequence. The sequence will display an \"R\" to indicate the change. Click 'Sequence Trimmer.' Click 'Sequence Trimmer' again to examine to changes made in the sequence Click 'Pair Builder.' Select the check boxes next to the sequences that represent bidirectional reads of the same sequence set. Alternatively Select the 'Auto Pair' function and verify the pairs generated. Sample Data \"Mosquito\" dataset: Click Try Auto Pairing . One pair of horsefly sequences and 4 pairs of mosquito sequences will be created. Finally, click Save . As necessary, Reverse Compliment sequences that were sequenced in the reverse orientation by clicking the 'F' next to the sequence name. The 'F' will become an 'R' to indicate the sequence has been reverse complimented. Click Save to save the created pairs. C. Build a consensus sequence This step remove poor quality areas at the 5' and/or 3' ends of the consensus sequence. Click on \"Trim Consensus.\" Once the job is ready to view, click \"Trim Consensus\" again to view the results. Scroll left and right in the consensus editor window to identify what string of nucleotides from the consensus sequence you want to trim. Click on the last consensus sequence nucleotide that you want to trim. A red line will indicate what nucleotides will be removed from the consensus sequences. Click Trim . A new \"Consensus Editor\" window will pop up displaying the trimmed sequences. Sample Data \"Mosquito\" dataset: All of the sequences in this dataset benefit from trimming. Follow the steps above to trim sequences. We recommending trimming at the first and last \"grey\" (lower quality) nucleotide on the right and left ends.","title":"DNA Subway Blue Line - View and Clean Barcoding Sequence Data"},{"location":"dna_subway_guide/#dna-subway-blue-line-find-matches-with-blast","text":"DNA Subway Blue Line will search a local copy of a BLAST databases to check for published matches in GenBank. Tip At the end of the BLAST results page, you can see the latest update to the DNA Subway BLAST database. Click 'BLASTN' then click the 'BLAST' link to BLAST the sequence of interest. When the search is completed a 'View' link will appear. Examine the BLAST matches for candidate identification. Clicking the species name given in the BLAST hit will also give additional information/photos of the listed species. If desired, select the check box next to any hit, and click &Add BLAST hits to project to add selected sequences to your project. Sample Data \"Mosquito\" dataset: We recommend performing a BLASTN search for all samples and saving the top 2 matches to your project for additional analysis (as in Step 3).","title":"DNA Subway Blue Line - Find Matches with BLAST"},{"location":"dna_subway_guide/#dna-subway-blue-line-add-reference-data","text":"Depending on the project type you have created, you will have access to additional sequence data that may be of interest. For example, if you are doing a DNA barcoding project using the rbcL gene, samples of rbcL sequence from major plant groups (Angiosperms, Gymnosperms, etc.) will be provided. Choose any data set to add it to your analysis; you will be able to include or exclude individual sequences within the set in the next step. Click 'Reference Data.' Select sequences of your choice. Click Add ref data to add the data to your project. Sample Data \"Mosquito\" dataset: Select Common insects and then click &Add ref data .","title":"DNA Subway Blue Line - Add Reference Data"},{"location":"dna_subway_guide/#dna-subway-blue-line-build-a-multiple-sequence-alignment-and-phylogenetic-tree","text":"A. Build a multiple sequence alignment and phylogenetic tree Click 'Select Data.' Select any and all sequences you wish to add to your tree. Sample Data \"Mosquito\" dataset: We suggest first adding your \\\"user data\\\" and building an alignment and tree. You can return to this step later to build additional trees. Once Selected, click Save Selections . Follow the rest of the steps in this section and section B to create your tree. Click Save Selections to select data Click 'MUSCLE.' to run the MUSCLE program. Click 'MUSCLE' again to open the sequence alignment window. Examine the alignment and then select the Trim Alignment button in the upper-left of the Alignment viewer'. B. Build phylogenetic tree Click 'PHYLIP NJ' and then click again to examine a neighbor-joining tree Click 'PHYLIP ML' and then click again to examine a maximum-likelihood tree Sample Data \"Mosquito\" dataset: We suggest setting \"horsefly\" as outgroup for both trees.","title":"DNA Subway Blue Line - Build a Multiple Sequence Alignment and Phylogenetic Tree"},{"location":"dna_subway_guide/#walkthrough-of-dna-subway-green-line-kallistosleuth-rna-seq","text":"The Green Line runs within CyVerse DNA Subway and leverages powerful computing and data storage infrastructure and uses the supercomputer cluster to provide a high performance analytical platform with a simple user interface suitable for both teaching and research. is a quick, highly-efficient software for quantifying transcript abundances in an RNA-Seq experiment. Even on a typical laptop, Kallisto can quantify 30 million reads in less than 3 minutes. Integrated into CyVerse, you can take advantage of CyVerse DNA Subway to process your reads, do the Kallisto quantification, and analyze reads with the Kallisto companion software in an R-Shiny app. Some things to remember about the platform You must be a registered CyVerse user to use Green Line. The Green Line was designed to make RNA-Seq data analysis \"simple\". However, we ask that users thoughtfully decide what \"jobs\" they want to submit. Each user is limited to a maximum of 4 concurrent jobs running on Green Line . A single Green Line project may take a week to process since HPC computing is subject to queues which hundreds of other jobs may be staging for. Additionally these systems undergo regular maintenance and are subject to periodic disruption. Note New, faster Green Line Green Line is now running on Jestream Cloud . This should greatly reduce queue times (The entire running time for this tutorial is about 60 minutes). We have designed Green Line for a lower number of concurrent users (<50), and still recommend teaching using jobs you have made public, and only running the entire workflow when you are working with novel data. Please let us know about your experience: send feedback . Important: Discontinued Support for Tuxedo Workflow The Tuxedo workflow previously implemented for the Green Line will has been removed in June 2019 . Data and previously analyzed results will still be available on the CyVerse Data Store, however it is not possible to execute new analyses which include Tuxuedo. Sample Data How to use provided sample data In this guide, we will use an RNA-Seq dataset ( \"Zika infected hNPCs\" ). This experiment compared human neuroprogenetor cells (hNPCs) infected with the Zika virus to non-infected hNPCs. You can read more about the experimental conditions and methods in this reference . Where appropriate, a note (in this orange colored background) in the instructions will indicate which options to select to make use of this provided dataset. Sample data citation : Yi L, Pimentel H, Pachter L (2017) Zika infection of neural progenitor cells perturbs transcription in neurodevelopmental pathways. PLOS ONE 12(4): e0175744. reference . Video Course Here is a video series on analyzing data with DNA Subway using the above Zika dataset and lesson:","title":"Walkthrough of DNA Subway Green Line: Kallisto/Sleuth RNA-Seq"},{"location":"dna_subway_guide/#dna-subway-green-line-kallistosleuth-create-an-rna-seq-project-to-examine-differential-abundance","text":"A. Create a project in Subway Log-in to - unregistered users may NOT use Green Line. Click on the Green \"Next Generation Sequencing\" square to start a Green Line project. For 'Select Project Type' select either \"Single End Reads\" or \"Paired End Reads\". Sample Data \"Zika infected hNPCs\" dataset: Select Paired End Reads 4. For 'Select an Organism' select a species and genome build. Sample Data \"Zika infected hNPCs\" dataset: Select Homo sapiens - Ensembl 78 GrCh38 5. Enter a project title, and description; click 'Continue'. Tip If you don't see a desired species/genome contact us to have it added. B. Upload Read Data to CyVerse Data Store The sequence read files used in these experiments are too large to upload using the Subway internet interface. You must upload your files (either .fastq or .fastq.gz) directly to the CyVerse Data Store. Upload your reads to the CyVerse Data Store using Cyberduck. See instructions: Data Store Guide . Note This step is not directly connected with DNA Subway. You can use any data uploaded to the CyVerse Data Store. Data Limit There is a limit of 6GB per file for samples on Green Line. For larger file sizes, you may wish to use the Kallisto tools in the CyVerse Discovery Environment. See the for more information.","title":"DNA Subway Green Line: Kallisto/Sleuth - Create an RNA-Seq Project to Examine Differential Abundance"},{"location":"dna_subway_guide/#dna-subway-green-line-kallistosleuth-manage-data-and-check-quality-with-fastqc","text":"A. Select and pair files Click on the \"Manage Data\" step: this opens a Data store window that says \"Select your FASTQ files from the Data Store\" (if you are not logged in to CyVerse, it will ask you to do so). Click on the folder that matches your CyVerse username and Navigate to the folder where your sequencing files are located. Sample Data \"Zika infected hNPCs\" dataset: Select Sample Data . Select the sequencing files you want to analyze (either .fastq or .fastq.gz format). Sample Data \"Zika infected hNPCs\" dataset: You will be presented with the following 8 files; check-select all of the files and click the + Add files button: SRR3191542_1.fastq.gz SRR3191542_2.fastq.gz SRR3191543_1.fastq.gz SRR3191543_2.fastq.gz SRR3191544_1.fastq.gz SRR3191544_2.fastq.gz SRR3191545_1.fastq.gz SRR3191545_2.fastq.gz The SRR3191542 and SRR3191543 files are 2 replicates (paired-end) of the uninfected cells and the SRR3191544 and SRR3191545 file are from the Zika infected cells. If working with paired-end reads, click the Pair Mode OFF button to toggle to on; check each pair of sequencing files to pair them. Sample Data \"Zika infected hNPCs\" dataset: Right reads end in \"_1\" and left reads end in \"_2\". Click the Pair Mode OFF button to turn pairing on, and check-select each of the paired samples (e.g. SRR3191543_1.fastq.gz and SRR3191543_2.fastq.gz). B. Check sequencing quality with FastQC It is important to only work with high quality data. is a popular tool for determining sequencing quality. Tip This step takes place in the same Manage data window as the steps above. Once files have been loaded, in the 'Manage Data' window, click the 'Run' link in the 'QC' column to run FastQC. Note There is a limit of 4 concurrent jobs. These jobs should take less than 20 minutes to complete (depending on file size) and you may need to let several jobs finish before proceeding. If you have previously processed reads for quality, you can skip the FastQC step. 2. One the jobs are complete, click the 'View' link to view the results. Tip You can see a description and explanation of the FastQC report on the CyVerse Learning Center and a more detailed set of explanations on the website.","title":"DNA Subway Green Line: Kallisto/Sleuth - Manage Data and Check Quality with FASTQC"},{"location":"dna_subway_guide/#dna-subway-green-line-kallistosleuth-trim-and-filter-reads-with-fastx-toolkit","text":"Raw reads are first \"quality trimmed\" (remove poor quality bases off the end(s) of a read) and then are \"quality filtered\" (filter out entire poor quality reads) prior to aligning to the transcriptome. After trimming and filtering, FastQC is run on the trimmed/filtered files. Click \"FastX ToolKit\" to open the FastX Toolkit panel for all your data. For each file, under 'Basic', Click 'Run' to filter the reads using default parameters or click 'Advanced' to run with desired parameters; repeat this process for all the FASTQ files in your dataset. Sample Data \"Zika infected hNPCs\" dataset: The quality of the reads in this dataset is relatively good. You can skip the FastX Toolkit step for this dataset . Tip The 'Basic' setting for FastX Toolkit uses the same settings as the defaults in the 'Advanced' run: quality_trimmer: minimum quality : 20 quality_trimmer: minimum trimmed read length : 20 quality_filter: minimum quality : 20 quality_filter: minimum quality : 50 Once the job completes, click the 'View' link to view a generated FastQC report. Since you may trim reads multiple times to achieve the desired quality of data record the job IDs (e.g. fx####) that you wish to use in the subsequent steps.","title":"DNA Subway Green Line: Kallisto/Sleuth - Trim and Filter Reads with FastX Toolkit"},{"location":"dna_subway_guide/#dna-subway-green-line-kallistosleuth-quantify-reads-with-kallisto","text":"Kallisto uses a 'hash-based' pseudo alignment to deliver extremely fast matching of RNA-Seq reads against the transcriptome index (which was selected when you created your Green Line project). A Kallisto analysis must be run for each mapping of RNA-Seq reads to the index. In this tutorial, we have 12 fastQ files (6 pairs), so you will need to launch 6 Kallisto analyses. The Science Behind Kallisto You can find a detailed video series on the science behind the Kallisto software and pseudoalignment: [YouTube](https://www.youtube.com/playlist?list=PL-0S9LiUi0vhjynujVZw34RKmUo6vPmVd). Click the \"Quantification\" step and enter a sample and condition name for each of your samples. You will typically have several replicates (at least 3 minimum) for each sample. For your condition, our implementation of the Kallisto/Sleuth workflow supports two conditions . Warning When naming your samples and conditions, avoid spaces and special characters (e.g. !#$%^&/, etc.). Also be sure to be consistent with spelling. Sample Data \"Zika infected hNPCs\" dataset: We suggest the following names for this dataset: Left/Right Pair Sample name Condition SRR3191542_1.fastq.gz SRR3191542_2.fastq.gz Mock1-1 Mock SRR3191543_1.fastq.gz SRR3191543_1.fastq.gz Mock2-1 Mock SRR3191544_1.fastq.gz SRR3191544_2.fastq.gz ZIKV1-1 Zika SRR3191545_1.fastq.gz SRR3191545_2.fastq.gz ZIKV2-1 Zika After naming the samples and conditions, click the Submit button to submit a job. Typically, within ~1 minute you will be provided with a job number. The job will be entered into the queue at the TACC Stampede supercomputing system. You can come back and click the Quantification stop to see the status of the job. The indication for the quantification stop will show \"R\" (running) while the job is running. Sample Data \"Zika infected hNPCs\" dataset: Under parameters uncheck the Build pseudo-bam files option. Tip You can select some of the advanced options for your Kallisto job by clicking the \"Parameters\" link in the Quantification stop. See more about these advanced parameters in the Kallisto manual .","title":"DNA Subway Green Line: Kallisto/Sleuth - Quantify reads with Kallisto"},{"location":"dna_subway_guide/#dna-subway-green-line-kallistosleuth-visualize-data-using-igv","text":"In the \"View Results\" steps you have access to alignment visualizations, data download, and interactive visualization of your differential expression results. Click the \"View results\" step and choose one of the following options: IVG - Integrated Genome Viewer Tip IGV visualization will only be possible if you have built pseudo-bam files in the Kallisto step. Click the icon in the \"IGV\" column to view a visualization of your reads pseudoaligned to the reference transcriptome. You will need to click the Make it public button (and possibly be re-directed to the CyVerse Discovery Environment). After making the data \"public\" which allows DNA Subway to access your files on the CyVerse Data Store, you must also select a memory size to launch this Java application. If you are not sure of which value to select, use the default 750MB option. Warning Using IGV requires Java software. Java is increasingly unsupported for security reasons on the internet. Java Help Java must be available and enabled in your Internet browser to use the IGV function. Java frequently is the source of security vulnerabilities and so its not uncommon to experience configuration issues due to safety. Follow the tips below to configure Java for your computer. Alternatively, you can use the Download link (see instructions in the section below) to download your data (you will need the .bam and .bam.bai files) and download and install yourself. Internet Browser We highly recommend using Firefox as your browser for DNA Subway. - Verify your Java availability for your browser: Java test - Java must be enabled in your browser Java Configuration Open the Java control panel on your computer. (On Mac, open System Preferences > Java. On PC, open Control Panel > Programs > Java.) Click the Security tab and check \"Enable Java in the browser\" and set the security level for applications to \"high\". Add \" http://dnasubway.cyverse.org \" and \" http://gfx.dnalc.org \" to the \"Exception Site List\" in the Java Security tab. Download Data - Abundance Click the folder icon to be redirected to the CyVerse Discovery Environment (you may be required to log in). You will be directed to all outputs from you Kallisto analysis. You may preview them in the Discovery Environment or use the path listed to download the files using Cyberduck (see Data Store Guide ). A tab-separated file of abundances for each sequence pair is available at the download link.","title":"DNA Subway Green Line: Kallisto/Sleuth- Visualize data using IGV"},{"location":"dna_subway_guide/#dna-subway-green-line-kallistosleuth-visualize-data-using-sleuth","text":"Differential analysis - Shiny App Click the \"Sleuth R Shiny\" link to launch an interactive window which contains data and graphics from your analysis. R Shiny App Walkthrough The R Shiny App allows you to explore your differential expression results as generated by the . We will cover highlights to for each menu in the app. Data Transfer Timings It can take a few minutes for data to be transferred to the R Shiny server after the quantification step completes. If R Shiny does not load, try again in a few minutes. If you still have an issue, use the link and include your project number in the feedback form. Results Menu This menu is an interactive table of your results. You can choose which columns to display in the table using the checkboxes on the left of the screen. Several important values selected by default include: Target_id : This is the name of the transcript (gene) from the selected reference transcriptome. qval : This is a corrected (for multiple testing) p-value indicating the significance test of differential abundance. Lower numbers indicate greater significance. b : This is an estimate of the fold change between the conditions ext_gene : If available, these are gene names pulled from Ensemble Tip Click the Download button to download these results. Bootstrap This menu will display a box plot that indicates the difference in expression between conditions. The box plots themselves indicate variation between replicates as estimated by bootstrap sampling of the reads. A dropbox enables you to select any transcript. Clicking the \"Show genes\" will load alternative gene names if available. Tip Right-click a graph to download this and other images. PCA This graph displays principle components of each of the conditions/replicates. In general replicates of the same condition should cluster closely together. Volcano Plot This scatter plot displays all transcripts colored by significance of differential abundance. You may also use menu on the left of the screen to highlight specific genes/transcripts or previously set filters from the results menu. Loadings This barplot indicates which genes/transcripts explain most of the variance computed in the principle components analysis. Heatmap This heatmap gives a measure of the similarity between the possible comparison of the samples and their replicates. Summary : Together, Kallisto and Sleuth are quick, powerful ways to analyze RNA-Seq data.","title":"DNA Subway Green Line: Kallisto/Sleuth- Visualize data using Sleuth"},{"location":"dna_subway_guide/#walkthrough-of-dna-subway-purple-line-beta-testing-documentation","text":"BETA RELEASE The Purple line is in beta release. Please send feedback to DNALC Admin . The Purple Line provides the capability for analysis of microbiome and eDNA (environmental DNA) by implementing a simplified version of the QIIME 2 (pronounced \"chime two\") workflow. Using the Purple Line, you can analyze uploaded high throughput sequencing reads to identify species in microbial or environmental DNA samples. Metabarcoding uses high-throughput sequencing to analyze hundreds of thousands of DNA barcodes from complex mixtures of DNA. In a typical experiment, DNA is isolated from sterile swabs or material taken from different environmental locations or conditions. PCR is used to amplify a variable region, such as COI, or 12S or 16S ribosomal RNA genes, and sequence reads identify the variety and abundance of species from different samples. The analysis requires specialized software, such as QIIME 2. The Purple Line integrates sequence data and metadata imported from CyVerse's Data Store, demultiplexing of samples, quality control, and taxonomic identification and quantitation. Once sequences are analyzed, the results can be visualized to allow comparisons between samples and different conditions summarized in the metadata. Some things to remember about the platform You must be a registered CyVerse user to use Purple Line (register for a CyVerse account at user.cyverse.org ). The Purple line was designed to make microbiome/eDNA data analysis \"simple\". However, we ask that users very carefully and thoughtfully decide what \"jobs\" they want to submit. A single Purple Line project may take hours to process since HPC computing is subject to queues which may support hundreds of other jobs. These systems also undergo regular maintenance and are subject to periodic disruption. DNA Subway implements the QIIME 2 software. This software is in continual development. Our version may not be the most current, and our documentation and explanation is not meant to replace the full QIIME 2 documentation . We have made design decisions to create a straightforward classroom-friendly workflow. While this Subway Line does not have all possible features of QIIME 2, we purpose to cover important concepts behind microbiome and eDNA analysis. You may work with up to 96 samples (e.g. 192 paired files or 96 single read files) in a Purple line project. Sample Data: How to use provided sample data In this guide, we will use a microbiome dataset ( \"ubiome-test-data\" ) collected from various water sources in Montana (down-sampled and de-identified).Where appropriate, a note (in this orange colored background) in the instructions will indicate which options to select to make use of this provided dataset.","title":"Walkthrough of DNA Subway Purple Line (beta testing documentation)"},{"location":"dna_subway_guide/#dna-subway-purple-line-metadata-file-and-sequencing-prerequisites","text":"If you are generating data for a project (i.e. sequencing samples), you will need to provide the sequencing data (fastq files) as well as a metadata file that describes the data contained in these sequencing files. This metadata must conform to strict guidelines, or analyses will fail. QIIME 2 metadata is stored in a TSV (tab-separated values) file. These files typically have a .tsv or .txt file extension, though it doesn't matter to QIIME 2 what file extension is used. TSV files are simple text files used to store tabular data, and the format is supported by many types of software, such as editing, importing, and exporting from spreadsheet programs and databases. Thus, it's usually straightforward to manipulate QIIME 2 metadata using the software of your choosing. If in doubt, we recommend using a spreadsheet program such as Microsoft Excel or Google Sheets to edit and export your metadata files. Handling Project Metadata Before you create your project, you will have generated metadata (as described above) for your project. You have two options for preparing this metadata to ensure that it conforms to the required QIIME2 parameters. The file must be validated (which you can do on your own or using Subway). If there are errors in your file (this is common), they must be fixed. Formatting Your Metadata Leading and trailing whitespace characters If any cell in the metadata contains leading or trailing whitespace characters (e.g. spaces, tabs), those characters will be ignored when the file is loaded. Thus, leading and trailing whitespace characters are not significant, so cells containing the values 'gut' and ' gut' are equivalent. This rule is applied before any other rules described below ID column The first column MUST be the ID column name (i.e. ID header) and the first line of this column should be #SampleID or one of a few alternative. - Case-insensitive: id; sampleid; sample id; sample-id; featureid; feature id; feature-id. - Case-sensitive: #SampleID; #Sample ID; #OTUID; #OTU ID; sample_name Sample IDs For the sample IDs, there are some simple rules to comply with QIIME 2 requirements: IDs may consist of any Unicode characters, with the exception that IDs must not start with the pound sign (#), as those rows would be interpreted as comments and ignored. IDs cannot be empty (i.e. they must consist of at least one character). IDs must be unique (exact string matching is performed to detect duplicates). At least one ID must be present in the file. IDs cannot use any of the reserved ID column names (the sample ID names, above). The ID column can optionally be followed by additional columns defining metadata associated with each sample or feature ID. Metadata files are not required to have additional metadata columns, so a file containing only an ID column is a valid QIIME 2 metadata file. Column names May consist of any Unicode characters. Cannot be empty (i.e. column names must consist of at least one character). Must be unique (exact string matching is performed to detect duplicates). Column names cannot use any of the reserved ID column names. Column values May consist of any Unicode characters. Empty cells represent missing data. Note that cells consisting solely of whitespace characters are also interpreted as missing data. QIIME 2 currently supports categorical and numeric metadata columns. By default, QIIME 2 will attempt to infer the type of each metadata column: if the column consists only of numbers or missing data, the column is inferred to be numeric. Otherwise, if the column contains any non-numeric values, the column is inferred to be categorical. Missing data (i.e. empty cells) are supported in categorical columns as well as numeric columns. For more details, and for how to define the nature of the data when needed, see the QIIME 2 metadata documentation . Working with an existing metadata file Tip If you have your own metadata file, it will still need to be validated once uploaded to DNA Subway. Using a spreadsheet editor, create a metadata sheet that provides descriptions of the sequencing files used in your experiment. Export this file as a tab-delimited .txt or .tsv file. following the QIIME 2 metadata documentation]( https://docs.qiime2.org/2019.10/tutorials/metadata/ ) recommendations. (Optional: if you using your own metadata file you can validate it using DNA Subway and or online QIIME2 validator Keemei ). Tip See an example metadata file used for our sample data here: metadata file . Click the Download button on the linked page to download and examine the file. ( Note : This is an Excel version of the metadata file, you must save Excel files as .TSV (tab-separated) to be compatible with the QIIME 2 workflow.) Creating a metadata file using DNA Subway See DNA Subway Purple Line - Metadata and QC section C.","title":"DNA Subway Purple Line - Metadata file and Sequencing Prerequisites"},{"location":"dna_subway_guide/#dna-subway-purple-line-create-a-microbiome-analysis-project","text":"A. Create a project in Subway Log-in to DNA Subway (unregistered users may NOT use Purple Line, register for a CyVerse account at user.cyverse.org . Click the purple square (\"Microbiome Analysis\") to begin a project. For 'Select Project Type' select either Single End Reads or Paired End Reads Sample Data \"ubiome-test-data\" dataset: Select Single End Reads For 'Select File Format' select the format the corresponds to your sequence metadata. Sample Data \"ubiome-test-data\" dataset: Select Illumina Casava 1.8 Tip Typically, microbiome/eDNA will be in the form of multiplexed FastQ sequences. We support the following formats: Illumina Casava 1.8 Enter a project title, and description; click Continue . B. Upload read data to CyVerse Data Store The sequence read files used in these experiments are too large to upload using the Subway interface. You must upload your files ( Note : Only .fastq.gz files are accepted) directly to the CyVerse Data Store: Upload your FASTQ sequence reads; Note : Only .fastq.gz files are accepted. Sample metadata file (.tsv or .txt formatted according to QIIME 2 Metadata documentation ) to the CyVerse Data Store using Cyberduck. See instructions: CyVerse Data Store Guide . (Optional: You can edit and change metadata using the Subway interface in the [Manage data]step once the project is created.)","title":"DNA Subway Purple Line - Create a Microbiome Analysis Project"},{"location":"dna_subway_guide/#dna-subway-purple-line-metadata-and-qc","text":"A. Select files using Manage Data Click on the 'Manage data stop: this opens a window where you can add your FASTQ (up to 192 paired files or 96 single read files) and metadata files. Click +Add from CyVerse to add the FASTQ files uploaded to the CyVerse Data Store. Select your files and then click Add selected files {.interpreted-text role=\"guilabel\"} or Add all FASTQ files in this directory {.interpreted-text role=\"guilabel\"} as appropriate. Note : Only .fastq.gz files are accepted. Sample Data \"ubiome-test-data\" dataset: Navigate to: Shared Data > SEPA_microbiome_2016 > ubiome-test-data and click Add all FASTQ files in this directory 2. To add your metadata file you may use one of three options: - Add from CyVerse : Add a metadata file you have uploaded to CyVerse Data store - Upload locally : Directly upload a metadata file from your local computer - Create New : Create a new metadata file using DNA Subway Creating a metadata file using DNA Subway You can create a metadata file using DNA Subway. Creating the file step-by-step will help you to avoid metadata errors. Be sure you have consulted the QIIME 2 documentation so you can anticipate what the required fields are. To use this feature under in the 'Manage data' step under 'Metadata Files' click Create new Sample IDs and adding/removing samples These are unique IDs for each of your samples. All metadata files must have a column called #SampleID . Click +Add samples to add additional rows. In the Subway form, these will be unique, arbitrary names (roughly corresponding to well-positions on a 96-well microplate). You can change these (including pasting in sample names from an existing spreadsheet). Right-clicking on a row number allows you to remove or insert rows. Adding columns, managing sample descriptions and data types The very last column must be a sample description. You can click the arrow on the right of this column to add a new column (which will be added to the left). Column names must be unique, must not be empty, cannot contain whitespace, can contain a maximum of 32 characters, cannot match a reserved column name. Notice that when you click on a column name it is colored -pink for columns that have numeric data (e.g. measurements) and cyan for everything else (e.g. categorical descriptions in the form of words (i.e. strings)). Clicking a column name will allow you to change its type. Handling errors If you violate one of the rules for metadata formatting, the entry will turn red. Consult the help and or the QIIME 2 documentation to correct the error. Click Save to save your metadata file, and close the window. Sample Data \"ubiome-test-data\" dataset: Click Add from CyVerse Navigate to: Shared Data > SEPA_microbiome_2016 > ubiome-test-data Select the mappingfile_MT_corrected.tsv and then click Add selected files . 3. As needed, you can edit or rename your metadata file. Before proceeding, you must validate your metadata file. To validate, click the \"validate\" link to the right of the metadata file you wish to check. Once the validation completed, click Run to proceed. If you have errors, you will be presented with an Edit button so that you can return to the file and edit. B. Demultiplex reads At this step, reads will be grouped according to the sample metadata. This includes separating reads according to their index sequences if this was not done prior to running the Purple Line. For demultiplexing based on index sequences, the index sequences must be defined in the metadata file. Note Even if your files were previously demultimplexed (as will generally be the case with Illumina data) you must still complete this step to have your sequence read files appropriately associated with metadata. 1. Click the 'Demultiplex reads' and choose a number of reads to sample. When the job has completed click Demultiplexing Summary to view your results. In 'Random sequences to sample for QC', enter a value (1000 is recommended), Sample Data \"ubiome-test-data\" dataset: Use the default of 1000 sequences 2. When demultiplexing is complete, you will generate a file (.qzv) click this link to view a visualization and statistics on the sequence and metadata for this project. Tip Several jobs on Purple Line will take several minutes to an hour to complete. Each time you launch one of these steps you will get a Job ID. You can click the View job info {.interpreted-text role=\"guilabel\"} button to see a detailed status and diagnostic/error messages. If needed There is a [stop this job]{.title-ref} link at the bottom of the info page to cancel a job. Note QIIME2 Visualizations One of the features of QIIME 2 are the variety of visualizations provided at several analysis steps. Although this guide will not cover every feature of every visualization, here are some important points to note. QIIME2 View : DNA Subway uses the QIIME 2 View plugin to display visualizations. Like the standalone QIIME 2 software, you can navigate menus, and interact with several visualizations. Importantly, many files and visualizations can be directly download for your use outside of DNA Subway, including in report generation, or in your custom QIIME 2 analyses. You can view downloaded .qza or .qzv files at view.qiime2.org . Quality Graphs Explained After demultiplexing, you will be presented with a visualization that displays the following tables and graphs: Overview Tab Demultiplexed sequence counts summary : For each of the fastq files (each of which may generally correspond to a single sample), you are presented with comparative statistics on the number of sequences present. This is followed by a histogram that plots number of sequences by the number of samples. Per-sample sequence counts : These are the actual counts of sequences per sample as indicated by the sample names you provided in your metadata sheet. Interactive Quality Plot This is an interactive plot that gives you an average quality (y-axis) by the position along the read (x-axis). This box plot is derived from a random sampling of a subset of sequences. The number of sequences sampled will be indicated in the plot caption. You can use your mouse drag and zoom in to regions on the plot. Double-click your mouse to zoom out. 3. Click the \"Interactive Quality Plot\" tab to view a histogram of sequence quality. Use this plot at the tip below to determine a location to trim. Tips on trimming for sequence quality On the Interactive Quality Plot you are shown an histogram, plotting the average quality (x axis) Phred score vs. the position on the read (y axis) in base pairs for a subsample of reads. Zooming to determine 3' trim location Click and drag your mouse around a collection of base pair positions you wish to examine. Clicking on a given histogram bar will also generate a text report and metrics in the table below the chart. Using these metrics, you can choose a position to trim on the right side (e.g. 3' end of the sequence read). The 5' (left trim) is specific to your choice of primers and sequencing adaptors (e.g. the sum of the adaptor sequence you expect to be attached to the 5' end of the read). Poor quality metrics will generate a table colored in red, and those base positions will also be colored red in the histogram. Double-clicking will return the histogram to its original level of zoom. Example plots It is important to maximize the length of the reads while minimizing the use of low quality base calls. To this end, a good guideline is to trim the right end of reads to a length where the 25 th percentile is at a quality score of 25 or more. However, the length of trimming will depend on the quality of the sequence, so you may have to use a lower quality threshold to retain enough sequence for informative sequence searches and alignments. This may require multiple runs of the analysis to find the optimal trim length for your data. Quality drops significantly at base 35 Improved quality sequence C. Use DADA2 for Trimming and Error-correction of Reads It is important to only work with high quality data. This step will generate a sequence quality histogram which can be used to determine parameter for trimming. Click 'DADA2' and choose the metadata file corresponding to the samples you wish to analyze. Then choose values for trimming of the reads. For \"trimLeft\" (the position starting from the left you wish to trim) and \"TruncLen\" (this is the position where reads should be trimmed, truncating the 3' end of the read. Reads shorter than this length will be discarded). Finally, click Trim reads . Sample Data \"ubiome-test-data\" dataset: Based on the histogram for our sample, we recommend the following parameters: trimLeft: 17 (this is specific to primers and adaptors in this experiment) TruncLen: 200 (this is where low quality sequence begins, in this case because our sequence length is lower than the expected read length) D. Check Results of Trimming Once trimming is complete, the following outputs are expected: Click on DADA2 and then click on the links in the Results table to examine results. Trim Table ( Metric summary , Frequency per sample , Frequency per feature ): Summarizes the dataset post-trimming including the number of samples and the number of features per sample. The \"Interactive Sample Detail\" tab contains a sampling depth tool that will be used in computation of the core matrix. Note You will use the maximum frequency value for the Alpha rarefaction step So you may wish to record this value now for the DNA Subway 'Clustering sequences' step. Stats : Sequencing statistics for each of the sample IDs described in the original metadata file. Representative Sequences ( Sequence Length Statistics , Seven-Number Summary of Sequence Lengths , Sequence Table ): This table contains a listing of features observed in the sequence data, as well as the DNA sequence that defines a feature. Clicking on the DNA sequence will submit that sequence for BLAST at NCBI in a separate browser tab. The feature table contains two columns output by DADA2. DADA2 (Divisive Amplicon Denoising Algorithm 2) determines what sequences are in the samples. DADA2 filters the sequences and identifies probable amplification or sequencing errors, filters out chimeric reads, and can pair forward and reverse reads to create the best representation of the sequences actually found in the samples and eliminating erroneous sequences. Feature ID : A unique identifier for sequences. Sequence : A DNA Sequence associated with each identifier. Clicking on any given sequence will initiate at BLAST search on the NCBI website. Click \"View report\" on the BLAST search that opens in a new web browser tab to obtain your results. Keep in mind that if your sequences are short (due to read length or trimming) many BLAST searches may not return significant results. Tip Although the term \"feature\" can (unfortunately) have many meanings as used by the QIIME2 documentation, unless otherwise noted in this documentation it can be thought of as an OTU ( Operational Taxonomic Unit ); another substitution for the word species. OTU is a convenient and common terminology for referring to an unclassified or undetermined species. Ultimately, we are attempting to identify an organism from a sample of DNA which may not be informative enough to reach a definitive conclusion. Tip If you want to redo the DADA2 step with different parameters, click the \"New Job\" tab on the upper left of a DADA2 window to submit a new job. New jobs appear as tabs on Subway steps that are typically run several times. You can go back an see these jobs which are labeled with a job number.","title":"DNA Subway Purple Line - Metadata and QC"},{"location":"dna_subway_guide/#dna-subway-purple-line-alpha-rarefactionclustering-sequences","text":"A. Alpha rarefaction At this step, you can visualize summaries of the data. A feature table will generate summary statistics, including how many sequences are associated with each sample. Note that sample depth is limited to 100,000. Click on 'Alpha rarefaction'. Select \"run\" and designate the minimum and maximum rarefaction depth. A minimum value should be set at 1. The maximum value is specific to your data set. The maximum value is specific to your data set. To determine what the maximum value should be set to, open the \"Trim Table\" from the \"DADA2\" step. You may not choose a value that is greater than the maximum frequency per sample. In general, choosing a value that is somewhere around the median frequency seems to work well, but you may want to increase that value if the lines in the resulting rarefaction plot don't appear to be leveling out, or decrease that value if you seem to be losing many of your samples due to low total frequencies closer to the minimum sampling depth than the maximum sampling depth. Identify the maximum Sequence Count value and enter that number as the maximum value. Click Submit Job . Note Since you may want to try Alpha rarefaction using different combinations of results from DADA2 trimming and your choice of rarefaction depths, your trim (DADA2) jobs are displayed on the left, and each new Alpha rarefaction setting will appear as a tab on the top. Sample Data \"ubiome-test-data\" dataset: We recommend the following parameters: Min. rarefaction depth : 1 Max. rarefaction depth : 2938 Under 'Results' click on Alpha Rarefaction Plot to view the results. Navigating Alpha Rarefaction graphs Alpha rarefaction generates an interactive plot of species diversity by sampling depth by the categorical samplings described in your sample metadata. You can use dropdown menus to change metrics/conditions displayed and also export data as a CSV file.","title":"DNA Subway Purple Line - Alpha Rarefaction/Clustering Sequences"},{"location":"dna_subway_guide/#dna-subway-purple-line-calculate-core-metricsalpha-and-beta-diversity","text":"At this stop, you will examine Alpha Diversity (the diversity of species/taxa present within a single sample) and Beta Diversity (a comparison of species/taxa diversity between two or more samples). Alpha diversity answers the question - \"How many species are in a sample?\" Beta diversity answer the question - \"What are the differences in species between samples?\" A. Calculate core metrics Click on 'Core metrics' and then click the \"run\" link. Choose a sampling depth based upon the \"Sampling depth\" tool (described in Section D Step 1, in the Trim Table output; Interactive Sample Detail tab). Choose an appropriate classifier (see comments in the tip below) and click Submit job . Choosing Core metrics parameters Sampling Depth In downstream steps, you will need to choose a sampling depth for your sample comparisons. You can choose by examining the table generated at the Trim reads step. In the Trim Table output, Interactive Sample Detail tab, use the \"Sampling depth\" tool to explore how many sequences can be sampled during the Core matrix computation. As you slide the bar to the right, more sequences are sampled, but samples that do not have this many sequences will be removed during analysis. The sampling depth affects the number of sequences that will be analyzed for taxonomy in later steps: as the sampling depth increases, a greater representation of the sequences will be analyzed. However, high sampling depth could exclude important samples, so a balance between depth and retaining samples in the analysis must be found. Classifier Choose a classifier pertaining to your experiment type. Microbiome choose Greengenes (515F/806R) or Greengenes (full sequences) or Sliva (16S rRNA) classifier eDNA experiment with marine fishes you may elect to choose the Fish 12S/ecoPrimer classifier Sample Data \"ubiome-test-data\" dataset: We recommend the following parameters: Sampling Depth : 3000 Classifier : Grenegenes (full sequences) B. Examine alpha and beta diversity When core metrics is complete, you should generate several visualization results. Click each of the following to get access: Alpha Diversity: Pielou's Evenness Alpha Correlation: Measure of community evenness using correlation tests Group Significance: Analysis of differences between features across group Faith's Phylogenetic Diversity Alpha Correlation: Faith Phylogenetic Diversity (a measure of community richness) with correlation tests Group Significance: Faith Phylogenetic Diversity ( a measure of community richness) Beta Diversity: Bray-Curtis Distance Bray-Curtis is a metric for describing the dissimilarity of species in an ecological sampling. - Bioenv: Bray-Curtis test metrics Emperor: Interactive PCoA plot of Bray-Curtis metrics Jaccard Distance Emperor: Interactive PCoA plot calculated by Jaccard similarity index. Unweighted UniFrac Distance UniFrac is a metric for describing the similarity of a biological community, taking into account the relatedness of community members. Bioenv: UniFrac test metrics Emperor: Unweighted interactive PCoA plot Weighted UniFrac Distance Unweighted UniFrac removes the effect of low-abundance features in the calculation of principal components. Emperor: Weighted interactive PCoA plot of UniFrac. Tip Emperor Plots These plots are all interactive three-dimensional plots of an analysis using principal components . Customization You can customize Emperor plots, including altering the color of and shape points, axes, and other parameters. You can also export images from this visualization. Bioenv These plots are tables of tests and descriptive metrics. C. Taxonomic Diversity: Taxonomic diversity is at the heart of many analyses. We suggest consulting the QIIME taxonomy overview for a detailed explanation of how QIIME2 calculates taxonomy and additional features of QIIME2 you may wish to explore beyond the functionalities DNA Subway has included. Bar Plots An interactive stacked bar plot of species diversity. Dropdown menus allow you to color by seven taxonomic levels 1) kingdom, 2) phylum, 3) class, 4) order, 5), family, 6) genus, 7) species. Plots can be further arranged/filtered/sorted accoridng to characteristics in the sample metadata. You may also download images and data used to create the barpot visualization. Taxonomy A table indicating the identified \"features\", their taxa, and an indication of confidence. You can download and interact with any of the available plots. D. Calculate differential abundance Click on the 'Differential abundance' stop. Then click on the \"Submit new \"Differential abundance\" job\" link. Choose a metadata category to group by, and a level of taxonomy to summarize by. Then click &submit job {.interpreted-text role=\"guilabel\"}. Sample Data \"ubiome-test-data\" dataset: We recommend the following parameters: Group data by : CollectionMethod Level of taxonomy to summarize : 5 Tip Download the provided CSV files so that you can generate customized plots.","title":"DNA Subway Purple Line - Calculate Core Metrics/Alpha and Beta Diversity"},{"location":"dna_subway_guide/#dna-subway-purple-line-visualize-data-with-picrust-and-phyloseq","text":"Under Development","title":"DNA Subway Purple Line - Visualize data with PiCrust and PhyloSeq"},{"location":"faq/","text":"Frequently Asked Questions \u00b6 User Account \u00b6 How do I update my account information? CyVerse users should update their account information annually for continued access to services. To update, go to the CyVerse User Portal , log in, and click the account icon in the upper right corner. In addition to updating your email, institution, occupation, preferences and other information that may have changed, please add your ORCID ID, a unique identifier which can help you receive credit for your work. Get an ORCID here https://orcid.org/register . By keeping your account information current, our funders can see the value of CyVerse to our community and we learn which of our services and platforms are most helpful to you. Data \u00b6 What if I need more space (storage) in the Data Store? Every user has a 5GB allocation in the Data Store. You can request more space by completing an Allocation Increase Form ; also see information on storage allocations for CyVerse's subscription tiers . How do I publish a large set of public data? If you need assistance transferring a large dataset to CyVerse, please contact CyVerse Support ( support@cyverse.org or use the blue chat icon at the bottom right). For more information on our policies, see CyVerse's Collaboration Policy and Data Management Policy . For more information on using data at CyVerse, see the Learning Center documentation on working with data . What public datasets are in CyVerse? CyVerse provides web access to its public datasets via WebDav https://data.cyverse.org Public datasets in CyVerse may also be accessed through the Discovery Environment, Atmosphere, the Science APIs and iCommands. For more information on using public data at CyVerse, see the Learning Center documentation pages on HTTP Access with WebDAV . How do I request a Community Released Data Folder? Community Released Data folders are available for evolving datasets that individuals or communities want to make available as quickly as possible for research and reuse, especially within CyVerse analysis platforms. Community Released Data folders are intended for datasets that are growing or changing frequently or that may not need long-term preservation. Before requesting a folder, please read this wiki article on publishing data through the Data Commons , and this one on preparing community-released data folders . Then, if you meet the criteria, you can request a folder using this form . How do I connect to a shared or public folder with CyberDuck? See our using CyberDuck documentation . How do I open a connection to a private folder that is shared with me? See our using the Data Store documentation . How do I make a folder public with iCommands? Although you can share files and folders in the DE and create public links, you must use iCommands make them visible to everyone. Permissions are set in iCommands by using ichmod ( https://docs.irods.org/4.2.1/icommands/user/#ichmod ){target=_blank} . To make a folder public, you must give read permission to two users: 'public' (anyone signed in with a CyVerse account) and 'anonymous' (anyone on the web - no log in required). To recursively make a shared folder called 'myfolder' public, use the instructions below. ichmod -r read public /iplant/home/shared/myfolder ichmod -r read anonymous /iplant/home/shared/myfolder To remove public access to the folder, use: ichmod -r null public /iplant/home/shared/myfolder ichmod -r null anonymous /iplant/home/shared/myfolder When sharing a file or folder, what permission should I give to my collaborator? It depends on what you want to allow the collaborator to do with the file or folder. Options are: read, write (ability to edit the file or folder), and own (in addition to edit, can also delete and move; use this permission with caution). Learn more here . Why can't I rename or delete files in a folder that has been shared with me? To rename a file or folder, you must have \"write\" permission, and to delete a file you must have \"own\" permission. To check the permission you have, click the checkbox for the item and look at the Permissions shown in the Details panel on the right. Contact the person who shared the file or folder with you if they did not give you the necessary level of permission. Learn more at Changing and Viewing Data Permission Levels in the DE . How can I manage shared files and folders for my lab group or project? See Setting Up a Shared Directory for a Lab or Project . Why doesn't anything happen when I move a folder I own to the Trash? If a folder has hundreds of files, it can take several hours for the deletion to complete in the DE. Please be patient and try refreshing your browser periodically. You cannot delete 1000 files or more in the DE. You must use iCommands instead. Note that deleted files may still show up in the search for awhile, but eventually deleted files will be fully purged from the system. Can I have spaces in file and folder names? No. Do not use spaces or special characters in file or folder names as they can cause analyses to fail. Learn more here . Can I view my files in a genome browser? You can view bam, vcf, and gff genome files you own in the genome browsers at Ensembl, UCSC, IGV, GBrowse, and jbrowse, and view Fasta genome files in CoGe. Learn more about viewing genome files in a genome browser or in CoGe . Apps and Analyses \u00b6 Why has my job failed or been running forever? The following recommendations can help you determine what went wrong and collect information for CyVerse staff in case you cannot resolve the problem yourself. Common things to check when troubleshooting an analysis View the app's parameters to make sure you used the correct input files and settings. Read through the app's documentation page. It also may be helpful to read through documentation about the tool that was used to create the app. Check the app's documentation page to see if a link was provided. If no link was provided, you can find specifics about the tool that was used and search for more information on the web. Avoid the use of special characters and spaces in analysis names, file names, and folder names when submitting an analysis through the DE (e.g., ~ ` ! @ # $ % ^ & * ( ) + = { } [ ] | : ; \" ' < , ? / and spaces). Getting Help with an analysis If you know that an analysis typically completes in 20 minutes but you have one that still shows Running status 24 hours after you submitted it, the app used for the analysis seems to have a problem, or you didn't get any output files or the output files were not what you expected, you can submit a request for help directly in the Analyses window. The status of the analysis determines the Help information that is displayed. In the Analyses window, find the analysis with the possible issue. Click the name of the failed analysis whose outputs you want to view. Review the suggestions for review. If you still need assistance, click I still need help and complete the form. Please go through all the troubleshooting steps yourself before requesting help. The problem is often something that you can diagnose yourself. Checking log files for error One of the main tools available for troubleshooting a failed analysis is the set of log files that are returned with each completed or failed analysis. These log files contain important information about the analysis, such as the settings that were used, files you used, and, in the case of a failed analysis, information to help explain why the analysis failed. Because different apps are based on different tools, there is no standard method used for error reporting, so the same type of error may land in different log files. For example, one app may return errors to the stdout files (usually the screen, although it can be redirected and is generally captured in a log file here), while another saves its errors to the stderr files (which usually writes to a file, but can also be redirected). This means you may have to look in more than one log file when troubleshooting a failed analysis. The log files that most commonly contain error information are (numerals in the filename correspond to the step number that was logged in your analysis): condor-stderr and condor-input-stdout log files contain errors and details about Condor, the batch manager program that handles the execution of your analyses submission in the analyses queue. condor-input-stderr and condor-input-stdout files contain details about outputs from the tool upon which the app is based. How do I get help with a tool (app) or workflow? The steps to get Help depend on whether you're a novice or an expert with the tool (executable or binary) on which the app or workflow is based. If you are a novice: Learn more about the tools used: Search the internet for the publication describing the tool and any related documentation. Make sure you understand what the tool is designed to do, what inputs it can accept and in which format, and how to set any parameters. Search the internet for informative sites in your domain. For example, SEQanswers is the go-to online forum for the next-generation sequencing community. Talk with someone at your institution who is more experienced with the tool. Try to use the app in the Discovery Environment. Click the info icon next to the app name to view the app manual and its sample test input files and expected outputs. If you are experienced with the tool or workflow: If you are experienced with the tool or workflow and need advice for how to work with very large-scale data or a complex workflow, you may request Extended Collaborative Support . Why is my analysis sitting in the Submitted state for so long? Analyses that use an app that runs on an HPC system can remain in the Submitted state for hours or even days. They may sit in the queue in Submitted state waiting to run, along with other possibly long-running jobs that were in the queue first. Therefore, it may take several days for your analysis to get its turn to run. Once your analysis runs, its results will be returned to the Data Store and you will get a notification that the analysis status is now Completed. Is there a limit to how many analyses (jobs) I can run at the same time in the Discovery Environment? The DE will run up to 8 of your analyses at the same time. You can launch more, but they will not run until some of your analyses have completed. I'm trying to run an analysis, but when I enter an input I can't see my files. Why? I know they are there. Because the app requires a folder as input, not a file , the files don't show since they aren't the appropriate inputs for the app. The files are indeed there but don't show. Check the app's input box; if it says \"Select a folder\", then it requires a folder input. Put the file(s) you want to input into a folder and then use that folder as input. Note: You can use Drag and Drop to input the folder by finding it in the Data window, making sure the folder name is shown in the center panel, and then dragging the folder into the app's input box. How do I rerun a job, but with different parameters or with a different input? You can easily relaunch the same analysis with different settings: In the Analyses window, click the app name in the App column for the analysis you want to rerun. This opens up an app window for that app, which is already configured with the inputs and settings you used for the previous analysis run. Change settings or inputs as needed. Click Launch Analysis to launch the new analysis. Learn more here. How do I run the same analysis on a number of files most efficiently? You can create a file that contains a list of up to 16 files to use as input for high-throughput and batch file execution. Such a file is called an HT Analysis Path List file. Learn more here , and if you still have questions, read here . I want to analyze a series of files with the same app, but the output files all have the same name. How do I distinguish them so I can use them in a workflow? You can avoid confusion by finding the output folder in your Data list and renaming each output file with a unique name. After renaming the output files, you can then use them together in a step of the analysis workflow. Why can't I find an app in the Discovery Environment? There are two common reasons why an app is not \"visible\" or doesn't come up in search in the Apps list: The app may be an HPC (high-performance computing) app, which is only displayed after you have logged in to Tapis, where the HPC apps are stored. To do so, click the HPC tab in the Apps window and enter your CyVerse username and password. The app may not yet be public, or the app owner may not have shared the unpublished app with you. Check with the owner to see if it is indeed shared with you or is public. If you still can't find the app, it's possible it has been deprecated. If an app is no longer returned in a search query, search for an app with a similar name or one that uses the same tool, topic, or operation. If you are the app integrator and need the app returned to the catalog, contact Support (support@cyverse.org) for assistance. Learn more about deprecated apps . What apps and workflows are in CyVerse? CyVerse has hundreds of apps and workflows in the Discovery Environment (DE). You can view the list of applications available in the DE here . Most apps in the DE have user manuals to help you use the app. You also can browse the list of tutorials to find help to learn a complicated workflow or how to use an app in the DE or VICE. How do I make my app available for others to use? You can create a new app interface in the Discovery Environment and share it with other users and you also can install the app on VICE. In most cases, providing a Docker container (or a link to one) with the application of your choice is all you need to start. See the Develop section of the Learning Center. Containers \u00b6 Does CyVerse have resources for GPU and containers (e.g., to stabilize R modules using the nvidia cuda)? Yes; please email Tyson at tswetnam@cyverse.org for details. While container performance is greater than a VM, how much is container performance below that of native mode, in general? Please see the Conclusion section bullet #2 in Evaluation of Docker Containers for Scientific Workloads in the Cloud . Are there tools for scanning publicly available containers in Atmosphere VMs for malware? Docker Hub and Quay , two of the most popular public container image registries, both provide security scanning for images that are uploaded to their sites. Details about how to enable or use these registries' security scanning features can be found here: https://developers.redhat.com/blog/2019/06/26/using-quay-io-to-find-vulnerabilities-in-your-container-images/ and https://docs.docker.com/docker-hub/vulnerability-scanning/ . Other tools to scan your container images without using DockerHub and Quay include Anchore , Clair , and Trivy , with new container-based security scanning software being developed all the time. Each solution seems to take a different approach to security scanning, so you might need to experiment to find the tool that works for your workflow. The easier tools to use are Anchore, which can be used as a container itself, and Trivy, which can be installed by a package manager. When using Singularity, there is built-in integration with Clair using Singularity's tools. Information about Singularity tools can be found here: https://github.com/singularityhub/stools Bring Your Own (BYO) \u00b6 How can I use CyVerse's tools and resources from within my program/app? See information about our Science APIs ; you can also contact Support using the blue chat icon at the bottom right of the platform. For projects requiring more extensive support, you can request community support or an external collaborative partnership (see Collaboration below). Collaboration \u00b6 How can I get a letter of collaboration for my grant proposal that uses CyVerse? To request a letter of collaboration, email info@cyverse.org your request with the following information: - the CyVerse resources your project will use (e.g., storage, computing power, expertise for scaling, etc.) and indicate if any resulting datasets will be made publicly available; - the name of the PI, proposal title, funding agency, the date you need the letter - if there is a template that must be used, please attach it to your email. What is an external collaborative partnership and how do I apply? External Collaborative Partnerships (ECP) pair member(s) of the CyVerse user community with expert CyVerse staff to address the computational needs of a scientific project. Requests are reviewed on an ongoing basis. The criteria CyVerse uses to review ECP requests are available here: ECP Criteria . To help you complete the ECP Application , the questions on the form are listed below. External Collaborative Partnership Application Questions Project Principal Investigator (PI) Institution Collaborating personnel: Provide a detailed list of students, technicians, informaticians and/or developers who will be able to assist with project design and implementation, their respective computational science skill sets (e.g., web design, Python, GWAS, etc.), and their specific time commitments during the project (e.g., 1.5 hrs/day). Previous interactions with CyVerse Funding sources Project title Project description Please summarize your proposal's activities and desired outcomes (500 chars or less) Scientific description: Provide a scientific description of your project. Describe how the proposed project is within the scope of CyVerse's scientific Enablement Vision. Illustrate how any resulting deliverables have the potential to enable science for scientists beyond your immediate network of collaborators. Technical description: Provide a technical description of your project. What is the computational need that Will be addressed with assistance from CyVerse? Identify specific potential deliverables to be implemented using CyVerse technologies, such as the Discovery Environment, Atmosphere, APIs, Data Store, Data Commons, etc. Timeline and milestones for completing the project: Provide a timeline of specific monthly milestones (deliverables). Projects of short duration (~2 months) should provide weekly milestones. Scientific and technical impact: Describe how the success of this collaboration will benefit your project and the broader community. Communication and sharing plan: Will the data and/or workflows be made publicly available through CyVerse? Will you be blogging and/or tweeting about the work? Will you be giving a talk about your work at your institution or at a professional conference? Will you be writing a news article for the CyVerse website or newsletter? Will you be preparing a tutorial that uses the datasets or workflows? Will you be leading a workshop(s) or webinar(s) to teach others to use the data or workflow(s)? Teaching and Training \u00b6 How can I use CyVerse in my course? A great teaching resource is to use containerized workflows in DE/VICE for a class. By loading a container with the software tools, datasets, and analysis parameters necessary to run an analysis, educators use containers to help overcome many technological and logistical (i.e., devices with different OS) hurdles for both learning and teaching informatics and computational skills. See Teaching with VICE for more information. Also, DNA Subway is especially useful for teaching the basics of computational genomics workflows: gene concepts, phylogenetics, DNA barcoding and RNA-Seq analysis. With a friendly user interface, DNA Subway uses the analogy of multiple subway stops and lines to understand genomics workflows and has been used successfully by high school students and above. Can CyVerse give a workshop at my institution? Funding to support workshop requests is very limioted, with priority for trainings at underserved institutions (rural, HBCU/Tribal/Hispanic-serving, etc.). Contact CyVerse's Education, Outreach, and Training Lead Jason Williams ( williams@cshl.edu ).","title":"FAQ"},{"location":"faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"faq/#user-account","text":"How do I update my account information? CyVerse users should update their account information annually for continued access to services. To update, go to the CyVerse User Portal , log in, and click the account icon in the upper right corner. In addition to updating your email, institution, occupation, preferences and other information that may have changed, please add your ORCID ID, a unique identifier which can help you receive credit for your work. Get an ORCID here https://orcid.org/register . By keeping your account information current, our funders can see the value of CyVerse to our community and we learn which of our services and platforms are most helpful to you.","title":"User Account"},{"location":"faq/#data","text":"What if I need more space (storage) in the Data Store? Every user has a 5GB allocation in the Data Store. You can request more space by completing an Allocation Increase Form ; also see information on storage allocations for CyVerse's subscription tiers . How do I publish a large set of public data? If you need assistance transferring a large dataset to CyVerse, please contact CyVerse Support ( support@cyverse.org or use the blue chat icon at the bottom right). For more information on our policies, see CyVerse's Collaboration Policy and Data Management Policy . For more information on using data at CyVerse, see the Learning Center documentation on working with data . What public datasets are in CyVerse? CyVerse provides web access to its public datasets via WebDav https://data.cyverse.org Public datasets in CyVerse may also be accessed through the Discovery Environment, Atmosphere, the Science APIs and iCommands. For more information on using public data at CyVerse, see the Learning Center documentation pages on HTTP Access with WebDAV . How do I request a Community Released Data Folder? Community Released Data folders are available for evolving datasets that individuals or communities want to make available as quickly as possible for research and reuse, especially within CyVerse analysis platforms. Community Released Data folders are intended for datasets that are growing or changing frequently or that may not need long-term preservation. Before requesting a folder, please read this wiki article on publishing data through the Data Commons , and this one on preparing community-released data folders . Then, if you meet the criteria, you can request a folder using this form . How do I connect to a shared or public folder with CyberDuck? See our using CyberDuck documentation . How do I open a connection to a private folder that is shared with me? See our using the Data Store documentation . How do I make a folder public with iCommands? Although you can share files and folders in the DE and create public links, you must use iCommands make them visible to everyone. Permissions are set in iCommands by using ichmod ( https://docs.irods.org/4.2.1/icommands/user/#ichmod ){target=_blank} . To make a folder public, you must give read permission to two users: 'public' (anyone signed in with a CyVerse account) and 'anonymous' (anyone on the web - no log in required). To recursively make a shared folder called 'myfolder' public, use the instructions below. ichmod -r read public /iplant/home/shared/myfolder ichmod -r read anonymous /iplant/home/shared/myfolder To remove public access to the folder, use: ichmod -r null public /iplant/home/shared/myfolder ichmod -r null anonymous /iplant/home/shared/myfolder When sharing a file or folder, what permission should I give to my collaborator? It depends on what you want to allow the collaborator to do with the file or folder. Options are: read, write (ability to edit the file or folder), and own (in addition to edit, can also delete and move; use this permission with caution). Learn more here . Why can't I rename or delete files in a folder that has been shared with me? To rename a file or folder, you must have \"write\" permission, and to delete a file you must have \"own\" permission. To check the permission you have, click the checkbox for the item and look at the Permissions shown in the Details panel on the right. Contact the person who shared the file or folder with you if they did not give you the necessary level of permission. Learn more at Changing and Viewing Data Permission Levels in the DE . How can I manage shared files and folders for my lab group or project? See Setting Up a Shared Directory for a Lab or Project . Why doesn't anything happen when I move a folder I own to the Trash? If a folder has hundreds of files, it can take several hours for the deletion to complete in the DE. Please be patient and try refreshing your browser periodically. You cannot delete 1000 files or more in the DE. You must use iCommands instead. Note that deleted files may still show up in the search for awhile, but eventually deleted files will be fully purged from the system. Can I have spaces in file and folder names? No. Do not use spaces or special characters in file or folder names as they can cause analyses to fail. Learn more here . Can I view my files in a genome browser? You can view bam, vcf, and gff genome files you own in the genome browsers at Ensembl, UCSC, IGV, GBrowse, and jbrowse, and view Fasta genome files in CoGe. Learn more about viewing genome files in a genome browser or in CoGe .","title":"Data"},{"location":"faq/#apps-and-analyses","text":"Why has my job failed or been running forever? The following recommendations can help you determine what went wrong and collect information for CyVerse staff in case you cannot resolve the problem yourself. Common things to check when troubleshooting an analysis View the app's parameters to make sure you used the correct input files and settings. Read through the app's documentation page. It also may be helpful to read through documentation about the tool that was used to create the app. Check the app's documentation page to see if a link was provided. If no link was provided, you can find specifics about the tool that was used and search for more information on the web. Avoid the use of special characters and spaces in analysis names, file names, and folder names when submitting an analysis through the DE (e.g., ~ ` ! @ # $ % ^ & * ( ) + = { } [ ] | : ; \" ' < , ? / and spaces). Getting Help with an analysis If you know that an analysis typically completes in 20 minutes but you have one that still shows Running status 24 hours after you submitted it, the app used for the analysis seems to have a problem, or you didn't get any output files or the output files were not what you expected, you can submit a request for help directly in the Analyses window. The status of the analysis determines the Help information that is displayed. In the Analyses window, find the analysis with the possible issue. Click the name of the failed analysis whose outputs you want to view. Review the suggestions for review. If you still need assistance, click I still need help and complete the form. Please go through all the troubleshooting steps yourself before requesting help. The problem is often something that you can diagnose yourself. Checking log files for error One of the main tools available for troubleshooting a failed analysis is the set of log files that are returned with each completed or failed analysis. These log files contain important information about the analysis, such as the settings that were used, files you used, and, in the case of a failed analysis, information to help explain why the analysis failed. Because different apps are based on different tools, there is no standard method used for error reporting, so the same type of error may land in different log files. For example, one app may return errors to the stdout files (usually the screen, although it can be redirected and is generally captured in a log file here), while another saves its errors to the stderr files (which usually writes to a file, but can also be redirected). This means you may have to look in more than one log file when troubleshooting a failed analysis. The log files that most commonly contain error information are (numerals in the filename correspond to the step number that was logged in your analysis): condor-stderr and condor-input-stdout log files contain errors and details about Condor, the batch manager program that handles the execution of your analyses submission in the analyses queue. condor-input-stderr and condor-input-stdout files contain details about outputs from the tool upon which the app is based. How do I get help with a tool (app) or workflow? The steps to get Help depend on whether you're a novice or an expert with the tool (executable or binary) on which the app or workflow is based. If you are a novice: Learn more about the tools used: Search the internet for the publication describing the tool and any related documentation. Make sure you understand what the tool is designed to do, what inputs it can accept and in which format, and how to set any parameters. Search the internet for informative sites in your domain. For example, SEQanswers is the go-to online forum for the next-generation sequencing community. Talk with someone at your institution who is more experienced with the tool. Try to use the app in the Discovery Environment. Click the info icon next to the app name to view the app manual and its sample test input files and expected outputs. If you are experienced with the tool or workflow: If you are experienced with the tool or workflow and need advice for how to work with very large-scale data or a complex workflow, you may request Extended Collaborative Support . Why is my analysis sitting in the Submitted state for so long? Analyses that use an app that runs on an HPC system can remain in the Submitted state for hours or even days. They may sit in the queue in Submitted state waiting to run, along with other possibly long-running jobs that were in the queue first. Therefore, it may take several days for your analysis to get its turn to run. Once your analysis runs, its results will be returned to the Data Store and you will get a notification that the analysis status is now Completed. Is there a limit to how many analyses (jobs) I can run at the same time in the Discovery Environment? The DE will run up to 8 of your analyses at the same time. You can launch more, but they will not run until some of your analyses have completed. I'm trying to run an analysis, but when I enter an input I can't see my files. Why? I know they are there. Because the app requires a folder as input, not a file , the files don't show since they aren't the appropriate inputs for the app. The files are indeed there but don't show. Check the app's input box; if it says \"Select a folder\", then it requires a folder input. Put the file(s) you want to input into a folder and then use that folder as input. Note: You can use Drag and Drop to input the folder by finding it in the Data window, making sure the folder name is shown in the center panel, and then dragging the folder into the app's input box. How do I rerun a job, but with different parameters or with a different input? You can easily relaunch the same analysis with different settings: In the Analyses window, click the app name in the App column for the analysis you want to rerun. This opens up an app window for that app, which is already configured with the inputs and settings you used for the previous analysis run. Change settings or inputs as needed. Click Launch Analysis to launch the new analysis. Learn more here. How do I run the same analysis on a number of files most efficiently? You can create a file that contains a list of up to 16 files to use as input for high-throughput and batch file execution. Such a file is called an HT Analysis Path List file. Learn more here , and if you still have questions, read here . I want to analyze a series of files with the same app, but the output files all have the same name. How do I distinguish them so I can use them in a workflow? You can avoid confusion by finding the output folder in your Data list and renaming each output file with a unique name. After renaming the output files, you can then use them together in a step of the analysis workflow. Why can't I find an app in the Discovery Environment? There are two common reasons why an app is not \"visible\" or doesn't come up in search in the Apps list: The app may be an HPC (high-performance computing) app, which is only displayed after you have logged in to Tapis, where the HPC apps are stored. To do so, click the HPC tab in the Apps window and enter your CyVerse username and password. The app may not yet be public, or the app owner may not have shared the unpublished app with you. Check with the owner to see if it is indeed shared with you or is public. If you still can't find the app, it's possible it has been deprecated. If an app is no longer returned in a search query, search for an app with a similar name or one that uses the same tool, topic, or operation. If you are the app integrator and need the app returned to the catalog, contact Support (support@cyverse.org) for assistance. Learn more about deprecated apps . What apps and workflows are in CyVerse? CyVerse has hundreds of apps and workflows in the Discovery Environment (DE). You can view the list of applications available in the DE here . Most apps in the DE have user manuals to help you use the app. You also can browse the list of tutorials to find help to learn a complicated workflow or how to use an app in the DE or VICE. How do I make my app available for others to use? You can create a new app interface in the Discovery Environment and share it with other users and you also can install the app on VICE. In most cases, providing a Docker container (or a link to one) with the application of your choice is all you need to start. See the Develop section of the Learning Center.","title":"Apps and Analyses"},{"location":"faq/#containers","text":"Does CyVerse have resources for GPU and containers (e.g., to stabilize R modules using the nvidia cuda)? Yes; please email Tyson at tswetnam@cyverse.org for details. While container performance is greater than a VM, how much is container performance below that of native mode, in general? Please see the Conclusion section bullet #2 in Evaluation of Docker Containers for Scientific Workloads in the Cloud . Are there tools for scanning publicly available containers in Atmosphere VMs for malware? Docker Hub and Quay , two of the most popular public container image registries, both provide security scanning for images that are uploaded to their sites. Details about how to enable or use these registries' security scanning features can be found here: https://developers.redhat.com/blog/2019/06/26/using-quay-io-to-find-vulnerabilities-in-your-container-images/ and https://docs.docker.com/docker-hub/vulnerability-scanning/ . Other tools to scan your container images without using DockerHub and Quay include Anchore , Clair , and Trivy , with new container-based security scanning software being developed all the time. Each solution seems to take a different approach to security scanning, so you might need to experiment to find the tool that works for your workflow. The easier tools to use are Anchore, which can be used as a container itself, and Trivy, which can be installed by a package manager. When using Singularity, there is built-in integration with Clair using Singularity's tools. Information about Singularity tools can be found here: https://github.com/singularityhub/stools","title":"Containers"},{"location":"faq/#bring-your-own-byo","text":"How can I use CyVerse's tools and resources from within my program/app? See information about our Science APIs ; you can also contact Support using the blue chat icon at the bottom right of the platform. For projects requiring more extensive support, you can request community support or an external collaborative partnership (see Collaboration below).","title":"Bring Your Own (BYO)"},{"location":"faq/#collaboration","text":"How can I get a letter of collaboration for my grant proposal that uses CyVerse? To request a letter of collaboration, email info@cyverse.org your request with the following information: - the CyVerse resources your project will use (e.g., storage, computing power, expertise for scaling, etc.) and indicate if any resulting datasets will be made publicly available; - the name of the PI, proposal title, funding agency, the date you need the letter - if there is a template that must be used, please attach it to your email. What is an external collaborative partnership and how do I apply? External Collaborative Partnerships (ECP) pair member(s) of the CyVerse user community with expert CyVerse staff to address the computational needs of a scientific project. Requests are reviewed on an ongoing basis. The criteria CyVerse uses to review ECP requests are available here: ECP Criteria . To help you complete the ECP Application , the questions on the form are listed below. External Collaborative Partnership Application Questions Project Principal Investigator (PI) Institution Collaborating personnel: Provide a detailed list of students, technicians, informaticians and/or developers who will be able to assist with project design and implementation, their respective computational science skill sets (e.g., web design, Python, GWAS, etc.), and their specific time commitments during the project (e.g., 1.5 hrs/day). Previous interactions with CyVerse Funding sources Project title Project description Please summarize your proposal's activities and desired outcomes (500 chars or less) Scientific description: Provide a scientific description of your project. Describe how the proposed project is within the scope of CyVerse's scientific Enablement Vision. Illustrate how any resulting deliverables have the potential to enable science for scientists beyond your immediate network of collaborators. Technical description: Provide a technical description of your project. What is the computational need that Will be addressed with assistance from CyVerse? Identify specific potential deliverables to be implemented using CyVerse technologies, such as the Discovery Environment, Atmosphere, APIs, Data Store, Data Commons, etc. Timeline and milestones for completing the project: Provide a timeline of specific monthly milestones (deliverables). Projects of short duration (~2 months) should provide weekly milestones. Scientific and technical impact: Describe how the success of this collaboration will benefit your project and the broader community. Communication and sharing plan: Will the data and/or workflows be made publicly available through CyVerse? Will you be blogging and/or tweeting about the work? Will you be giving a talk about your work at your institution or at a professional conference? Will you be writing a news article for the CyVerse website or newsletter? Will you be preparing a tutorial that uses the datasets or workflows? Will you be leading a workshop(s) or webinar(s) to teach others to use the data or workflow(s)?","title":"Collaboration"},{"location":"faq/#teaching-and-training","text":"How can I use CyVerse in my course? A great teaching resource is to use containerized workflows in DE/VICE for a class. By loading a container with the software tools, datasets, and analysis parameters necessary to run an analysis, educators use containers to help overcome many technological and logistical (i.e., devices with different OS) hurdles for both learning and teaching informatics and computational skills. See Teaching with VICE for more information. Also, DNA Subway is especially useful for teaching the basics of computational genomics workflows: gene concepts, phylogenetics, DNA barcoding and RNA-Seq analysis. With a friendly user interface, DNA Subway uses the analogy of multiple subway stops and lines to understand genomics workflows and has been used successfully by high school students and above. Can CyVerse give a workshop at my institution? Funding to support workshop requests is very limioted, with priority for trainings at underserved institutions (rural, HBCU/Tribal/Hispanic-serving, etc.). Contact CyVerse's Education, Outreach, and Training Lead Jason Williams ( williams@cshl.edu ).","title":"Teaching and Training"},{"location":"getting_help/","text":"Getting Help \u00b6 First, check if your question is answered on the FAQ page . Next, try searching the Learning Center documentation using the search bar at the top of the page. If you still haven't found an answer, click the Intercom icon on the lower right-hand side of the page to start messaging with the CyVerse support team. Issues with Documentation \u00b6 To report an issue with the documentation itself, or to propose a change to the documentation, click on the GitHub icon in the top right of the page to navigate to the GitHub repository, where you can open an Issue. If you prefer not to use GitHub, you can email us at learning@cyverse.org .","title":"Getting Help"},{"location":"getting_help/#getting-help","text":"First, check if your question is answered on the FAQ page . Next, try searching the Learning Center documentation using the search bar at the top of the page. If you still haven't found an answer, click the Intercom icon on the lower right-hand side of the page to start messaging with the CyVerse support team.","title":"Getting Help"},{"location":"getting_help/#issues-with-documentation","text":"To report an issue with the documentation itself, or to propose a change to the documentation, click on the GitHub icon in the top right of the page to navigate to the GitHub repository, where you can open an Issue. If you prefer not to use GitHub, you can email us at learning@cyverse.org .","title":"Issues with Documentation"},{"location":"glossary/","text":"Glossary & Acronyms \u00b6 This glossary is to help you become more familiar with terms used in the CyVerse ecosystem as well as more broadly in Open Science and beyond. A \u00b6 action: automate a workflow in the context of CI/CD, see GitHub Actions https://github.com/features/actions agile: development methodology https://en.wikipedia.org/wiki/Agile_software_development for organizing a team to complete tasks organized over short periods called 'sprints' allocation: portion of a resource assigned to a particular recipient, typical unit is a core or node hour Anaconda: open source data science platform. https://www.anaconda.com/ application: also called an 'app', a software designed to help the user to perform specific task awesome: a curated set of lists that provide insight into awesome software projects on GitHub https://github.com/topics/awesome-list AVU: Attribute-Value-Unit a components for iRODS metadata https://docs.irods.org/4.1.9/icommands/metadata/ B \u00b6 beta: :math: \\beta , a software version which is not yet ready for publication but is being tested bash: Bash is the GNU Project's shell, the Bourne-Again Shell https://www.gnu.org/software/bash/ biocontainer: a community-driven project that provides the infrastructure and basic guidelines to create, manage and distribute bioinformatics packages (e.g conda) and containers (e.g docker, singularity) bioconda: a channel for the conda package manager specializing in bioinformatics software C \u00b6 CLI: (1) the UNIX shell `command line interface https://en.wikipedia.org/wiki/Command-line_interface , most typically BASH (2) the CyVerse Learning Institute https://learning.cyverse.org command: a set of instructions sent to the computer, typically in a typed interface conda: an installation type of the Anaconda data science platform. Command line application for managing packages and environments container: virtualization of an operating system run within an isolated user space Continuous Integration: (CI) is testing automation to check that the application is not broken whenever new commits are integrated into the main branch Continuous Delivery: (CD) is an extension of 'continuous integration' to make sure that you can release new changes in a sustainable way Continuous Deployment: a step further than 'continuous delivery', every change that passes all stages of your production pipeline is released Continuous Development: a process for iterative software development and is an umbrella over several other processes including 'continuous integration', 'continuous testing', 'continuous delivery' and 'continuous deployment' Continuous Testing: a process of testing and automating software development CRAN: The Comprehensive R Archive Network https://cran.r-project.org/ CyVerse tool: Software program that is integrated into the back end of the DE for use in DE apps CyVerse app: graphic interface of a tool made available for use in the DE D \u00b6 Debian: a free OS https://www.debian.org/ , base of other Linux distributions such as Ubuntu Development: the environment on your computer where you write code DevOps Software *Dev*elopment and information techology *Op*erations techniques for shortening the time to change software in relation to CI/CD Discovery Environment (DE): a data science workbench for running executable, interactive, and high throughput applications in `CyVerse DE https://de.cyverse.org distribution: abbreviated as 'distro', an operating system made from a software collection based upon the Linux kernel Docker: https://www.docker.com/ is an open source software platform to create, deploy and manage virtualized application containers on a common operating system (OS), with an ecosystem of allied tools. A program that runs and handles life-cycle of containers and images DockerHub: an official registry of docker containers, operated by Docker. https://hub.docker.com/ DOI: a digital object identifier. A persistant identifier number, managed by the doi.org https://www.doi.org/ Dockerfile: a text document that contains all the commands you would normally execute manually in order to build a Docker image. Docker can build images automatically by reading the instructions from a Dockerfile E \u00b6 environment: software that includes operating system, database system, specific tools for analysis entrypoint: In a Dockerfile, an ENTRYPOINT is an optional definition for the first part of the command to be run F \u00b6 FOSS: (1) Free and Open Source Software https://en.wikipedia.org/wiki/Free_and_open-source_software , (2) Foundational Open Science Skills https://cyverse.org/foss function: a named section of a program that performs a specific task G \u00b6 git: a version control system software GitHub: a website for hosting git repositories -- owned by Microsoft https://github.com GitLab: a website for hosting git repositories https://gitlab.com GitOps: using git framework as a means of deploying infrastructure on cloud using Kubernetes GPU: graphic processing unit GUI: graphical user interface H \u00b6 hack: a quick job that produces what is needed, but not well HPC: high performance computer, for large syncronous computation HTC: high throughput computer, for many parallel tasks I \u00b6 IaaS: Infrastructure as a Service https://en.wikipedia.org/wiki/Infrastructure_as_a_service . online services that provide APIs iCommands: command line application https://docs.irods.org/master/icommands/user/ for accessing iRODS Data Store IDE: integrated development environment, typically a graphical interface for working with code language or packages instance: a single virtul machine image: self-contained, read-only \u2018snapshot\u2019 of your applications and packages, with all their dependencies iRODS: an open source integrated Rule-Oriented Data Management System https://irods.org/ J \u00b6 Java: programming language, class-based, object-oriented JavaScript: programming language JSON: Java Script Object Notation, data interchange format that uses human-readable text Jupyter(Hub,Lab,Notebooks): an IDE, originally the iPythonNotebook, operates in the browser https://jupyter.org/ K \u00b6 kernel: central component of most operating systems (OS) Kubernetes: an open source container orchestration platform created by Google Kubernetes https://kubernetes.io/ is often referred to as \"K8s\" L \u00b6 lib: a UNIX library linux: open source Unix-like operating system M \u00b6 makefile: a file containing a set of directives used by a make build automation tool https://www.gnu.org/software/make/ markdown: a lightweight markup language with plain text formatting syntax master: a racist word used by computer engineers to describe the main or `primary`` computer or branch metadata:: data about data, useful for searching and querying multi-thread: a process which runs on more than one CPU or GPU core at the same time Mac OS X: Apple's popular desktop OS N \u00b6 node: a computer, typically 1 or 2 core (with many threads) server in a cloud or HPC center O \u00b6 ontology: formal naming and structural hierarchy used to describe data, also called a knowledge graph https://en.wikipedia.org/wiki/Ontology_(information_science) organization: a group, in the context of GitHub a place where developers contribute code to repositories Operating System (OS): software that manages computer hardware, software resources, and provides common services for computer programs Open Science Grid (OSG): national, distributed computing partnership for data-intensive research https://opensciencegrid.org/ ORCID: Open Researcher and Contributor ID https://orcid.org/ , a persistent digital identifier that distinguishes you from every other researcher P \u00b6 PaaS: Platform as a Service https://en.wikipedia.org/wiki/Platform_as_a_service run and manage applications in cloud without complexity of developing it yourself package: an app designed for a particular langauge package manager: a collection of software tools that automates the process of installing, upgrading, configuring, and removing computer programs for a computer's operating system in a consistent manner Production: environment where users access the final code after all of the updates and testing Python: interpreted, high-level, general-purpose programming language https://www.python.org/ Q \u00b6 QUAY.io: private Docker registry https://quay.io R \u00b6 R: data science programming language R Project https://cran.r-project.org/ recipe file: a file with installation scripts used for building software such as containers, e.g. Dockerfile registry: a storage and content delivery system, such as that used by Docker remote desktop: a VM with a graphic user interface accessed via a browser repo(sitory): a directory structure for hosting code and data RST: ReStructuredText, a markdown type file ReadTheDocs: a web service for rendering documentation (that this website uses) https://readthedocs.org and readthedocs.com https://readthedocs.com/ root: the administrative user on a linux kernel - use your powers wisely S \u00b6 SaaS: Software as a Service https://en.wikipedia.org/wiki/Software_as_a_service web based platform for using software schema: a metadata standard for labeling, tagging or coding for recording & cataloging information or structuring descriptive records. see https://schema.org/ scrum: daily set of tasks and evalautions as part of a sprint. shell: is a command line interface program that runs other programs (may be complex, technical programs or very simple programs such as making a directory). These simple, stand-alone programs are called commands Singularity: a container software, used widely on HPC, created by SyLabs https://sylabs.io/ SLACK: Searchable Log of All Conversation and Knowledge, a team communication tool https://slack.com/ slave: a racist word used to describe worker or secondary computers sprint: set period of time during which specific work has to be completed and made ready for review Singularity def file: (definition file) recipe for building a Singualrity container Stage: environment that is as similar to the production environment as can be for final testing T \u00b6 tar: software utility for collecting many files into one archive file, often referred to as a tarball tensor: algebraic object that describes a linear mapping from one set of algebraic objects to another terminal: a windowed emulator for directly enterinc commands to a computer thread: a CPU process or a series of linked messages in a discussion board tool: In the context of CyVerse Discovery Environment, a Docker Container TPU: tensor processing unit Travis: Travis-CI https://travis-ci.org/ , a continuous integration software U \u00b6 Ubuntu: most popular Linux OS distribution https://ubuntu.com/ , based on Debian UNIX: operating system user: the profile under which applications are started and run, root is the most powerful system administrator V \u00b6 VICE: Visual Interactive Computing Environment https://learning.cyverse.org/projects/vice/en/latest virtual machine: is a software computer that, like a physical computer, runs an operating system and applications W \u00b6 waterfall: software development broken into linear sequential phases, similar to a Gantt chart webGL: JavaScript API for rendering interactive 2D and 3D graphics within any compatible web browser without the use of plug-ins Windows: Microsoft's most popular desktop OS workspace: (vs. repo) worker node: A cluster typically has one or more nodes, which are the worker machines that run your containerized applications and other workloads. Each node is managed from the master, which receives updates on each node's self-reported status. X \u00b6 XML: Extensible Markup Language, data interchange format that uses human-readable text Y \u00b6 YAML: YAML Ain't Markup Language, data interchange format that uses human-readable text Z \u00b6 ZenHub: team collaboration solution built directly into GitHub that uses kanban style boards Zenodo: general-purpose open-access repository developed under the European OpenAIRE program and operated by CERN zip: a compressed file format zsh: Z-Shell https://www.zsh.org/ now the default shell on new Mac OS X Please cite CyVerse appropriately when you make use of our resources, see CyVerse citation policy . Fix or improve this documentation We make regular contributions to these materials, and you can suggest new materials or create and share your own. If you have ideas or suggestions please email learning@cyverse.org . You can also view, edit, and submit contributions on GitHub. On Github: GitHub Send feedback: learning@cyverse.org","title":"Glossary"},{"location":"glossary/#glossary-acronyms","text":"This glossary is to help you become more familiar with terms used in the CyVerse ecosystem as well as more broadly in Open Science and beyond.","title":"Glossary &amp; Acronyms"},{"location":"glossary/#a","text":"action: automate a workflow in the context of CI/CD, see GitHub Actions https://github.com/features/actions agile: development methodology https://en.wikipedia.org/wiki/Agile_software_development for organizing a team to complete tasks organized over short periods called 'sprints' allocation: portion of a resource assigned to a particular recipient, typical unit is a core or node hour Anaconda: open source data science platform. https://www.anaconda.com/ application: also called an 'app', a software designed to help the user to perform specific task awesome: a curated set of lists that provide insight into awesome software projects on GitHub https://github.com/topics/awesome-list AVU: Attribute-Value-Unit a components for iRODS metadata https://docs.irods.org/4.1.9/icommands/metadata/","title":"A"},{"location":"glossary/#b","text":"beta: :math: \\beta , a software version which is not yet ready for publication but is being tested bash: Bash is the GNU Project's shell, the Bourne-Again Shell https://www.gnu.org/software/bash/ biocontainer: a community-driven project that provides the infrastructure and basic guidelines to create, manage and distribute bioinformatics packages (e.g conda) and containers (e.g docker, singularity) bioconda: a channel for the conda package manager specializing in bioinformatics software","title":"B"},{"location":"glossary/#c","text":"CLI: (1) the UNIX shell `command line interface https://en.wikipedia.org/wiki/Command-line_interface , most typically BASH (2) the CyVerse Learning Institute https://learning.cyverse.org command: a set of instructions sent to the computer, typically in a typed interface conda: an installation type of the Anaconda data science platform. Command line application for managing packages and environments container: virtualization of an operating system run within an isolated user space Continuous Integration: (CI) is testing automation to check that the application is not broken whenever new commits are integrated into the main branch Continuous Delivery: (CD) is an extension of 'continuous integration' to make sure that you can release new changes in a sustainable way Continuous Deployment: a step further than 'continuous delivery', every change that passes all stages of your production pipeline is released Continuous Development: a process for iterative software development and is an umbrella over several other processes including 'continuous integration', 'continuous testing', 'continuous delivery' and 'continuous deployment' Continuous Testing: a process of testing and automating software development CRAN: The Comprehensive R Archive Network https://cran.r-project.org/ CyVerse tool: Software program that is integrated into the back end of the DE for use in DE apps CyVerse app: graphic interface of a tool made available for use in the DE","title":"C"},{"location":"glossary/#d","text":"Debian: a free OS https://www.debian.org/ , base of other Linux distributions such as Ubuntu Development: the environment on your computer where you write code DevOps Software *Dev*elopment and information techology *Op*erations techniques for shortening the time to change software in relation to CI/CD Discovery Environment (DE): a data science workbench for running executable, interactive, and high throughput applications in `CyVerse DE https://de.cyverse.org distribution: abbreviated as 'distro', an operating system made from a software collection based upon the Linux kernel Docker: https://www.docker.com/ is an open source software platform to create, deploy and manage virtualized application containers on a common operating system (OS), with an ecosystem of allied tools. A program that runs and handles life-cycle of containers and images DockerHub: an official registry of docker containers, operated by Docker. https://hub.docker.com/ DOI: a digital object identifier. A persistant identifier number, managed by the doi.org https://www.doi.org/ Dockerfile: a text document that contains all the commands you would normally execute manually in order to build a Docker image. Docker can build images automatically by reading the instructions from a Dockerfile","title":"D"},{"location":"glossary/#e","text":"environment: software that includes operating system, database system, specific tools for analysis entrypoint: In a Dockerfile, an ENTRYPOINT is an optional definition for the first part of the command to be run","title":"E"},{"location":"glossary/#f","text":"FOSS: (1) Free and Open Source Software https://en.wikipedia.org/wiki/Free_and_open-source_software , (2) Foundational Open Science Skills https://cyverse.org/foss function: a named section of a program that performs a specific task","title":"F"},{"location":"glossary/#g","text":"git: a version control system software GitHub: a website for hosting git repositories -- owned by Microsoft https://github.com GitLab: a website for hosting git repositories https://gitlab.com GitOps: using git framework as a means of deploying infrastructure on cloud using Kubernetes GPU: graphic processing unit GUI: graphical user interface","title":"G"},{"location":"glossary/#h","text":"hack: a quick job that produces what is needed, but not well HPC: high performance computer, for large syncronous computation HTC: high throughput computer, for many parallel tasks","title":"H"},{"location":"glossary/#i","text":"IaaS: Infrastructure as a Service https://en.wikipedia.org/wiki/Infrastructure_as_a_service . online services that provide APIs iCommands: command line application https://docs.irods.org/master/icommands/user/ for accessing iRODS Data Store IDE: integrated development environment, typically a graphical interface for working with code language or packages instance: a single virtul machine image: self-contained, read-only \u2018snapshot\u2019 of your applications and packages, with all their dependencies iRODS: an open source integrated Rule-Oriented Data Management System https://irods.org/","title":"I"},{"location":"glossary/#j","text":"Java: programming language, class-based, object-oriented JavaScript: programming language JSON: Java Script Object Notation, data interchange format that uses human-readable text Jupyter(Hub,Lab,Notebooks): an IDE, originally the iPythonNotebook, operates in the browser https://jupyter.org/","title":"J"},{"location":"glossary/#k","text":"kernel: central component of most operating systems (OS) Kubernetes: an open source container orchestration platform created by Google Kubernetes https://kubernetes.io/ is often referred to as \"K8s\"","title":"K"},{"location":"glossary/#l","text":"lib: a UNIX library linux: open source Unix-like operating system","title":"L"},{"location":"glossary/#m","text":"makefile: a file containing a set of directives used by a make build automation tool https://www.gnu.org/software/make/ markdown: a lightweight markup language with plain text formatting syntax master: a racist word used by computer engineers to describe the main or `primary`` computer or branch metadata:: data about data, useful for searching and querying multi-thread: a process which runs on more than one CPU or GPU core at the same time Mac OS X: Apple's popular desktop OS","title":"M"},{"location":"glossary/#n","text":"node: a computer, typically 1 or 2 core (with many threads) server in a cloud or HPC center","title":"N"},{"location":"glossary/#o","text":"ontology: formal naming and structural hierarchy used to describe data, also called a knowledge graph https://en.wikipedia.org/wiki/Ontology_(information_science) organization: a group, in the context of GitHub a place where developers contribute code to repositories Operating System (OS): software that manages computer hardware, software resources, and provides common services for computer programs Open Science Grid (OSG): national, distributed computing partnership for data-intensive research https://opensciencegrid.org/ ORCID: Open Researcher and Contributor ID https://orcid.org/ , a persistent digital identifier that distinguishes you from every other researcher","title":"O"},{"location":"glossary/#p","text":"PaaS: Platform as a Service https://en.wikipedia.org/wiki/Platform_as_a_service run and manage applications in cloud without complexity of developing it yourself package: an app designed for a particular langauge package manager: a collection of software tools that automates the process of installing, upgrading, configuring, and removing computer programs for a computer's operating system in a consistent manner Production: environment where users access the final code after all of the updates and testing Python: interpreted, high-level, general-purpose programming language https://www.python.org/","title":"P"},{"location":"glossary/#q","text":"QUAY.io: private Docker registry https://quay.io","title":"Q"},{"location":"glossary/#r","text":"R: data science programming language R Project https://cran.r-project.org/ recipe file: a file with installation scripts used for building software such as containers, e.g. Dockerfile registry: a storage and content delivery system, such as that used by Docker remote desktop: a VM with a graphic user interface accessed via a browser repo(sitory): a directory structure for hosting code and data RST: ReStructuredText, a markdown type file ReadTheDocs: a web service for rendering documentation (that this website uses) https://readthedocs.org and readthedocs.com https://readthedocs.com/ root: the administrative user on a linux kernel - use your powers wisely","title":"R"},{"location":"glossary/#s","text":"SaaS: Software as a Service https://en.wikipedia.org/wiki/Software_as_a_service web based platform for using software schema: a metadata standard for labeling, tagging or coding for recording & cataloging information or structuring descriptive records. see https://schema.org/ scrum: daily set of tasks and evalautions as part of a sprint. shell: is a command line interface program that runs other programs (may be complex, technical programs or very simple programs such as making a directory). These simple, stand-alone programs are called commands Singularity: a container software, used widely on HPC, created by SyLabs https://sylabs.io/ SLACK: Searchable Log of All Conversation and Knowledge, a team communication tool https://slack.com/ slave: a racist word used to describe worker or secondary computers sprint: set period of time during which specific work has to be completed and made ready for review Singularity def file: (definition file) recipe for building a Singualrity container Stage: environment that is as similar to the production environment as can be for final testing","title":"S"},{"location":"glossary/#t","text":"tar: software utility for collecting many files into one archive file, often referred to as a tarball tensor: algebraic object that describes a linear mapping from one set of algebraic objects to another terminal: a windowed emulator for directly enterinc commands to a computer thread: a CPU process or a series of linked messages in a discussion board tool: In the context of CyVerse Discovery Environment, a Docker Container TPU: tensor processing unit Travis: Travis-CI https://travis-ci.org/ , a continuous integration software","title":"T"},{"location":"glossary/#u","text":"Ubuntu: most popular Linux OS distribution https://ubuntu.com/ , based on Debian UNIX: operating system user: the profile under which applications are started and run, root is the most powerful system administrator","title":"U"},{"location":"glossary/#v","text":"VICE: Visual Interactive Computing Environment https://learning.cyverse.org/projects/vice/en/latest virtual machine: is a software computer that, like a physical computer, runs an operating system and applications","title":"V"},{"location":"glossary/#w","text":"waterfall: software development broken into linear sequential phases, similar to a Gantt chart webGL: JavaScript API for rendering interactive 2D and 3D graphics within any compatible web browser without the use of plug-ins Windows: Microsoft's most popular desktop OS workspace: (vs. repo) worker node: A cluster typically has one or more nodes, which are the worker machines that run your containerized applications and other workloads. Each node is managed from the master, which receives updates on each node's self-reported status.","title":"W"},{"location":"glossary/#x","text":"XML: Extensible Markup Language, data interchange format that uses human-readable text","title":"X"},{"location":"glossary/#y","text":"YAML: YAML Ain't Markup Language, data interchange format that uses human-readable text","title":"Y"},{"location":"glossary/#z","text":"ZenHub: team collaboration solution built directly into GitHub that uses kanban style boards Zenodo: general-purpose open-access repository developed under the European OpenAIRE program and operated by CERN zip: a compressed file format zsh: Z-Shell https://www.zsh.org/ now the default shell on new Mac OS X Please cite CyVerse appropriately when you make use of our resources, see CyVerse citation policy . Fix or improve this documentation We make regular contributions to these materials, and you can suggest new materials or create and share your own. If you have ideas or suggestions please email learning@cyverse.org . You can also view, edit, and submit contributions on GitHub. On Github: GitHub Send feedback: learning@cyverse.org","title":"Z"},{"location":"manuals/","text":"Manuals \u00b6 Platform Purpose Link Data Store data hosting and storage Data Store Discovery Environment analysis and workbench Discovery Environment Discovery Environment API API access DE API Manual Atmosphere Cloud Services Atmosphere Manual BISQUE Image Analysis BiSQUE Guide DNA Subway Genomics Education DNA Subway Guide TAPIS TACC APIs TAPIS","title":"Developer Manuals"},{"location":"manuals/#manuals","text":"Platform Purpose Link Data Store data hosting and storage Data Store Discovery Environment analysis and workbench Discovery Environment Discovery Environment API API access DE API Manual Atmosphere Cloud Services Atmosphere Manual BISQUE Image Analysis BiSQUE Guide DNA Subway Genomics Education DNA Subway Guide TAPIS TACC APIs TAPIS","title":"Manuals"},{"location":"mooc/","text":"Self-Guided Courses \u00b6 CyVerse Self-Guided Course (USA version) Created: 2022-02-14 In collaboration with CyVerse Austria and CyVerse UK, we have created a massive open online course (MOOC) for self-guided students, covering the basics of data management and analysis in CyVerse. This is a perfect starting point for new CyVerse users to get a basic understanding of how their computational workflows and data lifecycles can work in CyVerse.","title":"Self-Guided Tour"},{"location":"mooc/#self-guided-courses","text":"CyVerse Self-Guided Course (USA version) Created: 2022-02-14 In collaboration with CyVerse Austria and CyVerse UK, we have created a massive open online course (MOOC) for self-guided students, covering the basics of data management and analysis in CyVerse. This is a perfect starting point for new CyVerse users to get a basic understanding of how their computational workflows and data lifecycles can work in CyVerse.","title":"Self-Guided Courses"},{"location":"powered_by/","text":"Leveraging CyVerse Services \u00b6 CyVerse public platform provides a nominal quantity of compute and data storage to all of our users. For researchers who need more, we also provide mechanisms for extending and powering your research. Professional Services \u00b6 CyVerse offers a suite of services for institutions seeking to deploy CyVerse's cyberinfrastructure locally. With a secure, shared data management and computing environment with increased speed and performance, a local installation can better support your members' research and teaching needs for: Security compliance (e.g., HIPAA, ITAR, ISO, etc.) Federation with local and commercial cloud and high-performance computing Integration with local user identity management systems Our professional services include installation, maintenance, and training for local installations of CyVerse. Because CyVerse fully supports open source practices, you can access all of our open source infrastructure code and architecture diagrams on Github . Contact Us if you're interested in knowing more. Powered by CyVerse \u00b6 Through our unique Powered by CyVerse program, third-party projects can leverage CyVerse cyberinfrastructure to provide their users with robust services such as secure single sign-on with authentication, easy and fast data transfers, access to large-scale, High-Performance Compute resources such as Jetstream or XSEDE, as well as expertise from developers and domain scientists. External Collaborative Partnership \u00b6 External Collaborative Partnerships (ECP) pair you with an expert staff member to address the computational needs of your specific scientific project. To be considered for a partnership, review the below criteria and complete the ECP Request Form . CyVerse does not provide funding support for external projects.","title":"Leverage CyVerse Services"},{"location":"powered_by/#leveraging-cyverse-services","text":"CyVerse public platform provides a nominal quantity of compute and data storage to all of our users. For researchers who need more, we also provide mechanisms for extending and powering your research.","title":"Leveraging CyVerse Services"},{"location":"powered_by/#professional-services","text":"CyVerse offers a suite of services for institutions seeking to deploy CyVerse's cyberinfrastructure locally. With a secure, shared data management and computing environment with increased speed and performance, a local installation can better support your members' research and teaching needs for: Security compliance (e.g., HIPAA, ITAR, ISO, etc.) Federation with local and commercial cloud and high-performance computing Integration with local user identity management systems Our professional services include installation, maintenance, and training for local installations of CyVerse. Because CyVerse fully supports open source practices, you can access all of our open source infrastructure code and architecture diagrams on Github . Contact Us if you're interested in knowing more.","title":"Professional Services"},{"location":"powered_by/#powered-by-cyverse","text":"Through our unique Powered by CyVerse program, third-party projects can leverage CyVerse cyberinfrastructure to provide their users with robust services such as secure single sign-on with authentication, easy and fast data transfers, access to large-scale, High-Performance Compute resources such as Jetstream or XSEDE, as well as expertise from developers and domain scientists.","title":"Powered by CyVerse"},{"location":"powered_by/#external-collaborative-partnership","text":"External Collaborative Partnerships (ECP) pair you with an expert staff member to address the computational needs of your specific scientific project. To be considered for a partnership, review the below criteria and complete the ECP Request Form . CyVerse does not provide funding support for external projects.","title":"External Collaborative Partnership"},{"location":"what_is_cyverse/","text":"What is CyVerse? \u00b6 CyVerse is a powerful computational infrastructure and the people who support its operations. CyVerse was built to handle huge datasets and complex analyses for life sciences research, thus enabling users to make data-driven discoveries. CyVerse cyberinfrastructure includes: Data Storage - free allocation space for all users, and fee-based storage services, contact us to help you scale your project. Data Science Workbench - An interactive, web-based, analytical platform called the \" Discovery Environment \" Cloud - hosted OpenStack virtual machines for computation, analysis, and storage. External Collaborative Partnerships - Work with our experienced data scientists and software engineers to scale your algorithms and data onto cloud and high performance compute. Contact Us if you are interested in starting an ECP. Education and Training - learn how to use containers, workflows, and public research cyberinfrastructure from our professional trainers. Cloud Resources for running your class or workshop in the cloud. Funding and Citations: CyVerse is funded entirely by the National Science Foundation under Award Numbers: Please cite CyVerse appropriately when you make use of our resources, see CyVerse citation policy .","title":"What is CyVerse?"},{"location":"what_is_cyverse/#what-is-cyverse","text":"CyVerse is a powerful computational infrastructure and the people who support its operations. CyVerse was built to handle huge datasets and complex analyses for life sciences research, thus enabling users to make data-driven discoveries. CyVerse cyberinfrastructure includes: Data Storage - free allocation space for all users, and fee-based storage services, contact us to help you scale your project. Data Science Workbench - An interactive, web-based, analytical platform called the \" Discovery Environment \" Cloud - hosted OpenStack virtual machines for computation, analysis, and storage. External Collaborative Partnerships - Work with our experienced data scientists and software engineers to scale your algorithms and data onto cloud and high performance compute. Contact Us if you are interested in starting an ECP. Education and Training - learn how to use containers, workflows, and public research cyberinfrastructure from our professional trainers. Cloud Resources for running your class or workshop in the cloud. Funding and Citations: CyVerse is funded entirely by the National Science Foundation under Award Numbers: Please cite CyVerse appropriately when you make use of our resources, see CyVerse citation policy .","title":"What is CyVerse?"},{"location":"bisque/","text":"Analyze Images with BisQue \u00b6 ViQi SaaS offering is based on the BisQue (Bio-Image Semantic Query User Environment) project, initially developed at UCSB with support from NSF and iPlant Collaborative. ViQi Inc is the current maintainer and license authority for the BisQue project. BisQue allows users to: Exchange, explore, and analyze biological images and their metadata. Image data analysis and management CyVerse BisQue Manual Request access to BisQue through the User Portal","title":"Analyze Images with BisQue"},{"location":"bisque/#analyze-images-with-bisque","text":"ViQi SaaS offering is based on the BisQue (Bio-Image Semantic Query User Environment) project, initially developed at UCSB with support from NSF and iPlant Collaborative. ViQi Inc is the current maintainer and license authority for the BisQue project. BisQue allows users to: Exchange, explore, and analyze biological images and their metadata. Image data analysis and management CyVerse BisQue Manual Request access to BisQue through the User Portal","title":"Analyze Images with BisQue"},{"location":"cloud/","text":"Cloud Services \u00b6 CyVerse offers two types of cloud service: Continuous Analysis via CACAO Event Driven Services via DataWatch CyVerse is partnered with Jetstream 2 to develop its web interface, and to manage cloud-native applications such as Terraform, Argo Workflows, and Kubernetes. Access to Jetstream 2 login is managed through XSEDE . Continuous Analysis \u00b6 CyVerse has built continuous frameworks for its own Atmosphere cloud and for Jetstream 2 CACAO is a project enabling Continuous Analysis on Kubernetes clusters.","title":"Cloud Services"},{"location":"cloud/#cloud-services","text":"CyVerse offers two types of cloud service: Continuous Analysis via CACAO Event Driven Services via DataWatch CyVerse is partnered with Jetstream 2 to develop its web interface, and to manage cloud-native applications such as Terraform, Argo Workflows, and Kubernetes. Access to Jetstream 2 login is managed through XSEDE .","title":"Cloud Services"},{"location":"cloud/#continuous-analysis","text":"CyVerse has built continuous frameworks for its own Atmosphere cloud and for Jetstream 2 CACAO is a project enabling Continuous Analysis on Kubernetes clusters.","title":"Continuous Analysis"},{"location":"cloud/atmo/","text":"Using Atmosphere \u00b6 Goal \u00b6 Atmosphere is one of the most versatile components of the CyVerse CI. Anything that you would normally be able to do with your local laptop/desktop, you can do on a virtual machine in the Atmosphere cloud. This guide will cover the basics you need to get started using Atmosphere. For the full documentation, see the Atmosphere Manual on the CyVerse wiki. Prerequisites \u00b6 In order to complete this tutorial you will need access to the following services/software Prerequisite Preparation/Notes Link/Download CyVerse account You will need a CyVerse account to complete this exercise Register Atmosphere Access Atmosphere access is by request only Check or request access: CyVerse User Portal iCommands (Optional) While you don\u2019t have to have iCommands installed, the transferring data section of this guide assumes familiarity with iCommands. You may wish to complete the iCommands tutorial, and you may wish to install iCommands on a local machine if you want to transfer data from that machine to an Atmosphere instance iCommands Guide , iCommands Download links Terminal or SSH client (Optional) You can connect via Webshell to an Atmosphere instance from a web browser. Alternatively, you can connect via SSH from a Mac or Linux computer. If you are using Windows, we suggest a SSH client. Windows compatible SSH client (Optional) PuTTY VNC Viewing Client (Optional) You can connect to a desktop-enabled Atmosphere instance from a web browser. Alternatively you can connect via a VNC viewing client such as Real VNC viewer. Download Real VNC Viewer for your OS Important To request access to Atmosphere, login to the CyVerse User Portal . In the Services Menu under \u2018MY SERVICES\u2019 you should see Atmosphere listed as an option you can launch. If not, look under the Available menu, and click the \u2018REQUEST ACCESS\u2019 link. You will receive an email requesting additional information. To qualify for an Atmosphere account, your CyVerse account must be associated with an institutional email address (e.g. .edu;.org;.gov). Logging in to Atmosphere \u00b6 Atmosphere presents a variety of features, starting with the Atmosphere Dashboard you will see at login. While it may be slightly overwhelming, we will focus on the features a first-time user would likely interact with. Return to the Learning Center and Atmosphere Manual to learn more about the advanced features not covered here. Some things to remember about the platform You must have access to Atmosphere to launch an instance. If you are not sure you have access, go back to the instructions at the beginning of this guide Atmosphere works on a very transparent allocation model. Every user has a defined amount of resources (CPUs, disk space, etc.) and time they can use these resources. We are always happy to work with users to increase these allocations, but ultimately there are limits. You can be a good community member by only using resources when you need them, and not leaving instances aimlessly running (the proverbial \u2018leaving the lights on\u2019). Logging on and viewing your resources \u00b6 Login to Atmosphere at https://atmo.cyverse.org/ and click the \u2018Login\u2019 link on the upper right-hand side of the screen. Enter your CyVerse credential and sign in. Upon login, you will be directed to the Atmosphere Dashboard. Much more about all the dashboard features is available in the Atmosphere Manual , but you can see the number of instances you have running, and percent of your allocation used. You can also see an history of instances launched. Tip Your allocation (a measure of how many instances you have running, their size, and the amount of time they have been active) automatically refreshes monthly. If you run out of allocation, you can click the need_more \u2018NEED MORE?\u2019 button to request an increase. When you exceed your allocation, your instances are suspended. You will not lose saved data, but running processes will be stopped. See the Atmosphere section in the [CyVerse service-level agreement](http://www.cyverse.org/service-level-agreement#Atmo) for details and definitions related to our allocation policies. Creating a Project and Launching an Instance \u00b6 Atmosphere makes it easy to launch an instance (virtual machine), but your work is more than just a computer - it is data and software. To that end, Atmosphere helps you organize your work into a project. A project contains one or more instances, and may contain several (or no) volumes (datasets) or images (\u201csaved\u201d instances). Definitions: Instance: An instance is a running virtual machine. You request from Atmosphere a CPUs, disk space, and memory, and you are temporarily allocated these physical resources to \u201cbuild\u201d your virtual computer (virtual machine). Image: An image is a file that contains an operating system, and any other data that was saved at the time of imaging (creating the image file). If we saved everything on your computer to an image file, we could clone your computer onto a new device and you would not have to reinstall any software. Your files, system preferences, etc. would all be saved. Volume: Volume: A volume is a \u201cvirtual disk\u201d that you can attach and detach to your instance, like a thumb drive. Normally, when you start an instance, you need to transfer data onto it. While the data transfer may be quick, it usually takes time. A volume is nearly instantaneous. Although it is virtual you can keep a volume persistently in Atmosphere, and attach and detach as needed to any instance. Note For our purpose, the terms \u201cinstance\u201d and \u201cvirtual machine\u201d are used interchangeably in this guide. Creating a Project \u00b6 Log in to Atmosphere . Click on the Projects menu at the top of the page; the click on the \u2018CREATE NEW PROJECT\u2019 button; give your project a name and description and click \u2018CREATE\u2019. From the Projects page, you will see a listing of existing projects and the number of instance, images, volumes, and links associated with these projects. Launching an Instance \u00b6 On the Projects page, click on an existing project to launch the instance as part of that project. If necessary, create a new project using the directions above. From your project\u2019s individual page, click on the NEW button and select \u2018Instance\u2019. Search through the available instances in the \u2018Launch an Instance/Select an Image\u2019 window. Tip You can search the image catalogue at any time from the Image Search page. Click on the \u2018Images\u2019 link at the top of the Atmosphere page. Most images have tags to help you identify the installed software. You can also click on an image listing to get additional details and descriptions. Since Most images are community-developed, the documentation is only as good as what is provided by the image owner. Search the catalog for the CyVerse Training Workshop image. To launch an instance now, click \u2018LAUNCH INSTANCE\u2019. Alternatively, you can name your image, or adjust other settings including the project, and instances size before clicking the launch button. Note If you are trying Atmosphere for the first time, we recommend using the default \u2018tiny1\u2019 instance size. Also note, that the largest instance sizes are limited and may not be available at any given time based on demand. Once your instance is launched, your project page will display the status of all instances. Instances are typically available within 10-15 minutes. You can only connect to an instance when the status displayed is \u2018Active\u2019. Connecting to an Instance \u00b6 Once your instance is in the \u2018Active\u2019 state, you can connect to the instance. All instances support connection at the command line via SSH. Many (but not all) instances may also have a graphical desktop. You can connect to these desktops via a VNC viewing client. We will cover both methods in this guide. Connect to Atmosphere Instance using SSH \u00b6 Connecting using Mac or Linux Terminal \u00b6 If necessary, login to Atmosphere and locate the instance you are connecting to in a given project. Locate the IP address and copy this to your clipboard. Open your computer\u2019s terminal application. Connect via SSH: $ ssh your_cyverse_username @your . atmosphere . ip . address ! If connecting for the first time , you may be get a security prompt The authenticity of host '128.196.64.200 (128.196.64.200)' can \\ 't be established. ECDSA key fingerprint is SHA256 : fzEJLqeljHgIwcGY0gUap2sRWLlGPQwUVimhEgkJYBs . Are you sure you want to continue connecting ( yes / no ) ? ! you may accept this prompt by typing yes You will be prompted to enter your CyVerse password Tip Your cursor will not move or indicate you are typing as you enter your password. If you make a mistake, hit enter and you will be prompted again. You should now be connected to your Atmosphere instance. Connecting using Windows and PuTTY \u00b6 If necessary, login to Atmosphere and locate the instance you are connecting to in a given project. Locate the IP address and copy this to your clipboard. Open \u2018PuTTY.exe\u2019 and paste the IP address into the \u2018Host Name (or IP address s)\u2019 field; click \u2018Open\u2019 Note If this is your first time connecting, you may get a security prompt that the server\u2019s host key is not cached in the registry. You may click \u2018Yes\u2019 to continue connecting. When prompted, enter your CyVerse username for the request to \u2018login as:\u2019 and enter your CyVerse password to connect. Tip Your cursor will not move or indicate you are typing as you enter your password. If you make a mistake, hit enter and you will be prompted again. Connect to Atmosphere Instance using VNC viewer \u00b6 Note You can only connect to an Atmosphere instance that has a desktop installed and has a running VNC server. Usually this information is in the image description. If you are unsure, or having difficulty in connecting to and instance you believe should have a desktop, contact Atmosphere support. If you have not already done so, download Real VNC Viewer . If necessary, login to Atmosphere and locate the instance you are connecting to in a given project. Locate the IP address and copy this to your clipboard. Open VNC Viewer. Paste your IP address + \u201c:1\u201d in the \u2018VNC Server\u2019 field (e.g. 161.803.39.887:1) and click connect. Note When connecting for the first time to an instance, you will be prompted to save a signature When prompted, ensure your username entered is your CyVerse username. Enter your CyVerse password and click Ok. You should now be connected to your instance desktop. Transferring Data to and from an Instance \u00b6 An Atmosphere instance only contains data that were included in the original image that was used to make that instance. You can transfer data to/from the CyVerse Data Store, an Atmosphere Volume, a sever, or your local machine. In this guide, we will only cover data transfer using iCommands. iCommands is installed on every Atmosphere instance. Related Links - iCommands Guide - iCommands Download Transferring Data to/from an Instance using iCommands \u00b6 You can execute to the instance\u2019s icommand if you are connected via SSH/PuTTY or if you are connected to the desktop via VNC, open the instance\u2019s terminal application. At the instance\u2019s terminal, start the iCommands configuration using the \u2018iinit\u2019 command and enter configure. Important This configuration is a one-time step on your first use with this instance. ``` py $ iinit ! As prompted, enter the following values: ! Host: data.cyverse.org ! Port: 1247 ! User: your_cyverse_username ! Zone: iplant ! Password: your_cyverse_password If you make a mistake in your configuration you can edit ~/.irods/irods_environment.json on your instance. Test your configuration by listing your Data Store contents with the \u201cils\u201d command. $ ils Tip If you made a mistake during the configuration, you can edit your icommands configuration file. To download a file from the Data Store to your instance, use \u201ciget\u201d $ iget data_store_file To upload file from your instance to the Data Store use \u201ciput\u201d $ iget file_on_instance location_on_data_store Tip iCommands has a variety of options, to see progress of transfers, operate recursively, and more. See additional iCommands documentation on the CyVerse wiki. Terminating an Instance \u00b6 Once you have finished with your Atmosphere instance you will need to terminate this instance. If you are not done with the instance and will use it again in a short amount of time, you can stop or suspend that instance. For more on these options, see the Atmosphere manual . Terminating an Instance \u00b6 Warning Once an instance is terminated, all data on that instance is unrecoverable. Ensure that any data you wish to save is transferred to a persistent location such as the CyVerse Data Store or an Atmosphere volume. If necessary, login to Atmosphere and locate the instance you are terminating in a given project. Click on the instance name to get to that instances page. You should see an \u201cActions\u201d menu on the right-hand side of the page. Click Delete to terminate the instance; read the warning, and click \u2018YES, DELETE THIS INSTANCE\u2019 when you are ready to proceed - remember all data still on this instance will be lost. Summary \u00b6 This guide has taken you through the absolute basics needed to start using Atmosphere. There is a lot more to learn, and many more capabilities than described here. We encourage you to look through the full manual to learn more.","title":"Using Atmosphere"},{"location":"cloud/atmo/#using-atmosphere","text":"","title":"Using Atmosphere"},{"location":"cloud/atmo/#goal","text":"Atmosphere is one of the most versatile components of the CyVerse CI. Anything that you would normally be able to do with your local laptop/desktop, you can do on a virtual machine in the Atmosphere cloud. This guide will cover the basics you need to get started using Atmosphere. For the full documentation, see the Atmosphere Manual on the CyVerse wiki.","title":"Goal"},{"location":"cloud/atmo/#prerequisites","text":"In order to complete this tutorial you will need access to the following services/software Prerequisite Preparation/Notes Link/Download CyVerse account You will need a CyVerse account to complete this exercise Register Atmosphere Access Atmosphere access is by request only Check or request access: CyVerse User Portal iCommands (Optional) While you don\u2019t have to have iCommands installed, the transferring data section of this guide assumes familiarity with iCommands. You may wish to complete the iCommands tutorial, and you may wish to install iCommands on a local machine if you want to transfer data from that machine to an Atmosphere instance iCommands Guide , iCommands Download links Terminal or SSH client (Optional) You can connect via Webshell to an Atmosphere instance from a web browser. Alternatively, you can connect via SSH from a Mac or Linux computer. If you are using Windows, we suggest a SSH client. Windows compatible SSH client (Optional) PuTTY VNC Viewing Client (Optional) You can connect to a desktop-enabled Atmosphere instance from a web browser. Alternatively you can connect via a VNC viewing client such as Real VNC viewer. Download Real VNC Viewer for your OS Important To request access to Atmosphere, login to the CyVerse User Portal . In the Services Menu under \u2018MY SERVICES\u2019 you should see Atmosphere listed as an option you can launch. If not, look under the Available menu, and click the \u2018REQUEST ACCESS\u2019 link. You will receive an email requesting additional information. To qualify for an Atmosphere account, your CyVerse account must be associated with an institutional email address (e.g. .edu;.org;.gov).","title":"Prerequisites"},{"location":"cloud/atmo/#logging-in-to-atmosphere","text":"Atmosphere presents a variety of features, starting with the Atmosphere Dashboard you will see at login. While it may be slightly overwhelming, we will focus on the features a first-time user would likely interact with. Return to the Learning Center and Atmosphere Manual to learn more about the advanced features not covered here. Some things to remember about the platform You must have access to Atmosphere to launch an instance. If you are not sure you have access, go back to the instructions at the beginning of this guide Atmosphere works on a very transparent allocation model. Every user has a defined amount of resources (CPUs, disk space, etc.) and time they can use these resources. We are always happy to work with users to increase these allocations, but ultimately there are limits. You can be a good community member by only using resources when you need them, and not leaving instances aimlessly running (the proverbial \u2018leaving the lights on\u2019).","title":"Logging in to Atmosphere"},{"location":"cloud/atmo/#logging-on-and-viewing-your-resources","text":"Login to Atmosphere at https://atmo.cyverse.org/ and click the \u2018Login\u2019 link on the upper right-hand side of the screen. Enter your CyVerse credential and sign in. Upon login, you will be directed to the Atmosphere Dashboard. Much more about all the dashboard features is available in the Atmosphere Manual , but you can see the number of instances you have running, and percent of your allocation used. You can also see an history of instances launched. Tip Your allocation (a measure of how many instances you have running, their size, and the amount of time they have been active) automatically refreshes monthly. If you run out of allocation, you can click the need_more \u2018NEED MORE?\u2019 button to request an increase. When you exceed your allocation, your instances are suspended. You will not lose saved data, but running processes will be stopped. See the Atmosphere section in the [CyVerse service-level agreement](http://www.cyverse.org/service-level-agreement#Atmo) for details and definitions related to our allocation policies.","title":"Logging on and viewing your resources"},{"location":"cloud/atmo/#creating-a-project-and-launching-an-instance","text":"Atmosphere makes it easy to launch an instance (virtual machine), but your work is more than just a computer - it is data and software. To that end, Atmosphere helps you organize your work into a project. A project contains one or more instances, and may contain several (or no) volumes (datasets) or images (\u201csaved\u201d instances). Definitions: Instance: An instance is a running virtual machine. You request from Atmosphere a CPUs, disk space, and memory, and you are temporarily allocated these physical resources to \u201cbuild\u201d your virtual computer (virtual machine). Image: An image is a file that contains an operating system, and any other data that was saved at the time of imaging (creating the image file). If we saved everything on your computer to an image file, we could clone your computer onto a new device and you would not have to reinstall any software. Your files, system preferences, etc. would all be saved. Volume: Volume: A volume is a \u201cvirtual disk\u201d that you can attach and detach to your instance, like a thumb drive. Normally, when you start an instance, you need to transfer data onto it. While the data transfer may be quick, it usually takes time. A volume is nearly instantaneous. Although it is virtual you can keep a volume persistently in Atmosphere, and attach and detach as needed to any instance. Note For our purpose, the terms \u201cinstance\u201d and \u201cvirtual machine\u201d are used interchangeably in this guide.","title":"Creating a Project and Launching an Instance"},{"location":"cloud/atmo/#creating-a-project","text":"Log in to Atmosphere . Click on the Projects menu at the top of the page; the click on the \u2018CREATE NEW PROJECT\u2019 button; give your project a name and description and click \u2018CREATE\u2019. From the Projects page, you will see a listing of existing projects and the number of instance, images, volumes, and links associated with these projects.","title":"Creating a Project"},{"location":"cloud/atmo/#launching-an-instance","text":"On the Projects page, click on an existing project to launch the instance as part of that project. If necessary, create a new project using the directions above. From your project\u2019s individual page, click on the NEW button and select \u2018Instance\u2019. Search through the available instances in the \u2018Launch an Instance/Select an Image\u2019 window. Tip You can search the image catalogue at any time from the Image Search page. Click on the \u2018Images\u2019 link at the top of the Atmosphere page. Most images have tags to help you identify the installed software. You can also click on an image listing to get additional details and descriptions. Since Most images are community-developed, the documentation is only as good as what is provided by the image owner. Search the catalog for the CyVerse Training Workshop image. To launch an instance now, click \u2018LAUNCH INSTANCE\u2019. Alternatively, you can name your image, or adjust other settings including the project, and instances size before clicking the launch button. Note If you are trying Atmosphere for the first time, we recommend using the default \u2018tiny1\u2019 instance size. Also note, that the largest instance sizes are limited and may not be available at any given time based on demand. Once your instance is launched, your project page will display the status of all instances. Instances are typically available within 10-15 minutes. You can only connect to an instance when the status displayed is \u2018Active\u2019.","title":"Launching an Instance"},{"location":"cloud/atmo/#connecting-to-an-instance","text":"Once your instance is in the \u2018Active\u2019 state, you can connect to the instance. All instances support connection at the command line via SSH. Many (but not all) instances may also have a graphical desktop. You can connect to these desktops via a VNC viewing client. We will cover both methods in this guide.","title":"Connecting to an Instance"},{"location":"cloud/atmo/#connect-to-atmosphere-instance-using-ssh","text":"","title":"Connect to Atmosphere Instance using SSH"},{"location":"cloud/atmo/#connecting-using-mac-or-linux-terminal","text":"If necessary, login to Atmosphere and locate the instance you are connecting to in a given project. Locate the IP address and copy this to your clipboard. Open your computer\u2019s terminal application. Connect via SSH: $ ssh your_cyverse_username @your . atmosphere . ip . address ! If connecting for the first time , you may be get a security prompt The authenticity of host '128.196.64.200 (128.196.64.200)' can \\ 't be established. ECDSA key fingerprint is SHA256 : fzEJLqeljHgIwcGY0gUap2sRWLlGPQwUVimhEgkJYBs . Are you sure you want to continue connecting ( yes / no ) ? ! you may accept this prompt by typing yes You will be prompted to enter your CyVerse password Tip Your cursor will not move or indicate you are typing as you enter your password. If you make a mistake, hit enter and you will be prompted again. You should now be connected to your Atmosphere instance.","title":"Connecting using Mac or Linux Terminal"},{"location":"cloud/atmo/#connecting-using-windows-and-putty","text":"If necessary, login to Atmosphere and locate the instance you are connecting to in a given project. Locate the IP address and copy this to your clipboard. Open \u2018PuTTY.exe\u2019 and paste the IP address into the \u2018Host Name (or IP address s)\u2019 field; click \u2018Open\u2019 Note If this is your first time connecting, you may get a security prompt that the server\u2019s host key is not cached in the registry. You may click \u2018Yes\u2019 to continue connecting. When prompted, enter your CyVerse username for the request to \u2018login as:\u2019 and enter your CyVerse password to connect. Tip Your cursor will not move or indicate you are typing as you enter your password. If you make a mistake, hit enter and you will be prompted again.","title":"Connecting using Windows and PuTTY"},{"location":"cloud/atmo/#connect-to-atmosphere-instance-using-vnc-viewer","text":"Note You can only connect to an Atmosphere instance that has a desktop installed and has a running VNC server. Usually this information is in the image description. If you are unsure, or having difficulty in connecting to and instance you believe should have a desktop, contact Atmosphere support. If you have not already done so, download Real VNC Viewer . If necessary, login to Atmosphere and locate the instance you are connecting to in a given project. Locate the IP address and copy this to your clipboard. Open VNC Viewer. Paste your IP address + \u201c:1\u201d in the \u2018VNC Server\u2019 field (e.g. 161.803.39.887:1) and click connect. Note When connecting for the first time to an instance, you will be prompted to save a signature When prompted, ensure your username entered is your CyVerse username. Enter your CyVerse password and click Ok. You should now be connected to your instance desktop.","title":"Connect to Atmosphere Instance using VNC viewer"},{"location":"cloud/atmo/#transferring-data-to-and-from-an-instance","text":"An Atmosphere instance only contains data that were included in the original image that was used to make that instance. You can transfer data to/from the CyVerse Data Store, an Atmosphere Volume, a sever, or your local machine. In this guide, we will only cover data transfer using iCommands. iCommands is installed on every Atmosphere instance. Related Links - iCommands Guide - iCommands Download","title":"Transferring Data to and from an Instance"},{"location":"cloud/atmo/#transferring-data-tofrom-an-instance-using-icommands","text":"You can execute to the instance\u2019s icommand if you are connected via SSH/PuTTY or if you are connected to the desktop via VNC, open the instance\u2019s terminal application. At the instance\u2019s terminal, start the iCommands configuration using the \u2018iinit\u2019 command and enter configure. Important This configuration is a one-time step on your first use with this instance. ``` py $ iinit ! As prompted, enter the following values: ! Host: data.cyverse.org ! Port: 1247 ! User: your_cyverse_username ! Zone: iplant ! Password: your_cyverse_password If you make a mistake in your configuration you can edit ~/.irods/irods_environment.json on your instance. Test your configuration by listing your Data Store contents with the \u201cils\u201d command. $ ils Tip If you made a mistake during the configuration, you can edit your icommands configuration file. To download a file from the Data Store to your instance, use \u201ciget\u201d $ iget data_store_file To upload file from your instance to the Data Store use \u201ciput\u201d $ iget file_on_instance location_on_data_store Tip iCommands has a variety of options, to see progress of transfers, operate recursively, and more. See additional iCommands documentation on the CyVerse wiki.","title":"Transferring Data to/from an Instance using iCommands"},{"location":"cloud/atmo/#terminating-an-instance","text":"Once you have finished with your Atmosphere instance you will need to terminate this instance. If you are not done with the instance and will use it again in a short amount of time, you can stop or suspend that instance. For more on these options, see the Atmosphere manual .","title":"Terminating an Instance"},{"location":"cloud/atmo/#terminating-an-instance_1","text":"Warning Once an instance is terminated, all data on that instance is unrecoverable. Ensure that any data you wish to save is transferred to a persistent location such as the CyVerse Data Store or an Atmosphere volume. If necessary, login to Atmosphere and locate the instance you are terminating in a given project. Click on the instance name to get to that instances page. You should see an \u201cActions\u201d menu on the right-hand side of the page. Click Delete to terminate the instance; read the warning, and click \u2018YES, DELETE THIS INSTANCE\u2019 when you are ready to proceed - remember all data still on this instance will be lost.","title":"Terminating an Instance"},{"location":"cloud/atmo/#summary","text":"This guide has taken you through the absolute basics needed to start using Atmosphere. There is a lot more to learn, and many more capabilities than described here. We encourage you to look through the full manual to learn more.","title":"Summary"},{"location":"de/","text":"Run Analyses with the Discovery Environment \u00b6 The Discovery Environment (DE) is an all-purpose informatics workspace, with an interface tailored to the needs of researchers with data to analyze but who may lack command line expertise or the compute resources to run software tools and analyses. All data (yours, shared, and public) are stored in CyVerse's cloud-based Data Store and are accessible from anywhere in CyVerse, including the DE . All analyses run on CyVerse's cloud and High Performance Computing resources, enabling you to run analyses, small to large, beyond what your personal computer can typically handle. For most tasks (e.g., launching an app or importing data from a URL) you can log out or navigate to another page or operation after you start the task; an automated email notification is sent to you when the task is completed.","title":"Run Analyses with the Discovery Environment"},{"location":"de/#run-analyses-with-the-discovery-environment","text":"The Discovery Environment (DE) is an all-purpose informatics workspace, with an interface tailored to the needs of researchers with data to analyze but who may lack command line expertise or the compute resources to run software tools and analyses. All data (yours, shared, and public) are stored in CyVerse's cloud-based Data Store and are accessible from anywhere in CyVerse, including the DE . All analyses run on CyVerse's cloud and High Performance Computing resources, enabling you to run analyses, small to large, beyond what your personal computer can typically handle. For most tasks (e.g., launching an app or importing data from a URL) you can log out or navigate to another page or operation after you start the task; an automated email notification is sent to you when the task is completed.","title":"Run Analyses with the Discovery Environment"},{"location":"de/bags/","text":"Sharing and Using Bags in the Discovery Environment \u00b6 You can share data, apps, and analyses using the sharing features with one or more CyVerse users through the Discovery Environment . The Bag is a handy feature in the DE that you can use to gather and download or share multiple data files, apps, and analyses or any combination of those resources with another user(s). There is no limit to the number of items you can put in a bag but you can only share files you own. Sharing Data in the Discovery Environment \u00b6 You must be logged in to share resources. Open the Data view of your home directory by clicking on in the left sidebar. Select the data resource(s) you wish to share; then click the \"Share\" button. In the Sharing dialog that opens, check that the resources you wish to share are shown. In the Search checkbox, search for the CyVerse user(s) you wish to share with by typing their full CyVerse username or email address. Subsequent searches will more quickly find names from your previous \"Shared with\" lists. Next, under \"Permission\", choose which type of permission to grant the person(s) you are sharing resources with. You can also \"Remove\" access using the Permission dialog box. When you are finished, click \"Done\" to begin sharing. The user(s) will be notified that resources have been shared with them and will see the shared item(s) in their \"Shared With Me\" folder when they log in. Managing Data Permissions Permission level Read Download/Save Metadata Rename Move Delete Read X X View Write X X Add/Edit Own X X Add/Edit X X X Sharing Apps in the Discovery Environment \u00b6 You must be logged in to share resources. Open the Apps view by clicking on the (app icon) in the left sidebar. Select your app(s) or app(s) you are building that you wish to share with another user(s) or your team; then click the Share button. In the Sharing dialog that opens, check that the app(s) you wish to share is shown. In the Search box at the top of the page, start typing the CyVerse username, team name, or email address of the CyVerse user(s) with whom you want to share. Search will start when you enter at least three characters. There is no limit to how many users you can share files and analyses with. Next, under \"Permission\", choose which type of permission you want to grant the person(s) or team you are sharing the app(s) with. Once you are finished, click \"Done\" to begin sharing. The user(s) will be notified that app(s) have been shared with them when they log in. Managing App Permissions Permissions (based on UNIX permissions) are described in this chart: Permission level Launch Edit Share Make Public Read X Write X X Own X X X X Sharing Analyses in the Discovery Environment \u00b6 You must be logged in to share resources. Open the Analyses view by clicking on the (analyses icon) in the left sidebar. Select one or more analyses you wish to share with another user(s); then click the Share button in the upper right corner of the page. In the Sharing dialog that opens, ensure that the analyses you wish to share are shown under Resources. In the Search box at the top of the page, search for the CyVerse user(s) you wish to share with by typing their full CyVerse username, team name or email address. Search will begin when you have typed at least three characters. Click the desired user(s). There is no limit to how many users you can share analyses with. Next, under \"Permission\", choose which type of permission to grant the person(s) you are sharing the analyses with. When you are finished, click \"Done\" to begin sharing. The user(s) will be notified that analyses have been shared with them when they log in. Manage Analyses Permissions Permission level Read Download/Save Metadata Rename Move Delete Read X X View Write X X Add/Edit Own X X Add/Edit X X X Using a Bag to Share or Download in the Discovery Environment \u00b6 You can share or download multiple items using the feature in the Discovery Environment. You must be logged in to use a bag. There is no limit to the number of items you can share in a bag. To share file(s) using a bag, open the Data, Apps or the Analyses view (or each consecutively), select one or more files, and click \"Add to Bag\" in the upper right corner. A red dot will appear on the (bag icon) to show how many resources are currently in the bag. When you've finished adding all the files (data, apps or analyses) you want to share in the bag, share the bag with another CyVerse user(s) by clicking on the (bag icon). In the dialog box that opens, all the files you have put in the bag are listed by default. Use the dropdown arrow to show downloadable or shareable files. You can \"Share\" the contents of the bag by clicking on the \"Share\" button. Another dialog box will open where you can set Permissions for the user(s) with whom you are sharing files. To download the bag's contents to your computer, click \"Download\" and then click on each of the links for the files. Sharing or downloading the contents of a bag does not empty the bag. You can share the same contents with another user(s); to empty the bag, click on the (bag icon) then click the \"Clear\" button. Emptying Bags There is no prompt or warning once you click \"Clear\", so the bag will be emptied immediately.","title":"Sharing and Using Bags"},{"location":"de/bags/#sharing-and-using-bags-in-the-discovery-environment","text":"You can share data, apps, and analyses using the sharing features with one or more CyVerse users through the Discovery Environment . The Bag is a handy feature in the DE that you can use to gather and download or share multiple data files, apps, and analyses or any combination of those resources with another user(s). There is no limit to the number of items you can put in a bag but you can only share files you own.","title":"Sharing and Using Bags in the Discovery Environment"},{"location":"de/bags/#sharing-data-in-the-discovery-environment","text":"You must be logged in to share resources. Open the Data view of your home directory by clicking on in the left sidebar. Select the data resource(s) you wish to share; then click the \"Share\" button. In the Sharing dialog that opens, check that the resources you wish to share are shown. In the Search checkbox, search for the CyVerse user(s) you wish to share with by typing their full CyVerse username or email address. Subsequent searches will more quickly find names from your previous \"Shared with\" lists. Next, under \"Permission\", choose which type of permission to grant the person(s) you are sharing resources with. You can also \"Remove\" access using the Permission dialog box. When you are finished, click \"Done\" to begin sharing. The user(s) will be notified that resources have been shared with them and will see the shared item(s) in their \"Shared With Me\" folder when they log in. Managing Data Permissions Permission level Read Download/Save Metadata Rename Move Delete Read X X View Write X X Add/Edit Own X X Add/Edit X X X","title":"Sharing Data in the Discovery Environment"},{"location":"de/bags/#sharing-apps-in-the-discovery-environment","text":"You must be logged in to share resources. Open the Apps view by clicking on the (app icon) in the left sidebar. Select your app(s) or app(s) you are building that you wish to share with another user(s) or your team; then click the Share button. In the Sharing dialog that opens, check that the app(s) you wish to share is shown. In the Search box at the top of the page, start typing the CyVerse username, team name, or email address of the CyVerse user(s) with whom you want to share. Search will start when you enter at least three characters. There is no limit to how many users you can share files and analyses with. Next, under \"Permission\", choose which type of permission you want to grant the person(s) or team you are sharing the app(s) with. Once you are finished, click \"Done\" to begin sharing. The user(s) will be notified that app(s) have been shared with them when they log in. Managing App Permissions Permissions (based on UNIX permissions) are described in this chart: Permission level Launch Edit Share Make Public Read X Write X X Own X X X X","title":"Sharing Apps in the Discovery Environment"},{"location":"de/bags/#sharing-analyses-in-the-discovery-environment","text":"You must be logged in to share resources. Open the Analyses view by clicking on the (analyses icon) in the left sidebar. Select one or more analyses you wish to share with another user(s); then click the Share button in the upper right corner of the page. In the Sharing dialog that opens, ensure that the analyses you wish to share are shown under Resources. In the Search box at the top of the page, search for the CyVerse user(s) you wish to share with by typing their full CyVerse username, team name or email address. Search will begin when you have typed at least three characters. Click the desired user(s). There is no limit to how many users you can share analyses with. Next, under \"Permission\", choose which type of permission to grant the person(s) you are sharing the analyses with. When you are finished, click \"Done\" to begin sharing. The user(s) will be notified that analyses have been shared with them when they log in. Manage Analyses Permissions Permission level Read Download/Save Metadata Rename Move Delete Read X X View Write X X Add/Edit Own X X Add/Edit X X X","title":"Sharing Analyses in the Discovery Environment"},{"location":"de/bags/#using-a-bag-to-share-or-download-in-the-discovery-environment","text":"You can share or download multiple items using the feature in the Discovery Environment. You must be logged in to use a bag. There is no limit to the number of items you can share in a bag. To share file(s) using a bag, open the Data, Apps or the Analyses view (or each consecutively), select one or more files, and click \"Add to Bag\" in the upper right corner. A red dot will appear on the (bag icon) to show how many resources are currently in the bag. When you've finished adding all the files (data, apps or analyses) you want to share in the bag, share the bag with another CyVerse user(s) by clicking on the (bag icon). In the dialog box that opens, all the files you have put in the bag are listed by default. Use the dropdown arrow to show downloadable or shareable files. You can \"Share\" the contents of the bag by clicking on the \"Share\" button. Another dialog box will open where you can set Permissions for the user(s) with whom you are sharing files. To download the bag's contents to your computer, click \"Download\" and then click on each of the links for the files. Sharing or downloading the contents of a bag does not empty the bag. You can share the same contents with another user(s); to empty the bag, click on the (bag icon) then click the \"Clear\" button. Emptying Bags There is no prompt or warning once you click \"Clear\", so the bag will be emptied immediately.","title":"Using a Bag to Share or Download in the Discovery Environment"},{"location":"de/create_apps/","text":"Creating Apps in the Discovery Environment (DE) \u00b6 Why use the DE? \u00b6 Use hundreds of bioinformatics Apps without the command line (or with, if you prefer) Batch and interactive modes Seamlessly integrated with data and high performance computing -- not dependent on your hardware Create and publish Apps and workflows so anyone can use them Analysis history and provenance -- \"avoid forensic bioinformatics\" Securely and easily manage, share, and publish data Types of apps \u00b6 CyVerse tool: Software program that is integrated into the back end of the DE for use in DE apps CyVerse app: graphic interface of a tool made available for use in the DE Executable : user starts an analysis and when the analysis finishes they can find the output files in their /analyses folder DE : run locally on our cluster HPC : labeled as 'Agave' in the DE. Run on XSEDE rsources at Texas Advanced Computing Center (TACC) OSG : run on the Open Science Grid Interactive : also called Visual and Interactive Computing Environment (VICE). Allows users to open Integrated Development Environments (IDEs) including RStudio, Project Jupyter and RShiny and work interactively within them. The (containerized) tool must be integrated into the Cyverse DE first. Then an app (interface) can be built for that tool. Building an App for Your Tool \u00b6 You can build an app for any tool that: is private to you is shared with you is public Note: It is a good idea to check if the tool you want is already integrated before you start. The tool may be there already and you can build an app using it. From the 'Apps' tab click on the 'Manage Tools' button in the upper right. In the 'Manage Tools' interface search for 'porechop' in the search bar at the top. If you find the tool you want then you can build an app using that tool. For more information about the app (including other apps already using this tool) you can select it (using the checkbox to the left) and then click 'details'. Step 1: App Info From the 'Apps' tab click on the 'Create' button in the top right corner and select 'Add App'. Choose an informative app name and description (eg. tool name and version). Select the tool you want to build the app on buy clicking the 'select' button. This will open the 'search tools' window. Search for and select your tool. Step 2: Parameters Divide the app into sections appropriate for that tool (input, options and output are usually sufficient sections for simple apps). You can add a section by clicking on the 'Add Section'. Once you have added a section you can edit the name by clicking on the pencil icon (right side). Within a section you can add the parameters necessary for your tool by clicking on 'Add Parameter' and choosing the type of parameter you want to add (e.g. input file). For each option you add, you will need to specify what the option is, the argument option (if there is one) and whether that option is required. If an option is not required be sure to check the 'exclude if nothing is entered' box. For tools that have positional agruments (no argument option, eg. -i) you can leave argument option blank but you will need to make sure your arguments are in the proper order in step 4. Note: Although it is best to add all of the options for your tool, as it makes the app the most useful, you can expose as many or as few options as you like (as long as you add all the required options). Step 3: Preview App Make sure your app looks the way you want it to and that you have included all of the required options. If you need to make changes use the back button to return to the previous step. Step 4: Command Line Order This will provide a preview of what your options will look like on the command line. In the list of options below, use the up and down arrows to the right of the option to move it up or down in the list. You should see these changes reflected in the command line preview box. This order is especially important if your tool uses positional arguments. Step 5: Completion Click 'Save' (upper right) to save your work. Then click 'Launch App' at the bottom of the page and test your app with appropriate data. If you need to make changes to your app after testing, you can find it under the 'Apps under development' section of the 'Apps' tab. Click on the three dots menu (to the right of your app) and select 'edit app'. This will re-open the apps editor and allow you to make changes. Once you know your app works correctly you can share or publish it as you wish. Public apps must have example data located in an appropriately named folder here: `/iplant/home/shared/iplantcollaborative/example_data` All public apps also have a brief documentation page on the CyVerse Wiki To publish your app click on the three dots menu (at the right of your app) and select 'Publish'. You will need to supply: location of the example data brief description of inputs, required options and outputs link to CyVerse Wiki documentation page link to docmentation for the tool (provided by the developers)","title":"Create DE Apps"},{"location":"de/create_apps/#creating-apps-in-the-discovery-environment-de","text":"","title":"Creating Apps in the Discovery Environment (DE)"},{"location":"de/create_apps/#why-use-the-de","text":"Use hundreds of bioinformatics Apps without the command line (or with, if you prefer) Batch and interactive modes Seamlessly integrated with data and high performance computing -- not dependent on your hardware Create and publish Apps and workflows so anyone can use them Analysis history and provenance -- \"avoid forensic bioinformatics\" Securely and easily manage, share, and publish data","title":"Why use the DE?"},{"location":"de/create_apps/#types-of-apps","text":"CyVerse tool: Software program that is integrated into the back end of the DE for use in DE apps CyVerse app: graphic interface of a tool made available for use in the DE Executable : user starts an analysis and when the analysis finishes they can find the output files in their /analyses folder DE : run locally on our cluster HPC : labeled as 'Agave' in the DE. Run on XSEDE rsources at Texas Advanced Computing Center (TACC) OSG : run on the Open Science Grid Interactive : also called Visual and Interactive Computing Environment (VICE). Allows users to open Integrated Development Environments (IDEs) including RStudio, Project Jupyter and RShiny and work interactively within them. The (containerized) tool must be integrated into the Cyverse DE first. Then an app (interface) can be built for that tool.","title":"Types of apps"},{"location":"de/create_apps/#building-an-app-for-your-tool","text":"You can build an app for any tool that: is private to you is shared with you is public Note: It is a good idea to check if the tool you want is already integrated before you start. The tool may be there already and you can build an app using it. From the 'Apps' tab click on the 'Manage Tools' button in the upper right. In the 'Manage Tools' interface search for 'porechop' in the search bar at the top. If you find the tool you want then you can build an app using that tool. For more information about the app (including other apps already using this tool) you can select it (using the checkbox to the left) and then click 'details'. Step 1: App Info From the 'Apps' tab click on the 'Create' button in the top right corner and select 'Add App'. Choose an informative app name and description (eg. tool name and version). Select the tool you want to build the app on buy clicking the 'select' button. This will open the 'search tools' window. Search for and select your tool. Step 2: Parameters Divide the app into sections appropriate for that tool (input, options and output are usually sufficient sections for simple apps). You can add a section by clicking on the 'Add Section'. Once you have added a section you can edit the name by clicking on the pencil icon (right side). Within a section you can add the parameters necessary for your tool by clicking on 'Add Parameter' and choosing the type of parameter you want to add (e.g. input file). For each option you add, you will need to specify what the option is, the argument option (if there is one) and whether that option is required. If an option is not required be sure to check the 'exclude if nothing is entered' box. For tools that have positional agruments (no argument option, eg. -i) you can leave argument option blank but you will need to make sure your arguments are in the proper order in step 4. Note: Although it is best to add all of the options for your tool, as it makes the app the most useful, you can expose as many or as few options as you like (as long as you add all the required options). Step 3: Preview App Make sure your app looks the way you want it to and that you have included all of the required options. If you need to make changes use the back button to return to the previous step. Step 4: Command Line Order This will provide a preview of what your options will look like on the command line. In the list of options below, use the up and down arrows to the right of the option to move it up or down in the list. You should see these changes reflected in the command line preview box. This order is especially important if your tool uses positional arguments. Step 5: Completion Click 'Save' (upper right) to save your work. Then click 'Launch App' at the bottom of the page and test your app with appropriate data. If you need to make changes to your app after testing, you can find it under the 'Apps under development' section of the 'Apps' tab. Click on the three dots menu (to the right of your app) and select 'edit app'. This will re-open the apps editor and allow you to make changes. Once you know your app works correctly you can share or publish it as you wish. Public apps must have example data located in an appropriately named folder here: `/iplant/home/shared/iplantcollaborative/example_data` All public apps also have a brief documentation page on the CyVerse Wiki To publish your app click on the three dots menu (at the right of your app) and select 'Publish'. You will need to supply: location of the example data brief description of inputs, required options and outputs link to CyVerse Wiki documentation page link to docmentation for the tool (provided by the developers)","title":"Building an App for Your Tool"},{"location":"de/login/","text":"Logging in to the Discovery Environment (DE) \u00b6 When you first open the Discovery Environment , you'll see the Home Dashboard. The Home Dashboard contains links to News , recent YouTube Videos , & Featured Apps. The left side navigation menu shows icons for accessing different parts of the DE. The menu can be expanded by clicking on the three bars in the top left. Sign in from the upper right corner of the DE and click the profile icon or clicking the Login link. If you attempt to view the Data Store or launch an App, you will see a pop-up: When signing in you will be redirected to our Authentication Service. Enter your CyVerse username and password. If you don't have an account yet or you've forgotten your password, you can visit https://user.cyverse.org to create an account. After logging in, you'll be returned to the Home Dashboard. If you were already on the Apps or Data when you logged in, you'll return to that page. You can take a short tour of the DE's main features by clicking the help icon in the left sidebar and selecting \"Product Tour\".","title":"Logging In"},{"location":"de/login/#logging-in-to-the-discovery-environment-de","text":"When you first open the Discovery Environment , you'll see the Home Dashboard. The Home Dashboard contains links to News , recent YouTube Videos , & Featured Apps. The left side navigation menu shows icons for accessing different parts of the DE. The menu can be expanded by clicking on the three bars in the top left. Sign in from the upper right corner of the DE and click the profile icon or clicking the Login link. If you attempt to view the Data Store or launch an App, you will see a pop-up: When signing in you will be redirected to our Authentication Service. Enter your CyVerse username and password. If you don't have an account yet or you've forgotten your password, you can visit https://user.cyverse.org to create an account. After logging in, you'll be returned to the Home Dashboard. If you were already on the Apps or Data when you logged in, you'll return to that page. You can take a short tour of the DE's main features by clicking the help icon in the left sidebar and selecting \"Product Tour\".","title":"Logging in to the Discovery Environment (DE)"},{"location":"de/manage_data/","text":"Managing Data in the Discovery Environment \u00b6 With CyVerse, you can manage data throughout the data lifecycle, from uploading, to adding metadata, to analyzing, sharing results, and making your data public for others to reuse. The Discovery Environment interface is just one of many ways to access, view, and manage your files in the Data Store . Where is the Data Store? The Data Store is not a separate platform; it is a service that crosscuts all of CyVerse so you can access your files (yours, shared with you, public) from anywhere in CyVerse. Browsing Data in the Discovery Environment \u00b6 After logging in, click on the Data icon in the left navigation menu. To see and browse information about your data files in the Data view, press the \"Customize Columns\" button to select more (or fewer) columns to display, such as size, modification date, permissions, etc. If the folder you're viewing has many items in it, use the < or > at the bottom of the page to move between pages. You can also change the number of items displayed per page. In the upper left, you should see a \"Community Data\" box. If you click on this box, you can change directories to view your data files (\"Home\"), or data shared with your username (\"Shared with me\"), or files in your \"Trash\". As you access the folders or files within your directory, breadcrumbs near the top of the page show the folder you are viewing and its parent folder(s). At the start of the breadcrumbs, you may select another root folder to view from within your home folder; click on the dropdown near your username to browse folders/files in \"Shared With Me\", \"Community Data\", or \"Trash\". Viewing File/Folder Details in the Discovery Environment \u00b6 Both the \"Details\" button near the top right and the More Options menu (ellipses) at the far right in a file or folder's row allow you to view and manage several types of information about your file/folder. You must be logged in to view file/folder details. From the Data view, click the checkbox next to a file or folder to select it and then click the \"Details\" or the ellipses to see specific information about the selected item, to copy the file path to the item, to add tags to the item, to edit metadata, or to set a file's info type. To view your permissions on the item and those of other users, click the \"Permissions\" tab under \"Details\". Uploading Files/Folders to the Data Store via the Discovery Environment \u00b6 The Data view shows a directory of the files and folders in your Data Store. You can select an existing folder as the destination for your uploaded file(s) or click the Folder button to create a new folder. The default file destination is your home Data Store folder (i.e., /iplant/home/<your_username> ). Click the \"Upload\" button to choose your options for importing files into the Data Store: To upload files from your local computer, choose Browse Local ; a file browser will open and you may select files to upload. To upload files from a URL, choose Import by URL ; you may paste in a valid HTTP or an FTP URL, then click Import . You may paste additional URLs or close the window by clicking Done . When you have begun the upload, you will get an automated notification that the file(s) has been queued. To view the status of an upload or import, click the Upload button and choose View Upload Queue . Deleting Files/Folders in the Discovery Environment \u00b6 You must be logged in and you must own the files or folders you wish to delete. From the Data view, select the desired file/folder by clicking the checkbox to its left. You can select multiple files/folders. To unselect an individual file/folder, click the checkbox again. You can select (or unselect) all files/folders at once by clicking the checkbox at the top of the list. Click on the More Options menu (ellipsis) in the upper right corner of the Data view and select Delete from the pop-up menu. When the file has been fully deleted, you will receive an automated notification (bell icon, upper right). When deleting or moving a file/folder, you cannot change anything associated with that file/folder until you receive the completion notification. Deleted files can be retrieved from your Trash. Uploading/Importing Data via the Browser You can use the DE interface to upload files of <2GB to the Data Store. When your Data Store file browser is open, you can also upload files from your computer by dragging them into your browser window. While uploading or downloading data via your browser, you must remain on the Data View until the task completes. The queue will only display the status of uploads from local files. Files imported by URL will generate an automated notification upon completion (or failure) to upload. When importing data from a URL, you can log out or navigate to another page or operation after you start the import; you will recieve an automated email notification when the task is complete. For larger files or large numbers of files, we recommend using other methods such as Cyberduck or iCommands . Advanced Data Management Features in the Discovery Environment \u00b6 The Discovery Environment also supports advanced data management tasks such as organizing your datasets, search, adding metadata to data, requesting a Digital Object Identifier (DOI), and importing or submitting data to/from NCBI SRA. To use the Advanced Search, run a query in the Search menu, then select \"Advanced Search Options\".","title":"Data Management with Discovery Environment"},{"location":"de/manage_data/#managing-data-in-the-discovery-environment","text":"With CyVerse, you can manage data throughout the data lifecycle, from uploading, to adding metadata, to analyzing, sharing results, and making your data public for others to reuse. The Discovery Environment interface is just one of many ways to access, view, and manage your files in the Data Store . Where is the Data Store? The Data Store is not a separate platform; it is a service that crosscuts all of CyVerse so you can access your files (yours, shared with you, public) from anywhere in CyVerse.","title":"Managing Data in the Discovery Environment"},{"location":"de/manage_data/#browsing-data-in-the-discovery-environment","text":"After logging in, click on the Data icon in the left navigation menu. To see and browse information about your data files in the Data view, press the \"Customize Columns\" button to select more (or fewer) columns to display, such as size, modification date, permissions, etc. If the folder you're viewing has many items in it, use the < or > at the bottom of the page to move between pages. You can also change the number of items displayed per page. In the upper left, you should see a \"Community Data\" box. If you click on this box, you can change directories to view your data files (\"Home\"), or data shared with your username (\"Shared with me\"), or files in your \"Trash\". As you access the folders or files within your directory, breadcrumbs near the top of the page show the folder you are viewing and its parent folder(s). At the start of the breadcrumbs, you may select another root folder to view from within your home folder; click on the dropdown near your username to browse folders/files in \"Shared With Me\", \"Community Data\", or \"Trash\".","title":"Browsing Data in the Discovery Environment"},{"location":"de/manage_data/#viewing-filefolder-details-in-the-discovery-environment","text":"Both the \"Details\" button near the top right and the More Options menu (ellipses) at the far right in a file or folder's row allow you to view and manage several types of information about your file/folder. You must be logged in to view file/folder details. From the Data view, click the checkbox next to a file or folder to select it and then click the \"Details\" or the ellipses to see specific information about the selected item, to copy the file path to the item, to add tags to the item, to edit metadata, or to set a file's info type. To view your permissions on the item and those of other users, click the \"Permissions\" tab under \"Details\".","title":"Viewing File/Folder Details in the Discovery Environment"},{"location":"de/manage_data/#uploading-filesfolders-to-the-data-store-via-the-discovery-environment","text":"The Data view shows a directory of the files and folders in your Data Store. You can select an existing folder as the destination for your uploaded file(s) or click the Folder button to create a new folder. The default file destination is your home Data Store folder (i.e., /iplant/home/<your_username> ). Click the \"Upload\" button to choose your options for importing files into the Data Store: To upload files from your local computer, choose Browse Local ; a file browser will open and you may select files to upload. To upload files from a URL, choose Import by URL ; you may paste in a valid HTTP or an FTP URL, then click Import . You may paste additional URLs or close the window by clicking Done . When you have begun the upload, you will get an automated notification that the file(s) has been queued. To view the status of an upload or import, click the Upload button and choose View Upload Queue .","title":"Uploading Files/Folders to the Data Store via the Discovery Environment"},{"location":"de/manage_data/#deleting-filesfolders-in-the-discovery-environment","text":"You must be logged in and you must own the files or folders you wish to delete. From the Data view, select the desired file/folder by clicking the checkbox to its left. You can select multiple files/folders. To unselect an individual file/folder, click the checkbox again. You can select (or unselect) all files/folders at once by clicking the checkbox at the top of the list. Click on the More Options menu (ellipsis) in the upper right corner of the Data view and select Delete from the pop-up menu. When the file has been fully deleted, you will receive an automated notification (bell icon, upper right). When deleting or moving a file/folder, you cannot change anything associated with that file/folder until you receive the completion notification. Deleted files can be retrieved from your Trash. Uploading/Importing Data via the Browser You can use the DE interface to upload files of <2GB to the Data Store. When your Data Store file browser is open, you can also upload files from your computer by dragging them into your browser window. While uploading or downloading data via your browser, you must remain on the Data View until the task completes. The queue will only display the status of uploads from local files. Files imported by URL will generate an automated notification upon completion (or failure) to upload. When importing data from a URL, you can log out or navigate to another page or operation after you start the import; you will recieve an automated email notification when the task is complete. For larger files or large numbers of files, we recommend using other methods such as Cyberduck or iCommands .","title":"Deleting Files/Folders in the Discovery Environment"},{"location":"de/manage_data/#advanced-data-management-features-in-the-discovery-environment","text":"The Discovery Environment also supports advanced data management tasks such as organizing your datasets, search, adding metadata to data, requesting a Digital Object Identifier (DOI), and importing or submitting data to/from NCBI SRA. To use the Advanced Search, run a query in the Search menu, then select \"Advanced Search Options\".","title":"Advanced Data Management Features in the Discovery Environment"},{"location":"de/managing_analyses/","text":"Managing Analyses in the Discovery Environment \u00b6 An analysis is the product of a launched app that has completed its computation of input data. The Discovery Environment maintains a history of all your analyses, including a unique analysis ID, launch date, input files, and other details. Browsing and Checking the Status of Analyses in the Discovery Environment \u00b6 Open the Analyses view by clicking on the (analyses icon) on the left sidebar of the DE interface to monitor the status of your submitted analysis. The analysis launched most recently will be at the top of the list. Analyses can be sorted by Name, Start date, End date or Status. To sort your analyses, hover your cursor over the name of the column you wish to sort by and click on the arrow that appears beside the column name. Analyses Status In the DE, an analyses can have one of the following status messages: Submitted : The analysis has been queued for running on CyVerse resources. Running : The analyses is now running - for most apps (non-interactive) the analysis will run until it is completed or a time limit is reached. For interactive (VICE) applications, you may now access your interactive application (check your notification icon for a link or click the link-out icon ). Completed : The application is completed and any logs and results have been written to the data store. Access the outputs by clicking the folder icon ) Canceled : The analyses has been cancelled. Failed : The analyses has resulted in an error. To filter your analyses by user, click on the View dropdown menu in the upper left corner and select either 'My analyses' or 'Shared with me'. The default view is 'My analyses'. To further filter your analyses by app type, click on the Filter dropdown menu and select the type of analyses you would like to see (i.e., HPC, DE, VICE, or OSG). To open and view the output folder of a completed analysis, click on the output folder icon at the right side of that particular analysis. Relaunching an Analyses in the Discovery Environment \u00b6 You can relaunch an analyses to load an analyses you have previously done. Your analyses will load with the same inputs and parameters as previously used and you will then have the option to some, all, or none of the of those settings. To relaunch Select an analysis from your history. Click the relaunch icon (). Alter any desired parameters and launch the application. Viewing Analyses Details in the Discovery Environment \u00b6 Click the \"Details\" button or the (info icon) to view details of the analysis (e.g. parameters used). Sharing an Analyses in the Discovery Environment \u00b6 Clicking the \"Share\" or \"Add To Bag\" button to share an analysis and its results with another CyVerse user. Additional Analyses Actions in the Discovery Environment \u00b6 Clicking the \"More Actions\" button allows you to perform the following actions: Go to Output folder : View the logs and outputs of a completed analysis Relaunch : Relaunch an analysis (with the option to edit parameters) Rename : Rename an analysis Update Comments... : Add or edit comment notation on an analysis Go to analyses : View an interactive analysis in a new tab Extend Time Limit : Extend the time limit of an interactive analysis Terminate : Stop a submitted or running analysis Delete : Delete an analysis from your history Add to Bag : Add to a \"bag\" for sharing","title":"Managing Analyses"},{"location":"de/managing_analyses/#managing-analyses-in-the-discovery-environment","text":"An analysis is the product of a launched app that has completed its computation of input data. The Discovery Environment maintains a history of all your analyses, including a unique analysis ID, launch date, input files, and other details.","title":"Managing Analyses in the Discovery Environment"},{"location":"de/managing_analyses/#browsing-and-checking-the-status-of-analyses-in-the-discovery-environment","text":"Open the Analyses view by clicking on the (analyses icon) on the left sidebar of the DE interface to monitor the status of your submitted analysis. The analysis launched most recently will be at the top of the list. Analyses can be sorted by Name, Start date, End date or Status. To sort your analyses, hover your cursor over the name of the column you wish to sort by and click on the arrow that appears beside the column name. Analyses Status In the DE, an analyses can have one of the following status messages: Submitted : The analysis has been queued for running on CyVerse resources. Running : The analyses is now running - for most apps (non-interactive) the analysis will run until it is completed or a time limit is reached. For interactive (VICE) applications, you may now access your interactive application (check your notification icon for a link or click the link-out icon ). Completed : The application is completed and any logs and results have been written to the data store. Access the outputs by clicking the folder icon ) Canceled : The analyses has been cancelled. Failed : The analyses has resulted in an error. To filter your analyses by user, click on the View dropdown menu in the upper left corner and select either 'My analyses' or 'Shared with me'. The default view is 'My analyses'. To further filter your analyses by app type, click on the Filter dropdown menu and select the type of analyses you would like to see (i.e., HPC, DE, VICE, or OSG). To open and view the output folder of a completed analysis, click on the output folder icon at the right side of that particular analysis.","title":"Browsing and Checking the Status of Analyses in the Discovery Environment"},{"location":"de/managing_analyses/#relaunching-an-analyses-in-the-discovery-environment","text":"You can relaunch an analyses to load an analyses you have previously done. Your analyses will load with the same inputs and parameters as previously used and you will then have the option to some, all, or none of the of those settings. To relaunch Select an analysis from your history. Click the relaunch icon (). Alter any desired parameters and launch the application.","title":"Relaunching an Analyses in the Discovery Environment"},{"location":"de/managing_analyses/#viewing-analyses-details-in-the-discovery-environment","text":"Click the \"Details\" button or the (info icon) to view details of the analysis (e.g. parameters used).","title":"Viewing Analyses Details in the Discovery Environment"},{"location":"de/managing_analyses/#sharing-an-analyses-in-the-discovery-environment","text":"Clicking the \"Share\" or \"Add To Bag\" button to share an analysis and its results with another CyVerse user.","title":"Sharing an Analyses in the Discovery Environment"},{"location":"de/managing_analyses/#additional-analyses-actions-in-the-discovery-environment","text":"Clicking the \"More Actions\" button allows you to perform the following actions: Go to Output folder : View the logs and outputs of a completed analysis Relaunch : Relaunch an analysis (with the option to edit parameters) Rename : Rename an analysis Update Comments... : Add or edit comment notation on an analysis Go to analyses : View an interactive analysis in a new tab Extend Time Limit : Extend the time limit of an interactive analysis Terminate : Stop a submitted or running analysis Delete : Delete an analysis from your history Add to Bag : Add to a \"bag\" for sharing","title":"Additional Analyses Actions in the Discovery Environment"},{"location":"de/using_apps/","text":"Using Apps in the Discovery Environment \u00b6 You can select from several hundred applications (apps) available in the Discovery Environment when you are ready to analyze your data. Launching Apps When launching Apps , you can log out or navigate to another page or operation after you start the task; an automated email notification is sent to you when those tasks are completed Browsing Apps in the Discovery Environment \u00b6 You must be logged in to browse and use apps. Click in the left sidebar of the DE to see the Apps view. When you first access the Apps view, you may be prompted to log in. After logging in, you will see a screen that looks something like this: Sorting and Filtering Apps in the Discovery Environment \u00b6 To sort the list of apps in ascending or descending order by app name, the name of the person who integrated the app, or its average rating, click on the column headings. You can navigate between pages and change how many apps are listed on a page by using the < or > controls at the bottom of the page. By default, the Apps view displays \"Featured Apps\" which are interactive. All \"Public Apps\" are available to you. With hundreds of apps and sometimes many versions of an app in the DE, you may want to view a subset of all available apps. There are two ways to do this. First, in the upper left corner of the Apps view, the currently active subset of apps is shown as the primary filter. Click the drop-down arrow next to the currently active subset to select a different apps subset to display: The currently selected app subset is highlighted in gray. The available app subsets are: Application type Description Apps under development Apps that you have added to the DE that have not been made public Favorite apps Apps that you have marked as favorite apps in the DE My public apps Apps that you have added to the DE that have been made publicly available Shared with me Apps that other users have shared with you High-Performance Computing Apps that run at the Texas Advanced Computing Center using the Tapis API Browse All Apps All apps available to you in the DE You can further reduce the list of the apps displayed by selecting a filter. Click the drop-down arrow in the Filter control (upper right corner of the Apps view) to select the type of apps you'd like to see in the listing: The currently selected filter is displayed in the Filter control itself. If no filter is selected, the control will be empty. The currently available app filters are: Application filter Description HPC High Performance Computing apps that run using the Tapis API DE Executable (non-interactive apps) that run on CyVerse computing resources VICE Interactive development environments (e.g., Jupyter, RStudio, R Shiny) and other apps with their own interactive interfaces Open Science Grid (OSG) Executable (non-interactive apps) that run on OSG resources The app filter you selected will be displayed in the Filter control. Viewing App Details in the Discovery Environment \u00b6 When you've found an app of interest, select it by clicking the checkbox to the left of the app name. A Details button will appear in the upper right corner of the Apps view, just to the right of the Filter control. Click the Details button to see additional information about the app (e.g., description, number of times run, etc.). The Details panel has several controls available. Click the Heart icon to add that app to your list of favorite apps (to remove from your favorite list, click the heart again). The heart will be solid blue if the app is already on your list of favorites. Click the Link icon to display a link to the app that you can copy and share with other CyVerse users. The Stars icon labeled Your rating allows you to rate the app. The Tools used by this App tab contains information about the underlying tools (steps) the app uses to perform an analysis. To dismiss the App Details view, click anywhere outside the panel. Create a Favorites list Favorite your frequently used apps to make them easier and faster to find next time. About VICE Apps in the Discovery Environment \u00b6 One type of app that you can filter for in the Discovery Environment are (VICE stands for Visual Interactive Computing Environment). VICE apps are interactive apps that include a Graphical User Interface (GUI) or an Integrated Development Environment (IDE) such as Project Jupyter, RStudio, or remote desktops to the DE. You must request special access and be approved to use VICE apps through the CyVerse User Portal . Advanced Features in the Discovery Environment \u00b6 The Discovery Environment also supports advanced features for apps such as integrating different types of apps into the DE, creating and running containers, and using Application Programming Interfaces (APIs) for programmatic backend access to CyVerse services. For how-to information on these features, see our Developer Manuals , Extending VICE Apps , and our Powered By documentation.","title":"Using Apps"},{"location":"de/using_apps/#using-apps-in-the-discovery-environment","text":"You can select from several hundred applications (apps) available in the Discovery Environment when you are ready to analyze your data. Launching Apps When launching Apps , you can log out or navigate to another page or operation after you start the task; an automated email notification is sent to you when those tasks are completed","title":"Using Apps in the Discovery Environment"},{"location":"de/using_apps/#browsing-apps-in-the-discovery-environment","text":"You must be logged in to browse and use apps. Click in the left sidebar of the DE to see the Apps view. When you first access the Apps view, you may be prompted to log in. After logging in, you will see a screen that looks something like this:","title":"Browsing Apps in the Discovery Environment"},{"location":"de/using_apps/#sorting-and-filtering-apps-in-the-discovery-environment","text":"To sort the list of apps in ascending or descending order by app name, the name of the person who integrated the app, or its average rating, click on the column headings. You can navigate between pages and change how many apps are listed on a page by using the < or > controls at the bottom of the page. By default, the Apps view displays \"Featured Apps\" which are interactive. All \"Public Apps\" are available to you. With hundreds of apps and sometimes many versions of an app in the DE, you may want to view a subset of all available apps. There are two ways to do this. First, in the upper left corner of the Apps view, the currently active subset of apps is shown as the primary filter. Click the drop-down arrow next to the currently active subset to select a different apps subset to display: The currently selected app subset is highlighted in gray. The available app subsets are: Application type Description Apps under development Apps that you have added to the DE that have not been made public Favorite apps Apps that you have marked as favorite apps in the DE My public apps Apps that you have added to the DE that have been made publicly available Shared with me Apps that other users have shared with you High-Performance Computing Apps that run at the Texas Advanced Computing Center using the Tapis API Browse All Apps All apps available to you in the DE You can further reduce the list of the apps displayed by selecting a filter. Click the drop-down arrow in the Filter control (upper right corner of the Apps view) to select the type of apps you'd like to see in the listing: The currently selected filter is displayed in the Filter control itself. If no filter is selected, the control will be empty. The currently available app filters are: Application filter Description HPC High Performance Computing apps that run using the Tapis API DE Executable (non-interactive apps) that run on CyVerse computing resources VICE Interactive development environments (e.g., Jupyter, RStudio, R Shiny) and other apps with their own interactive interfaces Open Science Grid (OSG) Executable (non-interactive apps) that run on OSG resources The app filter you selected will be displayed in the Filter control.","title":"Sorting and Filtering Apps in the Discovery Environment"},{"location":"de/using_apps/#viewing-app-details-in-the-discovery-environment","text":"When you've found an app of interest, select it by clicking the checkbox to the left of the app name. A Details button will appear in the upper right corner of the Apps view, just to the right of the Filter control. Click the Details button to see additional information about the app (e.g., description, number of times run, etc.). The Details panel has several controls available. Click the Heart icon to add that app to your list of favorite apps (to remove from your favorite list, click the heart again). The heart will be solid blue if the app is already on your list of favorites. Click the Link icon to display a link to the app that you can copy and share with other CyVerse users. The Stars icon labeled Your rating allows you to rate the app. The Tools used by this App tab contains information about the underlying tools (steps) the app uses to perform an analysis. To dismiss the App Details view, click anywhere outside the panel. Create a Favorites list Favorite your frequently used apps to make them easier and faster to find next time.","title":"Viewing App Details in the Discovery Environment"},{"location":"de/using_apps/#about-vice-apps-in-the-discovery-environment","text":"One type of app that you can filter for in the Discovery Environment are (VICE stands for Visual Interactive Computing Environment). VICE apps are interactive apps that include a Graphical User Interface (GUI) or an Integrated Development Environment (IDE) such as Project Jupyter, RStudio, or remote desktops to the DE. You must request special access and be approved to use VICE apps through the CyVerse User Portal .","title":"About VICE Apps in the Discovery Environment"},{"location":"de/using_apps/#advanced-features-in-the-discovery-environment","text":"The Discovery Environment also supports advanced features for apps such as integrating different types of apps into the DE, creating and running containers, and using Application Programming Interfaces (APIs) for programmatic backend access to CyVerse services. For how-to information on these features, see our Developer Manuals , Extending VICE Apps , and our Powered By documentation.","title":"Advanced Features in the Discovery Environment"},{"location":"ds/","text":"Manage Your Data with the Data Store \u00b6 The CyVerse Data Store is a platform for storing, managing, and sharing your data across the full data lifecycle. The Data Store crosscuts, and is accessible from, all CyVerse platforms. Data Store features are designed to help you follow a number of practices to ensure that the integrity and value of your data are maintained and to make your data more FAIR (Findable, Accessible, Interoperable, and Reusable) with less effort. This guide will cover the minimum needed to get you started. It assumes you have created a CyVerse account already. Please see the Data Store Manual for a more comprehensive look at Data Store capabilities.","title":"Manage Your Data with the Data Store"},{"location":"ds/#manage-your-data-with-the-data-store","text":"The CyVerse Data Store is a platform for storing, managing, and sharing your data across the full data lifecycle. The Data Store crosscuts, and is accessible from, all CyVerse platforms. Data Store features are designed to help you follow a number of practices to ensure that the integrity and value of your data are maintained and to make your data more FAIR (Findable, Accessible, Interoperable, and Reusable) with less effort. This guide will cover the minimum needed to get you started. It assumes you have created a CyVerse account already. Please see the Data Store Manual for a more comprehensive look at Data Store capabilities.","title":"Manage Your Data with the Data Store"},{"location":"ds/check_data/","text":"Checking Your Data Storage \u00b6 You can see how much data you are storing in the Data Store from the Resource Usage area of the Discovery Environment Home screen. But what if you want to delete some large folders, or check for duplicate files? The DataHog app can help you understand more about the size of the folders and files you have in the Data Store. Checking Folder Size using DataHog \u00b6 Log into the Discovery Environment . Click on the (Apps Icon) to view or browse Apps. Click on the \"Instant Launches\" button in the top right. Then, click on the name \"DataHog\" in the list to launch the app. If you do not see the app open in a new tab, make sure you allow pop-ups for this site. Note You can also launch DataHog like you would other apps by clicking on the app name in the Featured App list and proceeding through the app launch wizard. 4. When the app is running, enter your CyVerse username and password and click \"Import from iRODS\". You will also see a CyVerse tab but the iRODs tab is currently the preferred way to view data in CyVerse. 5. Once the import is complete, you will see a Summary of your data including a breakdown by file type, lists of files and folders by size, and lists of files and folders by date. There are other tabs to identify Duplicated Files as well as to import other storage sources so that you get a global view of your data. Click here to watch a 1-minute video on how to use DataHog.","title":"Checking Data Storage"},{"location":"ds/check_data/#checking-your-data-storage","text":"You can see how much data you are storing in the Data Store from the Resource Usage area of the Discovery Environment Home screen. But what if you want to delete some large folders, or check for duplicate files? The DataHog app can help you understand more about the size of the folders and files you have in the Data Store.","title":"Checking Your Data Storage"},{"location":"ds/check_data/#checking-folder-size-using-datahog","text":"Log into the Discovery Environment . Click on the (Apps Icon) to view or browse Apps. Click on the \"Instant Launches\" button in the top right. Then, click on the name \"DataHog\" in the list to launch the app. If you do not see the app open in a new tab, make sure you allow pop-ups for this site. Note You can also launch DataHog like you would other apps by clicking on the app name in the Featured App list and proceeding through the app launch wizard. 4. When the app is running, enter your CyVerse username and password and click \"Import from iRODS\". You will also see a CyVerse tab but the iRODs tab is currently the preferred way to view data in CyVerse. 5. Once the import is complete, you will see a Summary of your data including a breakdown by file type, lists of files and folders by size, and lists of files and folders by date. There are other tabs to identify Duplicated Files as well as to import other storage sources so that you get a global view of your data. Click here to watch a 1-minute video on how to use DataHog.","title":"Checking Folder Size using DataHog"},{"location":"ds/cyberduck/","text":"Transferring Data with Cyberduck \u00b6 Cyberduck is a 3 rd party software (available as freeware) tool that allows you to drag-and-drop large and/or multiple files between your local computer and the Data Store. Cyberduck can also be used to rename files and browse other shared or public Data Store locations. Download and first-time configuration of Cyberduck \u00b6 Download Cyberduck at the Cyberduck Website ; follow the installation instructions for your operating system. Download the CyVerse connection profile Double-click on the downloaded file to open the installed Cyberduck software. In the Cyberduck configuration window, enter your CyVerse username in the field 'iPlant username'. Under 'Advanced Options' ensure the 'Transfer Files' option is set to 'Open Multiple Connections' . Close this window - your entries will be automatically saved. Double-click on the Data Store bookmark in the Cyberduck window. Enter your CyVerse credentials. You should now be connected to the CyVerse Data Store and viewing the contents of your home directory. Tip At the top of your Cyberduck window you can see your location within the Data Store. From Cyberduck's 'Go' menu, you can select 'Go to folder' to navigate to any other Data Store location that is public or shared with you. Upload from local computer to Data Store using Cyberduck \u00b6 Warning When uploading your data to the Data Store, avoid naming files/folders with names containing spaces (e.g., experiment one.fastq) or special characters (e.g., ~ ` ! @ # $ % ^ & * ( ) + = { } [ ] | : ; \" ' < > , ? / and \\ ). The Apps on the Discovery Environment and most command line applications will typically not tolerate these characters. For long file/folder names, we recommend using underscore(s) (e.g., experiment_one.fastq) instead of spaces. Double-click on the Data Store bookmark to connect to the Data Store. Select file(s)/folder(s) from your local machine and drag them into the Cyberduck window. (You may drag directly into an existing folder or from the Cyberduck 'File' menu, create a new folder). A 'Transfers' window will appear. Monitor the upload to completion. Download from Data Store to local computer using Cyberduck \u00b6 Double-click on the Data Store bookmark to connect to the Data Store. Select file(s)/folder(s) in the Data Store (Cyberduck window) and drag them to a location on your local computer. A 'Transfers' window will appear. Monitor the download to completion. Tip In the Cyberduck 'File' menu, there are several more functionalities. You can directly specify files and folders to move without dragging and dropping them. You can also 'synchronize' folders - copying only items that are missing in a folder rather than copying all contents.","title":"Transferring Data with Cyberduck"},{"location":"ds/cyberduck/#transferring-data-with-cyberduck","text":"Cyberduck is a 3 rd party software (available as freeware) tool that allows you to drag-and-drop large and/or multiple files between your local computer and the Data Store. Cyberduck can also be used to rename files and browse other shared or public Data Store locations.","title":"Transferring Data with Cyberduck"},{"location":"ds/cyberduck/#download-and-first-time-configuration-of-cyberduck","text":"Download Cyberduck at the Cyberduck Website ; follow the installation instructions for your operating system. Download the CyVerse connection profile Double-click on the downloaded file to open the installed Cyberduck software. In the Cyberduck configuration window, enter your CyVerse username in the field 'iPlant username'. Under 'Advanced Options' ensure the 'Transfer Files' option is set to 'Open Multiple Connections' . Close this window - your entries will be automatically saved. Double-click on the Data Store bookmark in the Cyberduck window. Enter your CyVerse credentials. You should now be connected to the CyVerse Data Store and viewing the contents of your home directory. Tip At the top of your Cyberduck window you can see your location within the Data Store. From Cyberduck's 'Go' menu, you can select 'Go to folder' to navigate to any other Data Store location that is public or shared with you.","title":"Download and first-time configuration of Cyberduck"},{"location":"ds/cyberduck/#upload-from-local-computer-to-data-store-using-cyberduck","text":"Warning When uploading your data to the Data Store, avoid naming files/folders with names containing spaces (e.g., experiment one.fastq) or special characters (e.g., ~ ` ! @ # $ % ^ & * ( ) + = { } [ ] | : ; \" ' < > , ? / and \\ ). The Apps on the Discovery Environment and most command line applications will typically not tolerate these characters. For long file/folder names, we recommend using underscore(s) (e.g., experiment_one.fastq) instead of spaces. Double-click on the Data Store bookmark to connect to the Data Store. Select file(s)/folder(s) from your local machine and drag them into the Cyberduck window. (You may drag directly into an existing folder or from the Cyberduck 'File' menu, create a new folder). A 'Transfers' window will appear. Monitor the upload to completion.","title":"Upload from local computer to Data Store using Cyberduck"},{"location":"ds/cyberduck/#download-from-data-store-to-local-computer-using-cyberduck","text":"Double-click on the Data Store bookmark to connect to the Data Store. Select file(s)/folder(s) in the Data Store (Cyberduck window) and drag them to a location on your local computer. A 'Transfers' window will appear. Monitor the download to completion. Tip In the Cyberduck 'File' menu, there are several more functionalities. You can directly specify files and folders to move without dragging and dropping them. You can also 'synchronize' folders - copying only items that are missing in a folder rather than copying all contents.","title":"Download from Data Store to local computer using Cyberduck"},{"location":"ds/doi/","text":"Getting a DOI \u00b6 Background \u00b6 CyVerse Curated Data in the Data Commons contains files that have been assigned a Digital Object Identifier (DOI). These files are secure, stable, and unchangeable , thus they are ideal for easy data reuse and data citation. DOI Request Quickstart \u00b6 1. Organize data \u00b6 1.1 Create submission folder \u00b6 Organize your data so that there is one folder for each DOI (named according to the Data Commons Naming Conventions--see Step 1.2) Within that folder, include all files in your data package plus the ReadMe file and the inventory. You may have subfolders within a data package. You may include compressed files in a package, as described on the DOI Frequently Asked Questions , but do not compress the entire folder/package 1.2. Name your top level folder according to the Data Commons Naming Conventions \u00b6 CyVerse Curated Data datasets are searchable and discoverable based on their metadata. While the dataset itself can have any name chosen by the creator (within reason), the folder that contains the dataset must follow the naming practices described on this page. General guidelines Folder names must be unique. No invalid characters: Be sure there are no spaces or special characters in the folder name . Use underscores between each segment. Folder Name Format $Creator_$subject_$date $Creator: The Creator entry should be the same as entered in the Creator field of the DOI request - DataCite Metadata request form. The Creator is the lead author, the senior author, or the organization with the primary responsibility for the dataset. Start the field (the creator's name) with a capital letter. Co-creators: If there are two co-creators, use both names, separated by an underscore or using camel case. For three or more co-creators, select only one name or use a consortium name. Other contributors should be acknowledged in the metadata (as creators or contributors), which will display on the dataset landing page. $subject: Very briefly describes what the dataset is about. If the subject is more than one word, use either camel case (example: camelCase) or underscores (example: underscore_between_words) to separate the words. If another folder has the exact same name, you may modify the subject slightly to maintain uniqueness. $date: Either just the year, or the month and year, in which the dataset was created. Month and year should be used only if there is likely to be more than one dataset with the same creator and subject within the same year. Month must be a three-letter abbreviation: Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Nov, Dec Examples Valid Names \u00b6 Walls_yam_variation_2015 DeBarry_yamGenomicVariation_2016 Esteva_yam_variation_Mar2016 Esteva_Walls_yam_genomic_variation_Jun2016 YamConsortium_Dioscorea_variation_Nov2017 Invalid Names \u00b6 WallsYamVariation_2016 (Missing underscore between the creator and the subject) Esteva_yam_variation_June2016 (Month should be three letters: Jun) YamConsortium_Nov2017 (No subject) Walls_yam_variation_2016#1 (Contains a special character) Walls YamVariation 2020 (Contains spaces) Not recommended \u00b6 Although the following will pass validation, they are not recommended because the subject is too vague or too detailed: Walls_variation_2016 (Subject too vague) Esteva_yam_Mar2016 (Subject too vague) DeBarry_yam_genetic_and_environmental_variation_with_phenotype_data_version3_Dioscorea_2016 (Too detailed) 1.3. Create a ReadMe file \u00b6 Create a text file labeled \\\"ReadMe\\\" with the following information: How you obtained, organized, and labeled your dataset. How to reuse the data, such as which apps can analyze the data. The inventory (see Step 1.4) may be included as part of the ReadMe file. If your data include sequences, the ReadMe should include a list of corresponding BioSample IDs. Examples of good ReadMe files: https://datacommons.cyverse.org/browse/iplant/home/shared/commons_repo/curated/Carolyn_Lawrence_Dill_GOMAP_Cacao_NCBI_CriolloV2_March_2021.r1/_README.txt https://datacommons.cyverse.org/browse/iplant/home/shared/commons_repo/curated/Liang_Schnable_UNLPlantVision_2017/readMe.txt 1.4. Create an inventory \u00b6 You must create a plain text document that includes an inventory of the contents of the organized dataset (at a minimum, your dataset will contain one data file and one ReadMe file). The inventory may be part of the ReadMe file or a separate file. The inventory should include the ReadMe file and any other additional non-data materials you add to your dataset. If your dataset contains folders with many files (e.g., large collections of images), you do not need to list each file in the inventory. Simply describe the folder and what it contains. Describe the file naming conventions, if that is helpful. Example inventory Lyons_DOI-Example-Aug2020: Top level directory name README.txt: Plain text file that describes the origin of the data, experiments, data processing, etc. Also contains a list and description for the contents of the top-level directory (unless a separate inventory file is provided) License.txt: License file (e.g., GPL, MIT) that governs the use of the data a.data1/: Directory containing data b.data2/: Directory containing more data c.data3/: Directory containing even more data 2. Add metadata \u00b6 You must provide all required metadata in the 'DOI Request--Datacite 4.1' template at a minimum. You may add any additional metadata that is appropriate. We encourage the use of additional metadata to make your data better understood and more discoverable. For more information, including how to apply metadata, see Adding Metadata . Tip Get recognition for your work by including ORCIDs for yourself and all creators and contributors. 2.1 In the Data window, click the checkbox next to the folder. \u00b6 2.2 Select More actions > Metadata. \u00b6 2.3 Select More actions (again) > View in template. \u00b6 2.4 Choose the 'DOI Request - DataCite4.1' metadata template. \u00b6 2.5 Complete the required fields (marked with an asterisk) and as many of the optional fields as possible. \u00b6 Warning Be sure to include at least 3 subject key words or phrases, so that people can discover your data (Findability)! Each subject should be in its own field (click on the plus next to \"Subject\" to add a subject field. DO NOT use a comma-separated list. ) 2.6 Save the template. \u00b6 3. Submit request and wait for validations \u00b6 3.1. Before you submit \u00b6 Check the following to be sure everything is in order. There are no spaces or special characters in your file or folder names. You have included a ReadMe file that includes all the information specified in step 1.3. You followed the Data Commons Naming Conventions You have filled in all the required fields in the 'DOI Request - DataCite 4.1' metadata template You have included at least 3 subjects in your metadata Each subject is in a separate field (not comma-separated). The 'description' in your metadata is adequate (other users can tell what your data describe). You understand that once the DOI is issued you cannot change the data. If you know your data will change you should consider waiting to request a DOI. If you do need to make changes later this DOI can be deprecated, a new DOI issued, and the two DOIs linked together as versions. 3.2 Submit DOI request \u00b6 In the Data tab, click the checkbox next to the folder. Select More actions > Request DOI. After verifying you have read the instructions (i.e., this guide), click \\\"I need a DOI\\\". You will receive a verification email that your request has been received, and a notification will be listed in the Notifications list in the DE. Note At this point, your folder will move to a new location under Community Data/commons_repo/staging. 3.3. Validations \u00b6 After submitting your request, a CyVerse curator begins validating your dataset, metadata, and overall configuration of your dataset. Validations are based solely on the required DOI metadata and folder-naming conventions, as well as the data's potential utility to the CyVerse and larger scientific community, not the quality of your data. This is not a peer review process. Possible validation actions If the curator determines that minor changes are needed, they may make those changes themself. If the curator determines that substantive changes are needed, they will contact you with required changes. If the curator determines that your dataset is not appropriate for the Curated Data section of the Data Commons (e.g., because it belongs in NCBI), you will be notified. If the curator determines that the dataset is adequately organized and the DataCite metadata are accurate, they will provide a DOI, and you will be notified of the DOI and the final dataset location. Tip To check the status of your DOI request, click Notifications (the bell icon) at the top right of the DE screen. 4. After publication \u00b6 4.1. Get your dataset noticed \u00b6 Metadata, the description about your data, is key to getting your dataset noticed in the world wide web. Search engines and bibliographic aggregators index the metadata that you create to obtain a DOI. Thus, it is important that you do the following: Make sure the metadata are complete. Include precise keywords in the \"Subject\" attribute. Include descriptive terms about the science and themes involved in your research. These can go in the \"Subject\" attribute, but you can also create additional metadata attributes specific to your dataset. Include methods used to generate the dataset in the \"Description\" attribute, and in more detail in a ReadMe file. Describe the dataset for a broader audience so that they understand your research. Use the \"Description\" field for this. If you or team members have an ORCID ID, make sure to include it in the metadata. 4.2. Publicize your dataset \u00b6 Consider using social media to share the DOI of your dataset, and tag CyVerse. If you have an interesting story about your data, contact us at learning@cyverse.org , and we may be able to share it through CyVerse outreach. If you have a tool or workflow you developed to analyze your data in CyVerse, consider presenting it as part of our CyVerse Webinars. DOI Frequently Asked Questions \u00b6 Why should I publish my data in CyVerse Curated Data? CyVerse Curated Data is the ideal platform for ease of data reuse. Because it is assigned a permanent identifier (DOI), it is stable and unchangeable, making it ideal for data citation. Because the data is stored in large-scale storage resources that are monitored 24/7, it is secure. Because it allows transfer, upload, and download across different computers and platforms, it can store very large datasets. And because its data is accessible to CyVerse's suite of large-scale computational analysis resources, users can seamlessly analyze, manage, and publish new results. For more information, see Is CyVerse Curated Data Right for My Data? . What are the conditions for data to be published through CyVerse Curated Data? Several conditions must exist in your data before it can be published in CyVerse Curated Data: You must be a registered CyVerse account holder. To register for an account, see the Create Account Quickstart . A dataset may be up to 100GB in size. If you are interested in depositing a larger dataset, please request an increased data allocation before requesting a permanent identifier using this form . Data must be both curated and static. Once the data is published, it cannot be amended (although newer versions can be published). Data must be organized to identify the different components (raw, preprocessed, analysis, etc.). Compressed files must be in LASzip ( https://www.laszip.org/ ) or open-source Gzip family of compression formats including zip, tar, tar.gz, or tgz. At minimum, the dataset must include a complete description according to the DataCite standard . Domain-specific schemas, however, and the addition of ReadMe files, publications, or help notes that explain the data as well as how they were obtained and can be used, are encouraged. In organizing and documenting the data, users should ask themselves, \"What would someone need to reuse this data?\" Can I publish to the Data Commons if my data is not static and curated by CyVerse? Yes, you can make data available to the public via Community Released Data. You can request a community release data folder using this form . What is a DOI? A DOI is a Digital Object Identifier . It is a permanent, redirectable identifier and URL for your dataset, so that even if the location of your dataset changes, it can still be found with the same ID. DOIs are issued by CyVerse through the DataCite _ service. Do I need to contact CyVerse before requesting a DOI? The process of requesting a DOI is automated through the DE, but some tasks must be handled manually, such as DOIs for datasets with more than 1000 files or DOIs for datasets that are stored somewhere other than /iplant/home/share/commons_repo/curated. If you match either of those cases, please contact us at doi@cyverse.org . Also contact us if you have questions about how to organize your data or what scientific metadata to include. How much does a CyVerse permanent identifier cost? At this time, CyVerse does not charge for DOIs. However, the dataset must meet the requirements given on the page Is CyVerse Curated Data Right for My Data? . In the future, there may be a charge for issuing permanent identifiers in the CyVerse Data Commons. How long will it take to obtain a permanent identifier and publish my data? Provided that your dataset is in good order and ready to be published, the process may take up to one week, as it may involve a dialogue with the CyVerse data curators. If your data is well organized and the metadata is complete and accurate, the process will be much faster (usually 1-2 business days). It is best to submit your request at least one week before you need the identifier (e.g., for a manuscript submission) or more for very large of complex datasets. Can I publish different versions of my data? Yes. Each new version must be documented, and will be assigned a new permanent identifier that references the original dataset. For new versions, contact us at doi@cyverse.org . How small or big should my data be to be published? The size of the dataset is less important than its utility to the scientific community. Although there is no lower size limit for requesting a DOI, the default upper size limit for data allocations on CyVerse is 100GB. If you are interested in depositing a larger dataset, please request an increased data allocation before requesting a permanent identifier. Determine what to include A data collection may be composed of multiple files and different datasets. In preparing your data for publication identify the data and other materials that you consider useful for validation and reuse of your research: Data associated to a research project may include multiple files with different roles. If there are components of your dataset that belong in a public repository such as NCBI (e.g., fastq files), submit them to the repository, rather than to CyVerse Curated Data. You may want to include a list of external files in your dataset, with links. Beyond data, you will include the ReadMe file (see Step 1.3), and you may include scripts or links to scripts to run your analysis. Links to analysis tools can also be included as metadata (see Step 2). Determine how many permanent identifiers to request To determine how many DOIs to request for a given data collection, consider the following: Size and number of components. How many studies or publications does it represent? Is your data collection formed by different datasets and are those likely to be used separately? Do you want to create a data collection with one DOI for the entire project and additional related DOIs for distinct datasets so that they are cited individually? DOIs can be nested, so that one dataset is part of another. If you are uncertain about how many DOIs to request, contact us at doi@cyverse.org . What is the policy for submitting compressed data to CyVerse Curated Data? Certain file types are regularly transferred, stored, and used in applications in a compressed form, such as FASTQ for genomic data and LAZ for LIDAR data. Curated Data supports the deposition of files in the following open compressed formats: LASzip ( https://www.laszip.org/ ) and the open source Gzip ( http://en.wikipedia.org/wiki/Gzip ) family of compression formats including zip, tar, tar.gz, or tgz. Can I publish data in CyVerse if I am not a CyVerse user? You must have a CyVerse account to publish your data in the Data Commons repositories (Community Contributed or Curated Data). You do not have to be a user of the entire platform, but at minimum you must be able to upload data, add metadata, and use the Discovery Environment to request a DOI. If you have not used the DE's metadata features before, start with Using Metadata in the DE and read the section on metadata templates. How secure is the data in the Curated Data site? Data in our platform is stored in large-scale storage resources that are monitored 24/7. Data is authenticated through checksum analysis at ingest, and is locally and geographically replicated so that if any one system fails there will always be a safe copy of your data. What is CyVerse Data Commons' long-term commitment to hosting public data? If and when the Data Commons cannot host your data in CyVerse Curated Data, it will transfer custody of the data to another repository and will change the target URL to which the identifier points. What if in the future I want to move my data to another repository? If you want to move your data to another repository, please send a ticket with the new DOI and URL location and we will change the DOI target. You may leave a copy of the dataset in the CyVerse Curated Data site for ease of reuse within the computational environment. CyVerse will update the metadata to reflect the relationship between the two identical datasets. How can I make it easier for people to give me (and my co-creators) credit for using my dataset? Encourage others to cite your data using the DOI. Each dataset landing page includes a citation that can be copied or downloaded in standard formats (BibTEX or EndNote). Connecting your data to your ORCID (see http://orcid.org/ ) also ensures that you get credit for your work. ORCID provides a persistent digital identifier that distinguishes you from every other researcher and supports automated linkages between you and your professional activities, ensuring that your work is recognized. The DataCite metadata template includes places to list ORCIDs of the creator. The DOI creation metadata template has a place for ORCIDs of creators and contributors. If you have published a paper that goes with your data, be sure to cite the DOI in the paper. Provide a link to the paper's DOI in the metadata under \"relatedIdentifier\". If your data include specific instructions for citing or reuse, to provide those in the ReadMe file and (if brief) in the \\\"reuse_or_citation_conditions\\\" metadata field. Whom do I choose for the creator versus contributor? Creators are the main researchers involved in producing the data, or the authors of the publication, in priority order. To supply multiple creators, repeat this property. A creator may be a corporate/institutional or personal name; it does not need to be the person who is submitting the identifier request. A Contributor is the institution or person(s) responsible for collecting, managing, distributing, or otherwise contributing to the development of the resource. To supply multiple contributors, repeat this property. For software, if there is an alternate entity that \"holds, archives, publishes, prints, distributes, releases, issues, or produces\" the code, use the contributorType \"hostingInstitution\" for the code repository. You must include the role of all contributors. Choose from the dropdown list in the DOI request template. Which license can I use to publish my data? You can choose one of two open source licenses, depending on the materials you will be publishing: ODC PDDL for non-copyrightable materials (i.e., data only). CC0 for copyrightable material (Workflows, White Papers, Project Documents). If you have special circumstances that require a different license (e.g., your dataset is aggregated from previously published data that already has another license), please contact us at doi@cyverse.org . What metadata standards does CyVerse support for data publication? All data will follow the DataCite metadata schema (currently using version 4.1). However, DataCite metadata is citation metadata that does not represent the complexity of the research that went behind creating your data. Therefore, we encourage you to include additional metadata. We suggest that you include the metadata records and other help documents in your publication package within a folder labeled as \"metadata\" so it is easily identifiable for other users. Consider taking advantage of the DE's bulk metadata application feature for adding file level metadata, especially for large datasets. What if I want to change or add metadata to my public data? If you need to make changes to the metadata of a dataset with a DOI, contact us at doi@cyverse.org . If your dataset is connected to a paper that is published after the DOI is created, please contact us with the paper\\'s DOI so we can link it in the metadata. Where can I go for help on permanent identifiers? Email the CyVerse DOI team . Is the CyVerse Curated Data Repository right for my data? \u00b6 Before requesting a permanent identifier in CyVerse Curated Data through the Data Commons , answer the following series of questions. Question 1. Do you have a CyVerse account? Are you a registered CyVerse user? If not, register at CyVerse User Portal . If so, have you used the Discovery Environment (DE)? The tools for submitting data to Data Commons Curated Data are simple to use and available as part of the DE. At a minimum, you should be able to upload and organize your data using the DE or command-line tools, and be able to apply a template. Question 2. Is your data ready for publication? Is the dataset complete, stable, and ready for public consumption? Are you and all contributors to the dataset prepared to move the data into the public domain (meaning that anyone can access and use the data for any purpose, including commercial purposes)? Have you sufficiently documented how the data was created such that other scientists in your field will be able to reuse it? If there is a standard or commonly used format for your datatype, is your data in that format? If no standard exists, is your data in a format that can be easily used by most people with open source software (e.g., tables as a CSV or text file, rather than a Microsoft Excel spreadsheet)? Is your data organized in a clear and reasonable structure that others will be able to understand? If you answered no to any of these questions, your dataset is not yet ready for a permanent identifier through Data Commons Curated Data. Please continue to work on your dataset until it meets these requirements. Data will be reviewed by a curator to ensure that it meets these requirements. If you would like to make your data public, but it is not complete and/or stable, you may request data hosting in the Data Commons. Question 3. Is your data suitable for reuse in scientific analyses? Is your data of the type and format that allow it to be reused in other analyses? Are you prepared to supply metadata for your dataset? Does your dataset or metadata include sufficient instructions (e.g., a Readme file) such that someone in your field can understand how to reuse the data? Question 4. Is there a canonical repository for your data? Does a canonical repository exist for your data? Examples include NCBI, EBI, and MG-RAST. If a canonical repository exists, you should use it. CyVerse is there to help fill a gap, not replace an existing resource. If you answered No If you answered No to any of the questions above, your data may be suitable for a DOI, but not through Data Commons Curated Data. You should consider other repositories that are not geared specifically toward data analysis, such as your institution's library. Tip If your data was generated by or was input for an analysis algorithm or software that you developed yourself, please consider making the method available through CyVerse infrastructure (e.g., the Discovery Environment or Atmosphere) as well.","title":"Getting a DOI"},{"location":"ds/doi/#getting-a-doi","text":"","title":"Getting a DOI"},{"location":"ds/doi/#background","text":"CyVerse Curated Data in the Data Commons contains files that have been assigned a Digital Object Identifier (DOI). These files are secure, stable, and unchangeable , thus they are ideal for easy data reuse and data citation.","title":"Background"},{"location":"ds/doi/#doi-request-quickstart","text":"","title":"DOI Request Quickstart"},{"location":"ds/doi/#1-organize-data","text":"","title":"1. Organize data"},{"location":"ds/doi/#11-create-submission-folder","text":"Organize your data so that there is one folder for each DOI (named according to the Data Commons Naming Conventions--see Step 1.2) Within that folder, include all files in your data package plus the ReadMe file and the inventory. You may have subfolders within a data package. You may include compressed files in a package, as described on the DOI Frequently Asked Questions , but do not compress the entire folder/package","title":"1.1 Create submission folder"},{"location":"ds/doi/#12-name-your-top-level-folder-according-to-the-data-commons-naming-conventions","text":"CyVerse Curated Data datasets are searchable and discoverable based on their metadata. While the dataset itself can have any name chosen by the creator (within reason), the folder that contains the dataset must follow the naming practices described on this page. General guidelines Folder names must be unique. No invalid characters: Be sure there are no spaces or special characters in the folder name . Use underscores between each segment. Folder Name Format $Creator_$subject_$date $Creator: The Creator entry should be the same as entered in the Creator field of the DOI request - DataCite Metadata request form. The Creator is the lead author, the senior author, or the organization with the primary responsibility for the dataset. Start the field (the creator's name) with a capital letter. Co-creators: If there are two co-creators, use both names, separated by an underscore or using camel case. For three or more co-creators, select only one name or use a consortium name. Other contributors should be acknowledged in the metadata (as creators or contributors), which will display on the dataset landing page. $subject: Very briefly describes what the dataset is about. If the subject is more than one word, use either camel case (example: camelCase) or underscores (example: underscore_between_words) to separate the words. If another folder has the exact same name, you may modify the subject slightly to maintain uniqueness. $date: Either just the year, or the month and year, in which the dataset was created. Month and year should be used only if there is likely to be more than one dataset with the same creator and subject within the same year. Month must be a three-letter abbreviation: Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Nov, Dec Examples","title":"1.2. Name your top level folder according to the Data Commons Naming Conventions"},{"location":"ds/doi/#valid-names","text":"Walls_yam_variation_2015 DeBarry_yamGenomicVariation_2016 Esteva_yam_variation_Mar2016 Esteva_Walls_yam_genomic_variation_Jun2016 YamConsortium_Dioscorea_variation_Nov2017","title":"Valid Names"},{"location":"ds/doi/#invalid-names","text":"WallsYamVariation_2016 (Missing underscore between the creator and the subject) Esteva_yam_variation_June2016 (Month should be three letters: Jun) YamConsortium_Nov2017 (No subject) Walls_yam_variation_2016#1 (Contains a special character) Walls YamVariation 2020 (Contains spaces)","title":"Invalid Names"},{"location":"ds/doi/#not-recommended","text":"Although the following will pass validation, they are not recommended because the subject is too vague or too detailed: Walls_variation_2016 (Subject too vague) Esteva_yam_Mar2016 (Subject too vague) DeBarry_yam_genetic_and_environmental_variation_with_phenotype_data_version3_Dioscorea_2016 (Too detailed)","title":"Not recommended"},{"location":"ds/doi/#13-create-a-readme-file","text":"Create a text file labeled \\\"ReadMe\\\" with the following information: How you obtained, organized, and labeled your dataset. How to reuse the data, such as which apps can analyze the data. The inventory (see Step 1.4) may be included as part of the ReadMe file. If your data include sequences, the ReadMe should include a list of corresponding BioSample IDs. Examples of good ReadMe files: https://datacommons.cyverse.org/browse/iplant/home/shared/commons_repo/curated/Carolyn_Lawrence_Dill_GOMAP_Cacao_NCBI_CriolloV2_March_2021.r1/_README.txt https://datacommons.cyverse.org/browse/iplant/home/shared/commons_repo/curated/Liang_Schnable_UNLPlantVision_2017/readMe.txt","title":"1.3. Create a ReadMe file"},{"location":"ds/doi/#14-create-an-inventory","text":"You must create a plain text document that includes an inventory of the contents of the organized dataset (at a minimum, your dataset will contain one data file and one ReadMe file). The inventory may be part of the ReadMe file or a separate file. The inventory should include the ReadMe file and any other additional non-data materials you add to your dataset. If your dataset contains folders with many files (e.g., large collections of images), you do not need to list each file in the inventory. Simply describe the folder and what it contains. Describe the file naming conventions, if that is helpful. Example inventory Lyons_DOI-Example-Aug2020: Top level directory name README.txt: Plain text file that describes the origin of the data, experiments, data processing, etc. Also contains a list and description for the contents of the top-level directory (unless a separate inventory file is provided) License.txt: License file (e.g., GPL, MIT) that governs the use of the data a.data1/: Directory containing data b.data2/: Directory containing more data c.data3/: Directory containing even more data","title":"1.4. Create an inventory"},{"location":"ds/doi/#2-add-metadata","text":"You must provide all required metadata in the 'DOI Request--Datacite 4.1' template at a minimum. You may add any additional metadata that is appropriate. We encourage the use of additional metadata to make your data better understood and more discoverable. For more information, including how to apply metadata, see Adding Metadata . Tip Get recognition for your work by including ORCIDs for yourself and all creators and contributors.","title":"2. Add metadata"},{"location":"ds/doi/#21-in-the-data-window-click-the-checkbox-next-to-the-folder","text":"","title":"2.1 In the Data window, click the checkbox next to the folder."},{"location":"ds/doi/#22-select-more-actions-metadata","text":"","title":"2.2 Select More actions &gt; Metadata."},{"location":"ds/doi/#23-select-more-actions-again-view-in-template","text":"","title":"2.3 Select More actions (again) &gt; View in template."},{"location":"ds/doi/#24-choose-the-doi-request-datacite41-metadata-template","text":"","title":"2.4 Choose the 'DOI Request - DataCite4.1' metadata template."},{"location":"ds/doi/#25-complete-the-required-fields-marked-with-an-asterisk-and-as-many-of-the-optional-fields-as-possible","text":"Warning Be sure to include at least 3 subject key words or phrases, so that people can discover your data (Findability)! Each subject should be in its own field (click on the plus next to \"Subject\" to add a subject field. DO NOT use a comma-separated list. )","title":"2.5 Complete the required fields (marked with an asterisk) and as many of the optional fields as possible."},{"location":"ds/doi/#26-save-the-template","text":"","title":"2.6 Save the template."},{"location":"ds/doi/#3-submit-request-and-wait-for-validations","text":"","title":"3. Submit request and wait for validations"},{"location":"ds/doi/#31-before-you-submit","text":"Check the following to be sure everything is in order. There are no spaces or special characters in your file or folder names. You have included a ReadMe file that includes all the information specified in step 1.3. You followed the Data Commons Naming Conventions You have filled in all the required fields in the 'DOI Request - DataCite 4.1' metadata template You have included at least 3 subjects in your metadata Each subject is in a separate field (not comma-separated). The 'description' in your metadata is adequate (other users can tell what your data describe). You understand that once the DOI is issued you cannot change the data. If you know your data will change you should consider waiting to request a DOI. If you do need to make changes later this DOI can be deprecated, a new DOI issued, and the two DOIs linked together as versions.","title":"3.1. Before you submit"},{"location":"ds/doi/#32-submit-doi-request","text":"In the Data tab, click the checkbox next to the folder. Select More actions > Request DOI. After verifying you have read the instructions (i.e., this guide), click \\\"I need a DOI\\\". You will receive a verification email that your request has been received, and a notification will be listed in the Notifications list in the DE. Note At this point, your folder will move to a new location under Community Data/commons_repo/staging.","title":"3.2 Submit DOI request"},{"location":"ds/doi/#33-validations","text":"After submitting your request, a CyVerse curator begins validating your dataset, metadata, and overall configuration of your dataset. Validations are based solely on the required DOI metadata and folder-naming conventions, as well as the data's potential utility to the CyVerse and larger scientific community, not the quality of your data. This is not a peer review process. Possible validation actions If the curator determines that minor changes are needed, they may make those changes themself. If the curator determines that substantive changes are needed, they will contact you with required changes. If the curator determines that your dataset is not appropriate for the Curated Data section of the Data Commons (e.g., because it belongs in NCBI), you will be notified. If the curator determines that the dataset is adequately organized and the DataCite metadata are accurate, they will provide a DOI, and you will be notified of the DOI and the final dataset location. Tip To check the status of your DOI request, click Notifications (the bell icon) at the top right of the DE screen.","title":"3.3. Validations"},{"location":"ds/doi/#4-after-publication","text":"","title":"4. After publication"},{"location":"ds/doi/#41-get-your-dataset-noticed","text":"Metadata, the description about your data, is key to getting your dataset noticed in the world wide web. Search engines and bibliographic aggregators index the metadata that you create to obtain a DOI. Thus, it is important that you do the following: Make sure the metadata are complete. Include precise keywords in the \"Subject\" attribute. Include descriptive terms about the science and themes involved in your research. These can go in the \"Subject\" attribute, but you can also create additional metadata attributes specific to your dataset. Include methods used to generate the dataset in the \"Description\" attribute, and in more detail in a ReadMe file. Describe the dataset for a broader audience so that they understand your research. Use the \"Description\" field for this. If you or team members have an ORCID ID, make sure to include it in the metadata.","title":"4.1. Get your dataset noticed"},{"location":"ds/doi/#42-publicize-your-dataset","text":"Consider using social media to share the DOI of your dataset, and tag CyVerse. If you have an interesting story about your data, contact us at learning@cyverse.org , and we may be able to share it through CyVerse outreach. If you have a tool or workflow you developed to analyze your data in CyVerse, consider presenting it as part of our CyVerse Webinars.","title":"4.2. Publicize your dataset"},{"location":"ds/doi/#doi-frequently-asked-questions","text":"Why should I publish my data in CyVerse Curated Data? CyVerse Curated Data is the ideal platform for ease of data reuse. Because it is assigned a permanent identifier (DOI), it is stable and unchangeable, making it ideal for data citation. Because the data is stored in large-scale storage resources that are monitored 24/7, it is secure. Because it allows transfer, upload, and download across different computers and platforms, it can store very large datasets. And because its data is accessible to CyVerse's suite of large-scale computational analysis resources, users can seamlessly analyze, manage, and publish new results. For more information, see Is CyVerse Curated Data Right for My Data? . What are the conditions for data to be published through CyVerse Curated Data? Several conditions must exist in your data before it can be published in CyVerse Curated Data: You must be a registered CyVerse account holder. To register for an account, see the Create Account Quickstart . A dataset may be up to 100GB in size. If you are interested in depositing a larger dataset, please request an increased data allocation before requesting a permanent identifier using this form . Data must be both curated and static. Once the data is published, it cannot be amended (although newer versions can be published). Data must be organized to identify the different components (raw, preprocessed, analysis, etc.). Compressed files must be in LASzip ( https://www.laszip.org/ ) or open-source Gzip family of compression formats including zip, tar, tar.gz, or tgz. At minimum, the dataset must include a complete description according to the DataCite standard . Domain-specific schemas, however, and the addition of ReadMe files, publications, or help notes that explain the data as well as how they were obtained and can be used, are encouraged. In organizing and documenting the data, users should ask themselves, \"What would someone need to reuse this data?\" Can I publish to the Data Commons if my data is not static and curated by CyVerse? Yes, you can make data available to the public via Community Released Data. You can request a community release data folder using this form . What is a DOI? A DOI is a Digital Object Identifier . It is a permanent, redirectable identifier and URL for your dataset, so that even if the location of your dataset changes, it can still be found with the same ID. DOIs are issued by CyVerse through the DataCite _ service. Do I need to contact CyVerse before requesting a DOI? The process of requesting a DOI is automated through the DE, but some tasks must be handled manually, such as DOIs for datasets with more than 1000 files or DOIs for datasets that are stored somewhere other than /iplant/home/share/commons_repo/curated. If you match either of those cases, please contact us at doi@cyverse.org . Also contact us if you have questions about how to organize your data or what scientific metadata to include. How much does a CyVerse permanent identifier cost? At this time, CyVerse does not charge for DOIs. However, the dataset must meet the requirements given on the page Is CyVerse Curated Data Right for My Data? . In the future, there may be a charge for issuing permanent identifiers in the CyVerse Data Commons. How long will it take to obtain a permanent identifier and publish my data? Provided that your dataset is in good order and ready to be published, the process may take up to one week, as it may involve a dialogue with the CyVerse data curators. If your data is well organized and the metadata is complete and accurate, the process will be much faster (usually 1-2 business days). It is best to submit your request at least one week before you need the identifier (e.g., for a manuscript submission) or more for very large of complex datasets. Can I publish different versions of my data? Yes. Each new version must be documented, and will be assigned a new permanent identifier that references the original dataset. For new versions, contact us at doi@cyverse.org . How small or big should my data be to be published? The size of the dataset is less important than its utility to the scientific community. Although there is no lower size limit for requesting a DOI, the default upper size limit for data allocations on CyVerse is 100GB. If you are interested in depositing a larger dataset, please request an increased data allocation before requesting a permanent identifier. Determine what to include A data collection may be composed of multiple files and different datasets. In preparing your data for publication identify the data and other materials that you consider useful for validation and reuse of your research: Data associated to a research project may include multiple files with different roles. If there are components of your dataset that belong in a public repository such as NCBI (e.g., fastq files), submit them to the repository, rather than to CyVerse Curated Data. You may want to include a list of external files in your dataset, with links. Beyond data, you will include the ReadMe file (see Step 1.3), and you may include scripts or links to scripts to run your analysis. Links to analysis tools can also be included as metadata (see Step 2). Determine how many permanent identifiers to request To determine how many DOIs to request for a given data collection, consider the following: Size and number of components. How many studies or publications does it represent? Is your data collection formed by different datasets and are those likely to be used separately? Do you want to create a data collection with one DOI for the entire project and additional related DOIs for distinct datasets so that they are cited individually? DOIs can be nested, so that one dataset is part of another. If you are uncertain about how many DOIs to request, contact us at doi@cyverse.org . What is the policy for submitting compressed data to CyVerse Curated Data? Certain file types are regularly transferred, stored, and used in applications in a compressed form, such as FASTQ for genomic data and LAZ for LIDAR data. Curated Data supports the deposition of files in the following open compressed formats: LASzip ( https://www.laszip.org/ ) and the open source Gzip ( http://en.wikipedia.org/wiki/Gzip ) family of compression formats including zip, tar, tar.gz, or tgz. Can I publish data in CyVerse if I am not a CyVerse user? You must have a CyVerse account to publish your data in the Data Commons repositories (Community Contributed or Curated Data). You do not have to be a user of the entire platform, but at minimum you must be able to upload data, add metadata, and use the Discovery Environment to request a DOI. If you have not used the DE's metadata features before, start with Using Metadata in the DE and read the section on metadata templates. How secure is the data in the Curated Data site? Data in our platform is stored in large-scale storage resources that are monitored 24/7. Data is authenticated through checksum analysis at ingest, and is locally and geographically replicated so that if any one system fails there will always be a safe copy of your data. What is CyVerse Data Commons' long-term commitment to hosting public data? If and when the Data Commons cannot host your data in CyVerse Curated Data, it will transfer custody of the data to another repository and will change the target URL to which the identifier points. What if in the future I want to move my data to another repository? If you want to move your data to another repository, please send a ticket with the new DOI and URL location and we will change the DOI target. You may leave a copy of the dataset in the CyVerse Curated Data site for ease of reuse within the computational environment. CyVerse will update the metadata to reflect the relationship between the two identical datasets. How can I make it easier for people to give me (and my co-creators) credit for using my dataset? Encourage others to cite your data using the DOI. Each dataset landing page includes a citation that can be copied or downloaded in standard formats (BibTEX or EndNote). Connecting your data to your ORCID (see http://orcid.org/ ) also ensures that you get credit for your work. ORCID provides a persistent digital identifier that distinguishes you from every other researcher and supports automated linkages between you and your professional activities, ensuring that your work is recognized. The DataCite metadata template includes places to list ORCIDs of the creator. The DOI creation metadata template has a place for ORCIDs of creators and contributors. If you have published a paper that goes with your data, be sure to cite the DOI in the paper. Provide a link to the paper's DOI in the metadata under \"relatedIdentifier\". If your data include specific instructions for citing or reuse, to provide those in the ReadMe file and (if brief) in the \\\"reuse_or_citation_conditions\\\" metadata field. Whom do I choose for the creator versus contributor? Creators are the main researchers involved in producing the data, or the authors of the publication, in priority order. To supply multiple creators, repeat this property. A creator may be a corporate/institutional or personal name; it does not need to be the person who is submitting the identifier request. A Contributor is the institution or person(s) responsible for collecting, managing, distributing, or otherwise contributing to the development of the resource. To supply multiple contributors, repeat this property. For software, if there is an alternate entity that \"holds, archives, publishes, prints, distributes, releases, issues, or produces\" the code, use the contributorType \"hostingInstitution\" for the code repository. You must include the role of all contributors. Choose from the dropdown list in the DOI request template. Which license can I use to publish my data? You can choose one of two open source licenses, depending on the materials you will be publishing: ODC PDDL for non-copyrightable materials (i.e., data only). CC0 for copyrightable material (Workflows, White Papers, Project Documents). If you have special circumstances that require a different license (e.g., your dataset is aggregated from previously published data that already has another license), please contact us at doi@cyverse.org . What metadata standards does CyVerse support for data publication? All data will follow the DataCite metadata schema (currently using version 4.1). However, DataCite metadata is citation metadata that does not represent the complexity of the research that went behind creating your data. Therefore, we encourage you to include additional metadata. We suggest that you include the metadata records and other help documents in your publication package within a folder labeled as \"metadata\" so it is easily identifiable for other users. Consider taking advantage of the DE's bulk metadata application feature for adding file level metadata, especially for large datasets. What if I want to change or add metadata to my public data? If you need to make changes to the metadata of a dataset with a DOI, contact us at doi@cyverse.org . If your dataset is connected to a paper that is published after the DOI is created, please contact us with the paper\\'s DOI so we can link it in the metadata. Where can I go for help on permanent identifiers? Email the CyVerse DOI team .","title":"DOI Frequently Asked Questions"},{"location":"ds/doi/#is-the-cyverse-curated-data-repository-right-for-my-data","text":"Before requesting a permanent identifier in CyVerse Curated Data through the Data Commons , answer the following series of questions. Question 1. Do you have a CyVerse account? Are you a registered CyVerse user? If not, register at CyVerse User Portal . If so, have you used the Discovery Environment (DE)? The tools for submitting data to Data Commons Curated Data are simple to use and available as part of the DE. At a minimum, you should be able to upload and organize your data using the DE or command-line tools, and be able to apply a template. Question 2. Is your data ready for publication? Is the dataset complete, stable, and ready for public consumption? Are you and all contributors to the dataset prepared to move the data into the public domain (meaning that anyone can access and use the data for any purpose, including commercial purposes)? Have you sufficiently documented how the data was created such that other scientists in your field will be able to reuse it? If there is a standard or commonly used format for your datatype, is your data in that format? If no standard exists, is your data in a format that can be easily used by most people with open source software (e.g., tables as a CSV or text file, rather than a Microsoft Excel spreadsheet)? Is your data organized in a clear and reasonable structure that others will be able to understand? If you answered no to any of these questions, your dataset is not yet ready for a permanent identifier through Data Commons Curated Data. Please continue to work on your dataset until it meets these requirements. Data will be reviewed by a curator to ensure that it meets these requirements. If you would like to make your data public, but it is not complete and/or stable, you may request data hosting in the Data Commons. Question 3. Is your data suitable for reuse in scientific analyses? Is your data of the type and format that allow it to be reused in other analyses? Are you prepared to supply metadata for your dataset? Does your dataset or metadata include sufficient instructions (e.g., a Readme file) such that someone in your field can understand how to reuse the data? Question 4. Is there a canonical repository for your data? Does a canonical repository exist for your data? Examples include NCBI, EBI, and MG-RAST. If a canonical repository exists, you should use it. CyVerse is there to help fill a gap, not replace an existing resource. If you answered No If you answered No to any of the questions above, your data may be suitable for a DOI, but not through Data Commons Curated Data. You should consider other repositories that are not geared specifically toward data analysis, such as your institution's library. Tip If your data was generated by or was input for an analysis algorithm or software that you developed yourself, please consider making the method available through CyVerse infrastructure (e.g., the Discovery Environment or Atmosphere) as well.","title":"Is the CyVerse Curated Data Repository right for my data?"},{"location":"ds/icommands/","text":"Transferring Data with iCommands and Command Line \u00b6 iCommands is a collection of tools developed by the iRODS project. iRODS is the technology that supports the CyVerse Data Store. Using iCommands is the most flexible way to interact with the Data Store. This section will cover the basics of iCommands installation and use. Things to remember about iCommands: - This is a *command line* tool, operated in a terminal. - There is no support for Windows OS and PowerShell so we recommend using [Windows Subsystem for Linux (WSL)](https://docs.microsoft.com/en-us/windows/wsl/install). iCommands Installation for Linux \u00b6 On a Linux OS you can use a package manager to install iCommands in the terminal. Instructions for configuring the iRODS repositories in Linux can be be found on the iRODS Packages webpage. CentOS: Configure the repository and use yum to install the iCommands package irods-icommands . sudo rpm --import https://packages.irods.org/irods-signing-key.asc wget -qO - https://packages.irods.org/renci-irods.yum.repo \\ | sudo tee /etc/yum.repos.d/renci-irods.yum.repo sudo yum install irods-icommands If that does not work, you can install an older version of iCommands, 4.1.12, from RENCI's website. sudo yum install \\ https://files.renci.org/pub/irods/releases/4.1.12/centos7/irods-icommands-4.1.12-centos7-x86_64.rpm Ubuntu 18.04: Configure the repository and use apt to install the iCommands package irods-icommands . wget -qO - https://packages.irods.org/irods-signing-key.asc \\ | sudo apt-key add - echo \"deb [arch=amd64] https://packages.irods.org/apt/ $( lsb_release -sc ) main\" \\ | sudo tee /etc/apt/sources.list.d/renci-irods.list sudo apt-get update sudo apt install irods-icommands Ubuntu 20.04: iRODS doesn't currently support Ubuntu 20.04 (yet). However, the version for Ubuntu 18.04 works as long as a few extra packages are installed. Here are the commands to configure the iRODS repository: wget -qO - https://packages.irods.org/irods-signing-key.asc \\ | sudo apt-key add - echo \"deb [arch=amd64] https://packages.irods.org/apt/ bionic main\" \\ | sudo tee /etc/apt/sources.list.d/renci-irods.list sudo apt update Prior to installing the iCommands package, a few 18.04 packages need to be installed that are not available for 20.04. Here are the comands to install these packages: wget --directory-prefix /tmp/ \\ http://security.ubuntu.com/ubuntu/pool/main/p/python-urllib3/python-urllib3_1.22-1ubuntu0.18.04.2_all.deb \\ http://security.ubuntu.com/ubuntu/pool/main/r/requests/python-requests_2.18.4-2ubuntu0.1_all.deb \\ http://security.ubuntu.com/ubuntu/pool/main/o/openssl1.0/libssl1.0.0_1.0.2n-1ubuntu5.6_amd64.deb sudo apt install \\ /tmp/libssl1.0.0_1.0.2n-1ubuntu5.6_amd64.deb \\ /tmp/python-urllib3_1.22-1ubuntu0.18.04.2_all.deb \\ /tmp/python-requests_2.18.4-2ubuntu0.1_all.deb Now apt can be used to install the iCommands package irods-icommands . sudo apt install irods-icommands If the above does not work, e.g., incomplete support for Ubuntu 20.04, try installing an older version of iCommands, 4.1.10, by doing the following: sudo apt update wget \\ http://mirrors.kernel.org/ubuntu/pool/main/g/glibc/multiarch-support_2.27-3ubuntu1.4_amd64.deb \\ http://ftp.se.debian.org/debian/pool/main/o/openssl/libssl1.0.0_1.0.1t-1+deb8u8_amd64.deb \\ https://files.renci.org/pub/irods/releases/4.1.10/ubuntu14/irods-icommands-4.1.10-ubuntu14-x86_64.deb sudo dpkg --install \\ multiarch-support_2.27-3ubuntu1.4_amd64.deb \\ libssl1.0.0_1.0.1t-1+deb8u8_amd64.deb \\ irods-icommands-4.1.10-ubuntu14-x86_64.deb Arm64/Aarch64: A CyVerse community user compiled i-commands for Raspberry Pi (and tested in NVIDIA Jetsons): https://github.com/jmscslgroup/libpanda/blob/master/scripts/irods-icommands-debs.tgz wget https://github.com/jmscslgroup/libpanda/raw/master/scripts/irods-icommands-debs.tgz tar zxvf irods-icommands-debs.tgz cd irods-icommands-debs/ ./install.sh iCommands Installation for Mac OS X \u00b6 iRODS doesn't currently support Mac OS X, but CyVerse has built an installer for it. Download the CyVerse-specific Mac OS iCommands Download . Open the file by locating it in your Finder; right-click to run the installer. You may get a security warning noting the file is from an \"unidentified developer.\" You may bypass this warning by going to 'System Preferences', selecting the 'Security & Privacy' menu, and clicking the 'Open Anyway' button to proceed. Follow the prompts to begin the installation. You will need to know the administrator password to install new software on your computer. Note Newer Mac OS X now ships with zsh as its default shell rather than bash . The installer will attempt to write some environmental variables to the .bashrc file which for zsh is called the .zshrc . By default, this installation will place iCommands in your system PATH so you should be ready to run iCommands immediately at the terminal. If this does not happen (i.e., you get an error when trying to run iinit ), you can add the iCommands path by editing your .zshrc file: # add iCommands Path export PATH = \"/Applications/icommands/: $PATH \" export IRODS_PLUGINS_HOME = /Applications/icommands/plugins/ and then in terminal source the file source ~/.zshrc . iCommands First-time Configuration \u00b6 Note If using iCommands in an HPC environment, which already has iCommands installed, run the module load irods command to get access to iRODS iCommands. Once iCommands is installed and in the system PATH , these instructions apply at a terminal in Mac OS X and Linux systems. Open a terminal Type iinit command to start the configuration process. When prompted, enter the values shown below as comments in the example code block. CyVerse Data Store configuration: CyVerse Data Store configuration: host name port # username zone password data.cyverse.org 1247 CyVerse UserID iplant CyVerse Password Note You can reconfigure iCommands for other iRODS zones by changing your environment file. Verify that your iCommands installation works and is properly configured using the ils command to list the contents of your Data Store home directory. ils /iplant/home/your_home_directory: file1 file2 file3 C- /iplant/home/your_home_directory/analyses C- /iplant/home/your_home_directory/another_folder Anonymous Access to the CyVerse Data Store \u00b6 You can access public data in the CyVerse Data Store with iCommands using: Username: anonymous Password: Upload Files/Folders from Local Computer to Data Store \u00b6 Warning When uploading your data to the Data Store, you should not upload files/folders with names containing spaces (e.g., experiment one.fastq ) or special characters (e.g., ~ `` ! @ # $ % ^ & * ( ) + = { } [ ] | : ; \" ' < > , ? / and \\). The Apps on the Discovery Environment and most command line applications will typically not tolerate these characters. For long file/folder names, we recommend the use of underscores (e.g., experiment_one.fastq) instead of spaces. See the full iCommands iput documentation for more information. Upload a directory using the iput command. Remember, the -r flag is used to recursively upload a directory, so omit the -r flag if you are uploading a single file. iput -rPT /local_directory /iplant/home/cyverse_username/destination_folder # This command will output the progress as it uploads your local directory There are several optional arguments that the upload iCommand iput can take: iput -r # for recursive transfer of directories and their contents iput -P # to display the progress of the upload iput -f # to force the upload and overwrite iput -T # to renew socket connection after 10 mins (this may help connections # that are failing due to some connection/firewall settings) Download Files/Folders from Data Store to Local Computer \u00b6 See the full iCommands iget documentation for more information. Download a file using the iget command. Remember, the -r flag is used to recursively upload a directory, so omit the -r flag if you are uploading a single file. iget -PT /iplant/home/cyverse_username/target_file /local_destination # This command will output the progress as it downloads to your local machine Using optional arguments There are several optional arguments that the upload iCommand iget can take: iget -r # for recursive transfer of directories and their contents iget -P # to display the progress of the upload iget -f # to force the upload and overwrite iget -T # to renew socket connection after 10 mins (this may help connections # that are failing due to some connection/firewall settings) NetCDF iCommands \u00b6 For the Linux distributions, there are three extra iCommands that support common NetCDF operations: inc performs data operations on a list of NetCDF files incarch archives an open-ended time series data incattr performs operation on attributes of NetCDF files Each of these commands accepts the -h command line option. When a command is called with this option, it displays the command's help documentation. Please see this help documentation for more information. Installation Install iRODS Runtime. Before the NetCDF iCommands can be installed, the current version of the iRODS run-time library needs to be installed. Please install the appropriate version (e.g., irods-runtime-X-X-XX ). The distribution-specific packages can be found on RENCI's iRODs website . Install NetCDF API. Once the run-time library is installed, the iRODS NetCDF API library needs to be installed. Please use the appropriate link to download the installation package and install it. The package installer will likely warn that iRODS user and/or group don't exist, and that it will be using root instead. These warnings are harmless, since the package contents should be installed with root ownership. CentOS7 NetCDF API Ubuntu 14+ NetCDF API Additional Frequently Used iCommands \u00b6 In addition to the commands above, there are several frequently used iCommands, most of which follow the Linux paradigm: ipwd : Print current directory imkdir : Create a directory icd : Change directory irsync : Sync local directory with iRODS directory","title":"Transferring Data with iCommands and Command Line"},{"location":"ds/icommands/#transferring-data-with-icommands-and-command-line","text":"iCommands is a collection of tools developed by the iRODS project. iRODS is the technology that supports the CyVerse Data Store. Using iCommands is the most flexible way to interact with the Data Store. This section will cover the basics of iCommands installation and use. Things to remember about iCommands: - This is a *command line* tool, operated in a terminal. - There is no support for Windows OS and PowerShell so we recommend using [Windows Subsystem for Linux (WSL)](https://docs.microsoft.com/en-us/windows/wsl/install).","title":"Transferring Data with iCommands and Command Line"},{"location":"ds/icommands/#icommands-installation-for-linux","text":"On a Linux OS you can use a package manager to install iCommands in the terminal. Instructions for configuring the iRODS repositories in Linux can be be found on the iRODS Packages webpage. CentOS: Configure the repository and use yum to install the iCommands package irods-icommands . sudo rpm --import https://packages.irods.org/irods-signing-key.asc wget -qO - https://packages.irods.org/renci-irods.yum.repo \\ | sudo tee /etc/yum.repos.d/renci-irods.yum.repo sudo yum install irods-icommands If that does not work, you can install an older version of iCommands, 4.1.12, from RENCI's website. sudo yum install \\ https://files.renci.org/pub/irods/releases/4.1.12/centos7/irods-icommands-4.1.12-centos7-x86_64.rpm Ubuntu 18.04: Configure the repository and use apt to install the iCommands package irods-icommands . wget -qO - https://packages.irods.org/irods-signing-key.asc \\ | sudo apt-key add - echo \"deb [arch=amd64] https://packages.irods.org/apt/ $( lsb_release -sc ) main\" \\ | sudo tee /etc/apt/sources.list.d/renci-irods.list sudo apt-get update sudo apt install irods-icommands Ubuntu 20.04: iRODS doesn't currently support Ubuntu 20.04 (yet). However, the version for Ubuntu 18.04 works as long as a few extra packages are installed. Here are the commands to configure the iRODS repository: wget -qO - https://packages.irods.org/irods-signing-key.asc \\ | sudo apt-key add - echo \"deb [arch=amd64] https://packages.irods.org/apt/ bionic main\" \\ | sudo tee /etc/apt/sources.list.d/renci-irods.list sudo apt update Prior to installing the iCommands package, a few 18.04 packages need to be installed that are not available for 20.04. Here are the comands to install these packages: wget --directory-prefix /tmp/ \\ http://security.ubuntu.com/ubuntu/pool/main/p/python-urllib3/python-urllib3_1.22-1ubuntu0.18.04.2_all.deb \\ http://security.ubuntu.com/ubuntu/pool/main/r/requests/python-requests_2.18.4-2ubuntu0.1_all.deb \\ http://security.ubuntu.com/ubuntu/pool/main/o/openssl1.0/libssl1.0.0_1.0.2n-1ubuntu5.6_amd64.deb sudo apt install \\ /tmp/libssl1.0.0_1.0.2n-1ubuntu5.6_amd64.deb \\ /tmp/python-urllib3_1.22-1ubuntu0.18.04.2_all.deb \\ /tmp/python-requests_2.18.4-2ubuntu0.1_all.deb Now apt can be used to install the iCommands package irods-icommands . sudo apt install irods-icommands If the above does not work, e.g., incomplete support for Ubuntu 20.04, try installing an older version of iCommands, 4.1.10, by doing the following: sudo apt update wget \\ http://mirrors.kernel.org/ubuntu/pool/main/g/glibc/multiarch-support_2.27-3ubuntu1.4_amd64.deb \\ http://ftp.se.debian.org/debian/pool/main/o/openssl/libssl1.0.0_1.0.1t-1+deb8u8_amd64.deb \\ https://files.renci.org/pub/irods/releases/4.1.10/ubuntu14/irods-icommands-4.1.10-ubuntu14-x86_64.deb sudo dpkg --install \\ multiarch-support_2.27-3ubuntu1.4_amd64.deb \\ libssl1.0.0_1.0.1t-1+deb8u8_amd64.deb \\ irods-icommands-4.1.10-ubuntu14-x86_64.deb Arm64/Aarch64: A CyVerse community user compiled i-commands for Raspberry Pi (and tested in NVIDIA Jetsons): https://github.com/jmscslgroup/libpanda/blob/master/scripts/irods-icommands-debs.tgz wget https://github.com/jmscslgroup/libpanda/raw/master/scripts/irods-icommands-debs.tgz tar zxvf irods-icommands-debs.tgz cd irods-icommands-debs/ ./install.sh","title":"iCommands Installation for Linux"},{"location":"ds/icommands/#icommands-installation-for-mac-os-x","text":"iRODS doesn't currently support Mac OS X, but CyVerse has built an installer for it. Download the CyVerse-specific Mac OS iCommands Download . Open the file by locating it in your Finder; right-click to run the installer. You may get a security warning noting the file is from an \"unidentified developer.\" You may bypass this warning by going to 'System Preferences', selecting the 'Security & Privacy' menu, and clicking the 'Open Anyway' button to proceed. Follow the prompts to begin the installation. You will need to know the administrator password to install new software on your computer. Note Newer Mac OS X now ships with zsh as its default shell rather than bash . The installer will attempt to write some environmental variables to the .bashrc file which for zsh is called the .zshrc . By default, this installation will place iCommands in your system PATH so you should be ready to run iCommands immediately at the terminal. If this does not happen (i.e., you get an error when trying to run iinit ), you can add the iCommands path by editing your .zshrc file: # add iCommands Path export PATH = \"/Applications/icommands/: $PATH \" export IRODS_PLUGINS_HOME = /Applications/icommands/plugins/ and then in terminal source the file source ~/.zshrc .","title":"iCommands Installation for Mac OS X"},{"location":"ds/icommands/#icommands-first-time-configuration","text":"Note If using iCommands in an HPC environment, which already has iCommands installed, run the module load irods command to get access to iRODS iCommands. Once iCommands is installed and in the system PATH , these instructions apply at a terminal in Mac OS X and Linux systems. Open a terminal Type iinit command to start the configuration process. When prompted, enter the values shown below as comments in the example code block. CyVerse Data Store configuration: CyVerse Data Store configuration: host name port # username zone password data.cyverse.org 1247 CyVerse UserID iplant CyVerse Password Note You can reconfigure iCommands for other iRODS zones by changing your environment file. Verify that your iCommands installation works and is properly configured using the ils command to list the contents of your Data Store home directory. ils /iplant/home/your_home_directory: file1 file2 file3 C- /iplant/home/your_home_directory/analyses C- /iplant/home/your_home_directory/another_folder","title":"iCommands First-time Configuration"},{"location":"ds/icommands/#anonymous-access-to-the-cyverse-data-store","text":"You can access public data in the CyVerse Data Store with iCommands using: Username: anonymous Password:","title":"Anonymous Access to the CyVerse Data Store"},{"location":"ds/icommands/#upload-filesfolders-from-local-computer-to-data-store","text":"Warning When uploading your data to the Data Store, you should not upload files/folders with names containing spaces (e.g., experiment one.fastq ) or special characters (e.g., ~ `` ! @ # $ % ^ & * ( ) + = { } [ ] | : ; \" ' < > , ? / and \\). The Apps on the Discovery Environment and most command line applications will typically not tolerate these characters. For long file/folder names, we recommend the use of underscores (e.g., experiment_one.fastq) instead of spaces. See the full iCommands iput documentation for more information. Upload a directory using the iput command. Remember, the -r flag is used to recursively upload a directory, so omit the -r flag if you are uploading a single file. iput -rPT /local_directory /iplant/home/cyverse_username/destination_folder # This command will output the progress as it uploads your local directory There are several optional arguments that the upload iCommand iput can take: iput -r # for recursive transfer of directories and their contents iput -P # to display the progress of the upload iput -f # to force the upload and overwrite iput -T # to renew socket connection after 10 mins (this may help connections # that are failing due to some connection/firewall settings)","title":"Upload Files/Folders from Local Computer to Data Store"},{"location":"ds/icommands/#download-filesfolders-from-data-store-to-local-computer","text":"See the full iCommands iget documentation for more information. Download a file using the iget command. Remember, the -r flag is used to recursively upload a directory, so omit the -r flag if you are uploading a single file. iget -PT /iplant/home/cyverse_username/target_file /local_destination # This command will output the progress as it downloads to your local machine Using optional arguments There are several optional arguments that the upload iCommand iget can take: iget -r # for recursive transfer of directories and their contents iget -P # to display the progress of the upload iget -f # to force the upload and overwrite iget -T # to renew socket connection after 10 mins (this may help connections # that are failing due to some connection/firewall settings)","title":"Download Files/Folders from Data Store to Local Computer"},{"location":"ds/icommands/#netcdf-icommands","text":"For the Linux distributions, there are three extra iCommands that support common NetCDF operations: inc performs data operations on a list of NetCDF files incarch archives an open-ended time series data incattr performs operation on attributes of NetCDF files Each of these commands accepts the -h command line option. When a command is called with this option, it displays the command's help documentation. Please see this help documentation for more information. Installation Install iRODS Runtime. Before the NetCDF iCommands can be installed, the current version of the iRODS run-time library needs to be installed. Please install the appropriate version (e.g., irods-runtime-X-X-XX ). The distribution-specific packages can be found on RENCI's iRODs website . Install NetCDF API. Once the run-time library is installed, the iRODS NetCDF API library needs to be installed. Please use the appropriate link to download the installation package and install it. The package installer will likely warn that iRODS user and/or group don't exist, and that it will be using root instead. These warnings are harmless, since the package contents should be installed with root ownership. CentOS7 NetCDF API Ubuntu 14+ NetCDF API","title":"NetCDF iCommands"},{"location":"ds/icommands/#additional-frequently-used-icommands","text":"In addition to the commands above, there are several frequently used iCommands, most of which follow the Linux paradigm: ipwd : Print current directory imkdir : Create a directory icd : Change directory irsync : Sync local directory with iRODS directory","title":"Additional Frequently Used iCommands"},{"location":"ds/metadata/","text":"Adding Metadata to Data \u00b6 CyVerse supports a variety of solutions that allow you to associate your raw data with metadata. Metadata is critically important to quality research (see this article on FAIR Principles ), yet it is often an afterthought until you are ready to publish and share. Here are a few metadata features in CyVerse that you should know about and can adopt at the outset. Some things to remember about the CyVerse Discovery Environment You can add metadata to a single file/folder, or in bulk to large collections of data. You can use your own metadata schema or apply one of several metadata templates supported in the Discovery Environment. Additional templates you may wish to use can be found at resources like https://fairsharing.org/ . Metadata can be managed through the DE's graphical user interface or by using iCommands at the command line. This guide only covers metadata options in the Discovery Environment. Viewing and Editing Metadata for a Single File/Folder in the Discovery Environment \u00b6 Note You must have write or own permission to edit an object's metadata. Log into the Discovery Environment . Click on the (Data Icon) to view or browse data. Select (checkbox) a single file/folder for which you want to add metadata. Under the More Actions menu, click on 'Metadata' . You will see existing metadata for the file/folder in the Attribute, Value, Unit (AVU) format. Tip A single piece of metadata, or an AVU, comprises an attribute, value, and unit. An attribute is a changeable property or characteristic of the file or folder you have selected that can be set to a value. For example, \"time point\" might be an attribute of a file, while '7' could be its value, and \"hour\" a unit of the time point. Adding metadata Click the \"+ Add Metadata\" button to add a new entry. Then follow the directions for editing metadata below. Editing or deleting metadata You may use the \"pencil\" icon to edit an existing entry or the \"trash can\" icon to delete an entry. After you have made edits or deletions, click 'Save' to save all entries and apply the metadata. Adding Metadata to Multiple Files/Folders in the Discovery Environment \u00b6 Adding Metadata using a CyVerse Template Log into the Discovery Environment . Click on the (Data Icon) to open a Data window. Select (checkbox) a single file/folder to which you want to add metadata. Under the More Actions menu, click on Metadata . Click on the subsequent More Actions menu and select View in Template . You have two choices in using the template: A. Choose a template; clicking Select will allow you to apply the template and edit the metadata manually in the DE interface. B. Clicking the (Download icon) will download a .csv file you can edit and upload (see Applying bulk metadata below). Click OK to download. (In this example, we will use the DOI Request - DataCite Metadata ) template. Editing a metadata template in the DE Follow the steps in the \"Editing or deleting metadata\" from the section above. Editing a downloaded metadata template Unzip the downloaded template; it will contain two files: blank.csv and guide.csv . Open these files using the spreadsheet editor of your choice. Tip - *blank.csv* is the metadata template that you will complete for your data. - *guide.csv* contains instructions for your template, and will usually include controlled vocabulary terms for metadata descriptors. Edit the template in one of two ways: If all data will be in a single folder: In the blank.csv spreadsheet, in the 'file name or path' column, enter the file names of all the files in that folder you wish to annotate with metadata. Tip 1. In any data window, click the '\u22ee' (3-dots or ellipsis menu) next to any file or folder; choose 'copy path' to get the path to that item in the Data Store. 2. In the remaining columns of the template, enter the values for each file/attribute combination that applies. 3. If desired, add additional columns to the end of the template. The metadata in the additional columns will be saved in the Data Store but will not be stored as part of the template. 4. Save the file in CSV format (i.e., [filename].csv). Avoid using spaces or specal characters when naming the file or parent folder. You may name this metadata file anything you wish, but keep it in CSV format. If data will be in multiple folders: In the blank.csv spreadsheet, in the 'filename or path column, enter the full path of the top-level folder (e.g., /iplant/home/YOURUSERNAME/FOLDERNAME ) 1. In the remaining columns in the first row, enter the values for each file/attribute combination. 2. Repeat for each file, making sure to add the full file path (e.g., /iplant/home/YOURUSERNAME/FOLDERNAME ) for each file. 3. If desired, add additional columns to the end of the template. The metadata in the columns will be saved in the Data Store but will not be stored as part of the template. 4. Save the file in CSV format (i.e., [filename].csv). Avoid using spaces or specal characters when naming the file or parent folder. You may name this metadata file anything you wish, but keep it in CSV format. In an open 'Data' window in the Discovery Environment, navigate to the appropriate location for uploading the template: If the first column of your metadata file contains only file names (i.e., all data files are in the same folder), navigate to the folder and use the Upload button (Browse local) or your choice of upload tool to upload the metadata (csv file) to that folder. If the first column of your metadata file contains the full path to each file (i.e., the data files are in different folders), it does not matter where the metadata file is located on the Data Store. Use the Upload button (Browse local) or your choice of upload tool to upload the metadata (csv file) to an appropriate location on the Data Store. Tip For convenient management and editing, use absolute file paths (e.g., /iplant/home/your_file_location ) so that all of your metadata spreadsheets will be in one location on the Data Store. To apply the metadata, select (checkbox) in the Data window the name of the folder containing the data files to which you want to apply the metadata in bulk. Click the More Actions menu, select 'Apply Bulk Metadata'; browse to the uploaded metadata spreadsheet and select it. Your metadata should now be applied to your files. You should receive a notification (bell icon) in the Discovery Environment and you can confirm the metadata have been correctly applied by following the steps in the preceding section to view metadata.","title":"Adding Metadata"},{"location":"ds/metadata/#adding-metadata-to-data","text":"CyVerse supports a variety of solutions that allow you to associate your raw data with metadata. Metadata is critically important to quality research (see this article on FAIR Principles ), yet it is often an afterthought until you are ready to publish and share. Here are a few metadata features in CyVerse that you should know about and can adopt at the outset. Some things to remember about the CyVerse Discovery Environment You can add metadata to a single file/folder, or in bulk to large collections of data. You can use your own metadata schema or apply one of several metadata templates supported in the Discovery Environment. Additional templates you may wish to use can be found at resources like https://fairsharing.org/ . Metadata can be managed through the DE's graphical user interface or by using iCommands at the command line. This guide only covers metadata options in the Discovery Environment.","title":"Adding Metadata to Data"},{"location":"ds/metadata/#viewing-and-editing-metadata-for-a-single-filefolder-in-the-discovery-environment","text":"Note You must have write or own permission to edit an object's metadata. Log into the Discovery Environment . Click on the (Data Icon) to view or browse data. Select (checkbox) a single file/folder for which you want to add metadata. Under the More Actions menu, click on 'Metadata' . You will see existing metadata for the file/folder in the Attribute, Value, Unit (AVU) format. Tip A single piece of metadata, or an AVU, comprises an attribute, value, and unit. An attribute is a changeable property or characteristic of the file or folder you have selected that can be set to a value. For example, \"time point\" might be an attribute of a file, while '7' could be its value, and \"hour\" a unit of the time point. Adding metadata Click the \"+ Add Metadata\" button to add a new entry. Then follow the directions for editing metadata below. Editing or deleting metadata You may use the \"pencil\" icon to edit an existing entry or the \"trash can\" icon to delete an entry. After you have made edits or deletions, click 'Save' to save all entries and apply the metadata.","title":"Viewing and Editing Metadata for a Single File/Folder in the Discovery Environment"},{"location":"ds/metadata/#adding-metadata-to-multiple-filesfolders-in-the-discovery-environment","text":"Adding Metadata using a CyVerse Template Log into the Discovery Environment . Click on the (Data Icon) to open a Data window. Select (checkbox) a single file/folder to which you want to add metadata. Under the More Actions menu, click on Metadata . Click on the subsequent More Actions menu and select View in Template . You have two choices in using the template: A. Choose a template; clicking Select will allow you to apply the template and edit the metadata manually in the DE interface. B. Clicking the (Download icon) will download a .csv file you can edit and upload (see Applying bulk metadata below). Click OK to download. (In this example, we will use the DOI Request - DataCite Metadata ) template. Editing a metadata template in the DE Follow the steps in the \"Editing or deleting metadata\" from the section above. Editing a downloaded metadata template Unzip the downloaded template; it will contain two files: blank.csv and guide.csv . Open these files using the spreadsheet editor of your choice. Tip - *blank.csv* is the metadata template that you will complete for your data. - *guide.csv* contains instructions for your template, and will usually include controlled vocabulary terms for metadata descriptors. Edit the template in one of two ways: If all data will be in a single folder: In the blank.csv spreadsheet, in the 'file name or path' column, enter the file names of all the files in that folder you wish to annotate with metadata. Tip 1. In any data window, click the '\u22ee' (3-dots or ellipsis menu) next to any file or folder; choose 'copy path' to get the path to that item in the Data Store. 2. In the remaining columns of the template, enter the values for each file/attribute combination that applies. 3. If desired, add additional columns to the end of the template. The metadata in the additional columns will be saved in the Data Store but will not be stored as part of the template. 4. Save the file in CSV format (i.e., [filename].csv). Avoid using spaces or specal characters when naming the file or parent folder. You may name this metadata file anything you wish, but keep it in CSV format. If data will be in multiple folders: In the blank.csv spreadsheet, in the 'filename or path column, enter the full path of the top-level folder (e.g., /iplant/home/YOURUSERNAME/FOLDERNAME ) 1. In the remaining columns in the first row, enter the values for each file/attribute combination. 2. Repeat for each file, making sure to add the full file path (e.g., /iplant/home/YOURUSERNAME/FOLDERNAME ) for each file. 3. If desired, add additional columns to the end of the template. The metadata in the columns will be saved in the Data Store but will not be stored as part of the template. 4. Save the file in CSV format (i.e., [filename].csv). Avoid using spaces or specal characters when naming the file or parent folder. You may name this metadata file anything you wish, but keep it in CSV format. In an open 'Data' window in the Discovery Environment, navigate to the appropriate location for uploading the template: If the first column of your metadata file contains only file names (i.e., all data files are in the same folder), navigate to the folder and use the Upload button (Browse local) or your choice of upload tool to upload the metadata (csv file) to that folder. If the first column of your metadata file contains the full path to each file (i.e., the data files are in different folders), it does not matter where the metadata file is located on the Data Store. Use the Upload button (Browse local) or your choice of upload tool to upload the metadata (csv file) to an appropriate location on the Data Store. Tip For convenient management and editing, use absolute file paths (e.g., /iplant/home/your_file_location ) so that all of your metadata spreadsheets will be in one location on the Data Store. To apply the metadata, select (checkbox) in the Data window the name of the folder containing the data files to which you want to apply the metadata in bulk. Click the More Actions menu, select 'Apply Bulk Metadata'; browse to the uploaded metadata spreadsheet and select it. Your metadata should now be applied to your files. You should receive a notification (bell icon) in the Discovery Environment and you can confirm the metadata have been correctly applied by following the steps in the preceding section to view metadata.","title":"Adding Metadata to Multiple Files/Folders in the Discovery Environment"},{"location":"ds/quick-data-share/","text":"Distributing Data in 6 Steps \u00b6 Note This quickstart is focused on using the Discovery Environment to upload your data. For more information on alternative methods for data management, please refer to the Manage Your Data section or the Data Sharing page. Log into the Discovery Environment . Open the Data icon on the left. 3. Click the Upload button on the top right; in the dropdown menu that appears, select the preferred upload method ( Browse Local or Import from URL ). Additionally, you can also view your upload queue. 4. Once your file(s) is uploaded, click on the ellipses (3 dots) on the right of the file. This will open a dropdown menu with a number of options; Choose Share . 5. In the Share window, choose which CyVerse collaborator to share with. If your collaborator is not a registered CyVerse user, choose anonymous . 6. You can also generate a public URL for files, making it easier to share your files. To do so, click on the ellipses (3 dots) on the right of the file, and click Public Link(s). A window will appear with the generated URL, which collaborators can use to download your file. Warning Generating a public URL works for files, not folders! It is suggested to compress large numbers of files prior to sharing them.","title":"Distributing Data in 6 steps"},{"location":"ds/quick-data-share/#distributing-data-in-6-steps","text":"Note This quickstart is focused on using the Discovery Environment to upload your data. For more information on alternative methods for data management, please refer to the Manage Your Data section or the Data Sharing page. Log into the Discovery Environment . Open the Data icon on the left. 3. Click the Upload button on the top right; in the dropdown menu that appears, select the preferred upload method ( Browse Local or Import from URL ). Additionally, you can also view your upload queue. 4. Once your file(s) is uploaded, click on the ellipses (3 dots) on the right of the file. This will open a dropdown menu with a number of options; Choose Share . 5. In the Share window, choose which CyVerse collaborator to share with. If your collaborator is not a registered CyVerse user, choose anonymous . 6. You can also generate a public URL for files, making it easier to share your files. To do so, click on the ellipses (3 dots) on the right of the file, and click Public Link(s). A window will appear with the generated URL, which collaborators can use to download your file. Warning Generating a public URL works for files, not folders! It is suggested to compress large numbers of files prior to sharing them.","title":"Distributing Data in 6 Steps"},{"location":"ds/share/","text":"Sharing Data \u00b6 One of the most powerful features of the Data Store is the ability to share all of your data instantly with fine-grained permission control. You can share your data with other CyVerse users, and you can also make data available to anonymous users and with identifiers (i.e., a DOI) through the CyVerse Data Commons . This guide covers the most basic, commonly used sharing features of the Discovery Environment and Data Store. Share a File in the Discovery Environment with a URL (Public Link) \u00b6 You can quickly share files in your Data Store using a Discovery Environment Public Link. Note You can only share individual files using the public link. Since files are shared over HTTP, this is only recommended for small files. This is a convenient but less secure method for file transfer. Do not share sensitive/private data using these public links. Tip You can use this method to view files, for example in a genome browser. If necessary, login to the Discovery Environment . In the Data window, select (checkbox) one or more individual file(s) (not folders) you wish to share. From the More actions menu, select Public Link(s) . A new URL will be provided for you in a pop-up. Highlight and copy or click on Copy in order to get a window that will allow you to copy the URL to your clipboard. Anyone you share this link with will be able to download the file. You can test the link in a new web browser window. Tip You can quickly create a link to a file by clicking the \"3 dots\" (ellipsis) icon next to any file and selecting \"Public Link\". To deactivate a public link: To deactivate a link, select (checkbox) one or more individual file(s) that have been shared with a public link; then click on the Details menu. In the Details menu under the Permissions tab, click the \"pencil\" icon next to \" cyverse-anonymous@cyverse.org \" to edit the file's permissions. Share a File/Folder in the Discovery Environment with Another CyVerse User \u00b6 You can share data with another CyVerse user by granting them permission to read, write, or own files/folders. If necessary, login to the Discovery Environment . In the Data window, select (checkbox) file(s) or folder(s) you wish to share with another user; then under the Share menu, enter the CyVerse username, email, or group name you wish to share with. Next, under 'Permissions' choose which permission to grant to the recipient(s) you are sharing this file or folder with. Once you are finished, click Done to begin sharing. The user will be notified that a file has been shared with them. Tip You can share several files/folders at once by selecting them and then clicking the \"Add to Bag\" button in the Data window and then sharing the bag. Hint By managing access to data, the DE allows you to share large datasets instantaneously. Data permissions (based on UNIX permissions) are described in this chart: Permission level Read Download/Save Metadata Rename Move Delete Read X X View Write X X Add/Edit Own X X Add/Edit X X X","title":"Sharing Data"},{"location":"ds/share/#sharing-data","text":"One of the most powerful features of the Data Store is the ability to share all of your data instantly with fine-grained permission control. You can share your data with other CyVerse users, and you can also make data available to anonymous users and with identifiers (i.e., a DOI) through the CyVerse Data Commons . This guide covers the most basic, commonly used sharing features of the Discovery Environment and Data Store.","title":"Sharing Data"},{"location":"ds/share/#share-a-file-in-the-discovery-environment-with-a-url-public-link","text":"You can quickly share files in your Data Store using a Discovery Environment Public Link. Note You can only share individual files using the public link. Since files are shared over HTTP, this is only recommended for small files. This is a convenient but less secure method for file transfer. Do not share sensitive/private data using these public links. Tip You can use this method to view files, for example in a genome browser. If necessary, login to the Discovery Environment . In the Data window, select (checkbox) one or more individual file(s) (not folders) you wish to share. From the More actions menu, select Public Link(s) . A new URL will be provided for you in a pop-up. Highlight and copy or click on Copy in order to get a window that will allow you to copy the URL to your clipboard. Anyone you share this link with will be able to download the file. You can test the link in a new web browser window. Tip You can quickly create a link to a file by clicking the \"3 dots\" (ellipsis) icon next to any file and selecting \"Public Link\". To deactivate a public link: To deactivate a link, select (checkbox) one or more individual file(s) that have been shared with a public link; then click on the Details menu. In the Details menu under the Permissions tab, click the \"pencil\" icon next to \" cyverse-anonymous@cyverse.org \" to edit the file's permissions.","title":"Share a File in the Discovery Environment with a URL (Public Link)"},{"location":"ds/share/#share-a-filefolder-in-the-discovery-environment-with-another-cyverse-user","text":"You can share data with another CyVerse user by granting them permission to read, write, or own files/folders. If necessary, login to the Discovery Environment . In the Data window, select (checkbox) file(s) or folder(s) you wish to share with another user; then under the Share menu, enter the CyVerse username, email, or group name you wish to share with. Next, under 'Permissions' choose which permission to grant to the recipient(s) you are sharing this file or folder with. Once you are finished, click Done to begin sharing. The user will be notified that a file has been shared with them. Tip You can share several files/folders at once by selecting them and then clicking the \"Add to Bag\" button in the Data window and then sharing the bag. Hint By managing access to data, the DE allows you to share large datasets instantaneously. Data permissions (based on UNIX permissions) are described in this chart: Permission level Read Download/Save Metadata Rename Move Delete Read X X View Write X X Add/Edit Own X X Add/Edit X X X","title":"Share a File/Folder in the Discovery Environment with Another CyVerse User"},{"location":"ds/webdav/","text":"HTTP Access with WebDAV \u00b6 WebDAV is an extension to the HTTP protocol that allows users to remotely edit and manage files. CyVerse has added support for WebDAV to the Data Store. This means users can access their home and public folders in the CyVerse Data Store from their local computers using web browsers and other WebDAV-enabled applications such as common operating system file managers. With WebDAV, users can copy files between their local computer and the Data Store as easily as if they were copying them between two folders on their computer. Limitations \u00b6 WebDAV works best for small files or small collections of files. There is no hard size limit for files, but we do not recommended using WebDAV with files over 1 GiB in size (however, 10 GiB files have been downloaded from the CyVerse WebDAV service using a web browser with decent performance). The iCommands still outperform WebDAV. For better ways to download large files or large sets of files, please see the pages for iCommands or Cyberduck . Accessing CyVerse Data via WebDAV Services \u00b6 There are two access points to CyVerse WebDAV services: one for anonymous, read-only access and one for authenticated access. These services can be accessed directly in a web browser, or with command line tools. The simplest way to access WebDAV in a browser is to go to https://data.cyverse.org/ . This will bring up a menu for the options described below. WebDAV provides anonymous, read-only access through URLs rooted at https://data.cyverse.org/dav-anon/ . All data that can be seen by the anonymous user can be accessed anonymously through this service, excluding the immediate contents of /iplant/home and the immediate contents of /iplant/home/<username> , where <username> is any CyVerse login name. WebDAV also provides authenticated access through URLs rooted at https://data.cyverse.org/dav/ . Once a user has authenticated with their CyVerse credentials, they can access any file or folder with the permission level they have on the file or folder. User Data \u00b6 A user with a CyVerse login of <username> would use the WebDAV link https://data.cyverse.org/dav/iplant/home/<username>/ to access their data. Community Released Data/Project Data \u00b6 To access data from specific projects stored in iRODS at /iplant/home/shared/<project>/ , use the link https://data.cyverse.org/dav/iplant/projects/<project>/ . CyVerse Curated Data (Data with a DOI) \u00b6 To access the data curated by CyVerse in the Data Commons (that is, datasets with DOIs), use the following link: https://data.cyverse.org/dav-anon/iplant/commons/cyverse_curated/ . Common Ways to Access the WebDAV Service \u00b6 Via Web Browser Since WebDAV is an extension of HTTP, any web browser can be used to browse and download data through the service, using the links provided above. Via File Manager Most common operating systems come with a file manager application that can interface with a WebDAV service and can mount a WebDAV folder into the file system being managed. This allows other applications running on the same computer as the file manager to access data hosted by a WebDAV service as if it were local. Accessing through OS X Finder Use these instructions to connect to the WebDAV service with OS X Finder. Open Finder. From the menu bar, select Go, then Connect to Server (or use the keyboard shortcut command+K ). Enter the URL for the folder to access. Provide your CyVerse username and password, if prompted. Accessing through Windows File Explorer Use these instructions to connect to the WebDAV service with Windows File Explorer. Open the File Explorer. Right-click on This PC. Select Map Network Drive. Select Choose a custom network location and click Next. Enter the URL for the folder to access. Provide your CyVerse username and password, if prompted. Accessing through Gnome Files Use these instructions to open the WebDAV service from the Gnome desktop using Files. Open Files. Select Other Locations in the Places sidebar. In the Connect to Server footer, enter the URL for the desired folder to access. Note: Files identifies TLS encrypted WebDAV URLs with the scheme davs. This means the base for the CyVerse URLs is davs://data.cyverse.org/ instead of https://data.cyverse.org/ . (e.g., davs://data.cyverse.org/dav/iplant/home/<username>/ ) Click the neighboring Connect button. Provide your CyVerse username and password, if prompted. Accessing through Linux Terminal This requires root or at least sudo access. Use these instructions to mount a WebDAV folder into the file system from a Linux terminal. Ensure that davfs2 is installed, e.g., for Ubuntu, sudo apt install davfs2 . Create a directory where you to want to mount the data, e.g., mkdir /tmp/data. Mount the data as root, i.e., sudo mount -o gid=<you>,uid=<you> -t davfs <link> /tmp/data , where <you> is your username on the Linux machine and <link> is the URL to the WebDAV folder you want to mount. Provide your CyVerse username and password, if prompted. Summary \u00b6 This guide introduces the basic data management tools you need to manage the lifecycle of data in CyVerse. You can explore many more features that are detailed in the full Data Store Manual .","title":"HTTP Access with WebDAV"},{"location":"ds/webdav/#http-access-with-webdav","text":"WebDAV is an extension to the HTTP protocol that allows users to remotely edit and manage files. CyVerse has added support for WebDAV to the Data Store. This means users can access their home and public folders in the CyVerse Data Store from their local computers using web browsers and other WebDAV-enabled applications such as common operating system file managers. With WebDAV, users can copy files between their local computer and the Data Store as easily as if they were copying them between two folders on their computer.","title":"HTTP Access with WebDAV"},{"location":"ds/webdav/#limitations","text":"WebDAV works best for small files or small collections of files. There is no hard size limit for files, but we do not recommended using WebDAV with files over 1 GiB in size (however, 10 GiB files have been downloaded from the CyVerse WebDAV service using a web browser with decent performance). The iCommands still outperform WebDAV. For better ways to download large files or large sets of files, please see the pages for iCommands or Cyberduck .","title":"Limitations"},{"location":"ds/webdav/#accessing-cyverse-data-via-webdav-services","text":"There are two access points to CyVerse WebDAV services: one for anonymous, read-only access and one for authenticated access. These services can be accessed directly in a web browser, or with command line tools. The simplest way to access WebDAV in a browser is to go to https://data.cyverse.org/ . This will bring up a menu for the options described below. WebDAV provides anonymous, read-only access through URLs rooted at https://data.cyverse.org/dav-anon/ . All data that can be seen by the anonymous user can be accessed anonymously through this service, excluding the immediate contents of /iplant/home and the immediate contents of /iplant/home/<username> , where <username> is any CyVerse login name. WebDAV also provides authenticated access through URLs rooted at https://data.cyverse.org/dav/ . Once a user has authenticated with their CyVerse credentials, they can access any file or folder with the permission level they have on the file or folder.","title":"Accessing CyVerse Data via WebDAV Services"},{"location":"ds/webdav/#user-data","text":"A user with a CyVerse login of <username> would use the WebDAV link https://data.cyverse.org/dav/iplant/home/<username>/ to access their data.","title":"User Data"},{"location":"ds/webdav/#community-released-dataproject-data","text":"To access data from specific projects stored in iRODS at /iplant/home/shared/<project>/ , use the link https://data.cyverse.org/dav/iplant/projects/<project>/ .","title":"Community Released Data/Project Data"},{"location":"ds/webdav/#cyverse-curated-data-data-with-a-doi","text":"To access the data curated by CyVerse in the Data Commons (that is, datasets with DOIs), use the following link: https://data.cyverse.org/dav-anon/iplant/commons/cyverse_curated/ .","title":"CyVerse Curated Data (Data with a DOI)"},{"location":"ds/webdav/#common-ways-to-access-the-webdav-service","text":"Via Web Browser Since WebDAV is an extension of HTTP, any web browser can be used to browse and download data through the service, using the links provided above. Via File Manager Most common operating systems come with a file manager application that can interface with a WebDAV service and can mount a WebDAV folder into the file system being managed. This allows other applications running on the same computer as the file manager to access data hosted by a WebDAV service as if it were local. Accessing through OS X Finder Use these instructions to connect to the WebDAV service with OS X Finder. Open Finder. From the menu bar, select Go, then Connect to Server (or use the keyboard shortcut command+K ). Enter the URL for the folder to access. Provide your CyVerse username and password, if prompted. Accessing through Windows File Explorer Use these instructions to connect to the WebDAV service with Windows File Explorer. Open the File Explorer. Right-click on This PC. Select Map Network Drive. Select Choose a custom network location and click Next. Enter the URL for the folder to access. Provide your CyVerse username and password, if prompted. Accessing through Gnome Files Use these instructions to open the WebDAV service from the Gnome desktop using Files. Open Files. Select Other Locations in the Places sidebar. In the Connect to Server footer, enter the URL for the desired folder to access. Note: Files identifies TLS encrypted WebDAV URLs with the scheme davs. This means the base for the CyVerse URLs is davs://data.cyverse.org/ instead of https://data.cyverse.org/ . (e.g., davs://data.cyverse.org/dav/iplant/home/<username>/ ) Click the neighboring Connect button. Provide your CyVerse username and password, if prompted. Accessing through Linux Terminal This requires root or at least sudo access. Use these instructions to mount a WebDAV folder into the file system from a Linux terminal. Ensure that davfs2 is installed, e.g., for Ubuntu, sudo apt install davfs2 . Create a directory where you to want to mount the data, e.g., mkdir /tmp/data. Mount the data as root, i.e., sudo mount -o gid=<you>,uid=<you> -t davfs <link> /tmp/data , where <you> is your username on the Linux machine and <link> is the URL to the WebDAV folder you want to mount. Provide your CyVerse username and password, if prompted.","title":"Common Ways to Access the WebDAV Service"},{"location":"ds/webdav/#summary","text":"This guide introduces the basic data management tools you need to manage the lifecycle of data in CyVerse. You can explore many more features that are detailed in the full Data Store Manual .","title":"Summary"},{"location":"ds/move_data/","text":"Moving Data \u00b6 There are several ways to move data between the CyVerse Data Store and other computers, whether your local machine or a remote one. These methods vary in speed, flexibility, and technical knowledge necessary to use them. You may find that different methods suit your needs for different projects at different times. Method Access Point Upload/Download Installation/Setup Required Account Required Max File Size Discovery Environment Web Both No Yes 2GB/file upload, no limit import Data Commons Web Download No No 2GB/file Cyberduck Desktop App Both Yes Yes, or public data only > 10GB iCommands Command line Both Yes Yes, or public data only > 10GB The Moving Data section covers each of the four methods of moving data to the Data Store: Using the Discovery Environment web interface (visit the Distributing Data quickstart for a rapid introduction to distributing data) Using the CyberDuck desktop application Through the Command Line and iCommands Through an HTTPS connection using WebDAV Can also be used to create links for external download","title":"Moving Data"},{"location":"ds/move_data/#moving-data","text":"There are several ways to move data between the CyVerse Data Store and other computers, whether your local machine or a remote one. These methods vary in speed, flexibility, and technical knowledge necessary to use them. You may find that different methods suit your needs for different projects at different times. Method Access Point Upload/Download Installation/Setup Required Account Required Max File Size Discovery Environment Web Both No Yes 2GB/file upload, no limit import Data Commons Web Download No No 2GB/file Cyberduck Desktop App Both Yes Yes, or public data only > 10GB iCommands Command line Both Yes Yes, or public data only > 10GB The Moving Data section covers each of the four methods of moving data to the Data Store: Using the Discovery Environment web interface (visit the Distributing Data quickstart for a rapid introduction to distributing data) Using the CyberDuck desktop application Through the Command Line and iCommands Through an HTTPS connection using WebDAV Can also be used to create links for external download","title":"Moving Data"},{"location":"tutorials/","text":"Science Tutorials with CyVerse \u00b6 Bioinformatics Tutorials Using CyVerse \u00b6 Tutorial Date Notes RNASeq using VICE Dec 06, 2019 Perform RNAseq differential expression analysis using Read Mapping and Transcript Assembly (RMTA) and Rstudio-DESEq2 apps Assemble a Genome Using SOAPdenovo Dec 19, 2019 Commonly used procedure for de novo whole genome assembly of Illumina reads using the DE: Assemble reads, Assess assembly Cluster Orthologs and Paralogs and Assemble Custom Gene Sets Dec 11, 2019 Input entire protein-encoding gene or transcript repertoires from genomes of interest, and cluster homologs (orthologs and paralogs), then query clusters to assemble gene sets based on presence/absence and copy number. RNA-Seq with Kallisto and Sleuth Nov 04, 2019 Kallisto is a quick, highly-efficient software for quantifying transcript abundances in an RNA-Seq experiment. Sleuth is designed to analyze and visualize the Kallisto results in R. Kallisto-0.42.3-INDEX-QUANT-PE Oct 25, 2019 Kallisto is a program for quantifying abundances of transcripts from RNA-Seq data, or more generally of target sequences using high-throughput sequencing reads. It is based on the novel idea of pseudoalignment for rapidly determining the compatibility of reads with targets, without the need for alignment. Genome Annotation with MAKER Oct 09, 2019 This tutorial is a step-by-step guide for using SciApps to perform MAKER based annotation Evaluate and Pre-Process Sequencing Reads Jan 05, 2018 Clean and filter Illumina reads using DE apps. Taxonomic Name Resolution Service (TNRS) Dec 05, 2017 Become familiar with TNRS to identify, correct, and update scientific names of plants. Submit High-throughput Sequencing Reads to NCBI Sequence Read Archive (SRA) Dec 04, 2017 The SRA is a canonical repository for sequencing data generated by high-throughput instruments. The CyVerse submission pipeline allows you to directly submit your data into an SRA-linked BioProject. Evaluate High-throughput Sequencing Reads with FastQC Aug 01, 2017 FastQC is a popular tool for evaluating the quality of high-throughput sequencing reads such as from Illumina and PacBio. HTSeqQC Aug 01, 2017 An automated quality control analysis tool for a single and paired-end high-throughput sequencing data (HTS) generated from Illumina sequencing platforms Import data from NCBI SRA using the Discovery Environment Apr 04, 2017 The NCBI Sequence Read Archive (SRA) is a repository for high-throughput sequencing reads. These are valuable data for novel analysis and reuse. You can directly import data from SRA into your Data Store using a Discovery Environment app. Discover Variants Using SAM Tools Oct 11, 2016 Detect and call variants from sequence reads using Bowtie and SAM Tools. Filter, Trim, and Process High-throughput Sequencing Reads with Trimmomatic Sep 15, 2016 Trimmomatic is a popular application for filtering and trimming high- throughput sequencing reads. Several functions can remove populations of low quality reads, remove sequencing adaptors, and trim low-quality regions of individual reads. Characterizing Differential Expression With RNA-Seq (Without Reference Genome) Jul 21, 2015 Identify changes in gene expression levels between at least two sequenced transcriptome samples (18 separate tutorials) BLAST a Transcriptome May 11, 2016 Reduce number of transcripts and level of redundancy in an assembled transcriptome, and identify coding sequences that can be submitted to BLASTP searches. QIIME-1.9.1 for the DE Apr 12, 2016 QIIME is an open-source bioinformatics pipeline for performing microbiome analysis from raw DNA sequencing data. mini SOAPdenovo Jan 04, 2016 Gain familiarity with a commonly used procedure for de novo whole genome assembly of Illumina reads using the DE. Genome-wide Association Study (GWAS) Using a Genotyping-by-sequencing Approach Sep 27, 2012 Learn to identify genetic variants that are associated with a trait. SciApps \u00b6 Tutorial Date Notes Association analysis with mixed models Sep 18, 2013 A genome-wide association study (or GWAS) workflow using TASSEL, EMMAX, and MLMM for mixed model analysis. Atmosphere \u00b6 Tutorial Date Notes Basic Stacks Nov 06, 2017 Use next generation sequence data produced from Reduced Representation Libraries (RRL) such as Restriction site associated (RAD) tags. fastStructure Oct 01, 2017 fastStructure is a fast algorithm for inferring population structure from large SNP genotype data. It is based on a variational Bayesian framework for posterior inference and is written in Python2.x. Installing R packages on Atmosphere Jun 23, 2016 Install R packages on Atmosphere: Launch instance, transfer files to instance, install R package, request imaging. QIIME-1.9.1 for Atmosphere Jun 12, 2017 QIIME is an open-source bioinformatics pipeline for performing microbiome analysis from raw DNA rnaQUAST 1.2.0 May 19, 2016 rnaQUAST is a tool for evaluating RNA-Seq assemblies using reference genome and gene data database. In addition, rnaQUAST is also capable of estimating gene database coverage by raw reads and de novo quality assessment using third-party software (STAR, TopHat, GMAP etc.). QUAST 4.0 May 19, 2016 QUAST is a tool for evaluating genome assemblies by computing various metrics. rnaQUAST 1.1.0 May 11, 2016 rnaQUAST is a tool for evaluating RNA-Seq assemblies using reference genome and gene data database. In addition, rnaQUAST is also capable of estimating gene database coverage by raw reads and de novo quality assessment using third-party software (STAR, TopHat, GMAP etc.). Evolinc May 03, 2016 Evolinc is a two-part pipeline to identify lincRNAs from an assembled transcriptome file (.gtf output from cufflinks) and then determine the extent to which those lincRNAs are conserved in the genome and transcriptome of other species. FaST-LMM.Py v2.02 Apr 19, 2016 Introduce new users to the FaST-LMM software for GWAS analysis. KOBAS 2.0-09052014 Apr 19, 2016 Learn how to annotate and identify using KOBAS 2.0. Validate Workflow v0.9 Apr 19, 2016 Learn to navigate the Validate Workflow. BATools 0.0.1 Apr 10, 2016 Introduce new users to BATools and the BATools Wrapper Script. Geoinformatics Tutorials Using CyVerse \u00b6 Tutorial Date Notes NEON AOP Workshop Nov 11, 2021 Second virtual NEON AOP Workshop in collaboration with USDA-ARS and UArizona RISE Conference NEON AOP Workshop Nov 05-07, 2020 First virtual NEON AOP Workshop in collaboration with USDA-ARS and UArizona RISE Conference NEON-CyVerse Workshop Jan 09, 2019 CyVerse Workshop taught at Battelle Inc. NEON Headquarters, Boulder CO NEON Data Science Institute July 12, 2018 NEON summer workshop taught at Battelle Inc. NEON Headquarters, Boulder CO Astronomy Tutorials Using CyVerse \u00b6 Workshop Date Description Cloud Computing Busy Week Feb 2-7, 2020 a five-day busy week was conducted at the University of Arizona in order for PIRE members to work on large-scale synthetic data generation for the Event Horizon Telescope (EHT) project AstroContainers Workshop May 7-8, 2018 designed for astronomers and astrophysicists at Steward, LSST, NOAO, and LPL MiniHackathon PIRE Apr 11, 2018 Docker and Jupyter for Reproducible Astronomy","title":"Science Tutorials with CyVerse"},{"location":"tutorials/#science-tutorials-with-cyverse","text":"","title":"Science Tutorials with CyVerse"},{"location":"tutorials/#bioinformatics-tutorials-using-cyverse","text":"Tutorial Date Notes RNASeq using VICE Dec 06, 2019 Perform RNAseq differential expression analysis using Read Mapping and Transcript Assembly (RMTA) and Rstudio-DESEq2 apps Assemble a Genome Using SOAPdenovo Dec 19, 2019 Commonly used procedure for de novo whole genome assembly of Illumina reads using the DE: Assemble reads, Assess assembly Cluster Orthologs and Paralogs and Assemble Custom Gene Sets Dec 11, 2019 Input entire protein-encoding gene or transcript repertoires from genomes of interest, and cluster homologs (orthologs and paralogs), then query clusters to assemble gene sets based on presence/absence and copy number. RNA-Seq with Kallisto and Sleuth Nov 04, 2019 Kallisto is a quick, highly-efficient software for quantifying transcript abundances in an RNA-Seq experiment. Sleuth is designed to analyze and visualize the Kallisto results in R. Kallisto-0.42.3-INDEX-QUANT-PE Oct 25, 2019 Kallisto is a program for quantifying abundances of transcripts from RNA-Seq data, or more generally of target sequences using high-throughput sequencing reads. It is based on the novel idea of pseudoalignment for rapidly determining the compatibility of reads with targets, without the need for alignment. Genome Annotation with MAKER Oct 09, 2019 This tutorial is a step-by-step guide for using SciApps to perform MAKER based annotation Evaluate and Pre-Process Sequencing Reads Jan 05, 2018 Clean and filter Illumina reads using DE apps. Taxonomic Name Resolution Service (TNRS) Dec 05, 2017 Become familiar with TNRS to identify, correct, and update scientific names of plants. Submit High-throughput Sequencing Reads to NCBI Sequence Read Archive (SRA) Dec 04, 2017 The SRA is a canonical repository for sequencing data generated by high-throughput instruments. The CyVerse submission pipeline allows you to directly submit your data into an SRA-linked BioProject. Evaluate High-throughput Sequencing Reads with FastQC Aug 01, 2017 FastQC is a popular tool for evaluating the quality of high-throughput sequencing reads such as from Illumina and PacBio. HTSeqQC Aug 01, 2017 An automated quality control analysis tool for a single and paired-end high-throughput sequencing data (HTS) generated from Illumina sequencing platforms Import data from NCBI SRA using the Discovery Environment Apr 04, 2017 The NCBI Sequence Read Archive (SRA) is a repository for high-throughput sequencing reads. These are valuable data for novel analysis and reuse. You can directly import data from SRA into your Data Store using a Discovery Environment app. Discover Variants Using SAM Tools Oct 11, 2016 Detect and call variants from sequence reads using Bowtie and SAM Tools. Filter, Trim, and Process High-throughput Sequencing Reads with Trimmomatic Sep 15, 2016 Trimmomatic is a popular application for filtering and trimming high- throughput sequencing reads. Several functions can remove populations of low quality reads, remove sequencing adaptors, and trim low-quality regions of individual reads. Characterizing Differential Expression With RNA-Seq (Without Reference Genome) Jul 21, 2015 Identify changes in gene expression levels between at least two sequenced transcriptome samples (18 separate tutorials) BLAST a Transcriptome May 11, 2016 Reduce number of transcripts and level of redundancy in an assembled transcriptome, and identify coding sequences that can be submitted to BLASTP searches. QIIME-1.9.1 for the DE Apr 12, 2016 QIIME is an open-source bioinformatics pipeline for performing microbiome analysis from raw DNA sequencing data. mini SOAPdenovo Jan 04, 2016 Gain familiarity with a commonly used procedure for de novo whole genome assembly of Illumina reads using the DE. Genome-wide Association Study (GWAS) Using a Genotyping-by-sequencing Approach Sep 27, 2012 Learn to identify genetic variants that are associated with a trait.","title":"Bioinformatics Tutorials Using CyVerse"},{"location":"tutorials/#sciapps","text":"Tutorial Date Notes Association analysis with mixed models Sep 18, 2013 A genome-wide association study (or GWAS) workflow using TASSEL, EMMAX, and MLMM for mixed model analysis.","title":"SciApps"},{"location":"tutorials/#atmosphere","text":"Tutorial Date Notes Basic Stacks Nov 06, 2017 Use next generation sequence data produced from Reduced Representation Libraries (RRL) such as Restriction site associated (RAD) tags. fastStructure Oct 01, 2017 fastStructure is a fast algorithm for inferring population structure from large SNP genotype data. It is based on a variational Bayesian framework for posterior inference and is written in Python2.x. Installing R packages on Atmosphere Jun 23, 2016 Install R packages on Atmosphere: Launch instance, transfer files to instance, install R package, request imaging. QIIME-1.9.1 for Atmosphere Jun 12, 2017 QIIME is an open-source bioinformatics pipeline for performing microbiome analysis from raw DNA rnaQUAST 1.2.0 May 19, 2016 rnaQUAST is a tool for evaluating RNA-Seq assemblies using reference genome and gene data database. In addition, rnaQUAST is also capable of estimating gene database coverage by raw reads and de novo quality assessment using third-party software (STAR, TopHat, GMAP etc.). QUAST 4.0 May 19, 2016 QUAST is a tool for evaluating genome assemblies by computing various metrics. rnaQUAST 1.1.0 May 11, 2016 rnaQUAST is a tool for evaluating RNA-Seq assemblies using reference genome and gene data database. In addition, rnaQUAST is also capable of estimating gene database coverage by raw reads and de novo quality assessment using third-party software (STAR, TopHat, GMAP etc.). Evolinc May 03, 2016 Evolinc is a two-part pipeline to identify lincRNAs from an assembled transcriptome file (.gtf output from cufflinks) and then determine the extent to which those lincRNAs are conserved in the genome and transcriptome of other species. FaST-LMM.Py v2.02 Apr 19, 2016 Introduce new users to the FaST-LMM software for GWAS analysis. KOBAS 2.0-09052014 Apr 19, 2016 Learn how to annotate and identify using KOBAS 2.0. Validate Workflow v0.9 Apr 19, 2016 Learn to navigate the Validate Workflow. BATools 0.0.1 Apr 10, 2016 Introduce new users to BATools and the BATools Wrapper Script.","title":"Atmosphere"},{"location":"tutorials/#geoinformatics-tutorials-using-cyverse","text":"Tutorial Date Notes NEON AOP Workshop Nov 11, 2021 Second virtual NEON AOP Workshop in collaboration with USDA-ARS and UArizona RISE Conference NEON AOP Workshop Nov 05-07, 2020 First virtual NEON AOP Workshop in collaboration with USDA-ARS and UArizona RISE Conference NEON-CyVerse Workshop Jan 09, 2019 CyVerse Workshop taught at Battelle Inc. NEON Headquarters, Boulder CO NEON Data Science Institute July 12, 2018 NEON summer workshop taught at Battelle Inc. NEON Headquarters, Boulder CO","title":"Geoinformatics Tutorials Using CyVerse"},{"location":"tutorials/#astronomy-tutorials-using-cyverse","text":"Workshop Date Description Cloud Computing Busy Week Feb 2-7, 2020 a five-day busy week was conducted at the University of Arizona in order for PIRE members to work on large-scale synthetic data generation for the Event Horizon Telescope (EHT) project AstroContainers Workshop May 7-8, 2018 designed for astronomers and astrophysicists at Steward, LSST, NOAO, and LPL MiniHackathon PIRE Apr 11, 2018 Docker and Jupyter for Reproducible Astronomy","title":"Astronomy Tutorials Using CyVerse"},{"location":"vice/about/","text":"Interactive Analysis in the Discovery Environment \u00b6 VICE stands for Visual Interactive Computing Environment and is a part of CyVerse's Discovery Environment (DE) . The DE supports executable applications which run as workflows on high performance or high throughput computing environments. VICE allows for interactive software to run on the Discovery Environment. There are a few common categories of interactive applications: Integrated Development Environments (IDE) RStudio: JupyterLab: Interactive Apps (e.g., Shiny, WebGL, HTML5) Virtual Desktop Environments (e.g., Ubuntu Desktops w/ Apache Guacamole, VNC, Xpra) CyVerse hosts the recipes of its featured apps on GitHub: https://github.com/cyverse-vice/ . These images are built from other official projects and are maintained by CyVerse staff. From the Home tab in the DE, there are several apps that have an Instant Launch feature which allows you to start the app with a single click. These apps launch with their default number of cores, amount of RAM, and timeout, and without input data. You can always import data using HTTPS protocols or iCommands after launch. Getting VICE Access \u00b6 Since VICE (the Visual Interactive Computing Environment) is a target for cryptocurrency miners, we require an additional verification. To get access to VICE, your CyVerse account must be associated with a valid email address from an organization, an educational institution, or a government; e.g., an email ending with .org , .edu , or .gov . We do not grant VICE access to commercial email addresses, e.g., @gmail.com , @yahoo.com , @msn.com , etc. To request VICE access, visit the User Portal and Services ; look for DE VICE and select the REQUEST ACCESS link. You will be asked for a description of your intended VICE use: please give non-technical scientific details, and if you can, link an external resource (like a workshop or lab website) and funding agency. Launching a VICE application \u00b6 Quick Launch VICE Apps CyVerse maintains featured apps from the Rocker-Project , Project Jupyter , and Visual Studio Code Quick Launch Base Images Rocker-Project Project Jupyter Visual Studio Code These containers are built from community-maintained container stacks, with a few additonal packages for use in CyVerse DE. Log into the Discovery Environment . Click the Data Icon and navigate to your /iplant/home/<your-username> folder; click the (Add Folder button) and create a folder called demo_rocker/ inside your work space. Use this Quick Launch link or click on Apps to launch the featured Rocker RStudio Latest App. You can also use the DE Search bar to search for this application in Apps. Launch the application and adjust the following: Under \"Analysis Info\", for Output Folder click Browse and navigate to and select your new /demo_rocker/ folder, or leave it as the default analyses/ folder, then click Next ; For \"Parameters\", under \"Input Folder\" click Browse and navigate to any folder you own or is shared with you, or leave it as the default (empty), then click Next ; In Advanced Settings you can modify the resources used by the container (e.g., more cores, more RAM, or disk space for larger analyses) or leave the default settings, then click Next ; Click Launch Analysis to launch your application. Your new Featured App should be available within one minute. In the navigation bar, click on the Analyses view. Your application will be listed as \"Submitted\" (this takes a minute or two; maybe more depending on both the size of the container and any additional imported data). When the Status of the launch is \"Running\", click on the running App under \"Analyses\"; a new tab will open in your browser. Please be patient Even when the application has entered 'Running' status, it may take additional time for input data to be transferred onto the resource with the new container. Accessing data from VICE apps \u00b6 VICE apps have web access, so you can import data using methods like curl or querying external databases. You can also access your Data Store home and shared directories directly from a VICE app. Your home directory is found via the path work/home/cyverse_username/ . You will also have access to any data shared with you in the Data Store via the path work/home/shared/ . You will be able to read, write, and delete data from the Data Store from a VICE app, just as you would on a local filesystem. Working with many files Read/write speeds for single files are quite fast, but can slow down when accessing many files. If you are working with many small files, it may be faster to keep your data in the Data Store in a compressed format (such as .tgz or .zip), then use cp to copy the data from ~/work/home/username/ to ~/work . Working with many small files within the VICE app's container will be faster than accessing them directly from the Data Store. Speed benchmark for moving a folder with many CSV files: moving storms_by_year/ folder: 23.5s moving storms_by_year.zip: 0.07s unzipping: 0.063s Using Git and GitHub from VICE \u00b6 The core VICE apps (RStudio, JupyterLab, and Cloud Shell) also have the GitHub command line interface installed. You can run gh auth login and follow the prompts to log in to your GitHub account, which will give you HTTPS access to push and pull from your GitHub repositories. You can read more about the GitHub CLI on their manual page . You will also need to run git config user.email \"your.email\"; git config user.name \"Your Name\" to configure Git to be able to make commits. Working with Git repositories For the time being, we recommend cloning repositories into ~/work rather than into ~/work/home/username , because the large number of files in a Git repository can make transfers to the Data Store slow. We are working on optimizing the git clone process to address this issue. Instant Launches \u00b6 From the Home tab in the DE, there are several apps that have an Instant Launch feature which allows you to start the app with a single click. These apps launch with their default number of cores, amount of RAM, and timeout, and without input data. You can always import data using HTTPS protocols or iCommands after launch. Quick Launches \u00b6 Quick launch buttons are directed URLs that allow you to share an app with pre-set configurations. After selecting an app, you will be taken to the app launcher where you can select input data sets, and then set size and time parameters. Any public app can have a quick launch URL generated for it. To use one of the Featured Launches listed below in the table, copy the badge (button link) to add to wherever you collaborate (a webpage, project notes, documentation, etc.). To create your own Saved Launch, start by launching the app you want to use. This will be a good time to Favorite the app. In the \"Review & Launch\" panel, click the \"Create Saved Launch\" button. You will be asked to name your Saved Launch and check the box when prompted if you would like it to be public. Remember which app you saved, you will find the link under Details of the app you saved.","title":"Interactive Analysis"},{"location":"vice/about/#interactive-analysis-in-the-discovery-environment","text":"VICE stands for Visual Interactive Computing Environment and is a part of CyVerse's Discovery Environment (DE) . The DE supports executable applications which run as workflows on high performance or high throughput computing environments. VICE allows for interactive software to run on the Discovery Environment. There are a few common categories of interactive applications: Integrated Development Environments (IDE) RStudio: JupyterLab: Interactive Apps (e.g., Shiny, WebGL, HTML5) Virtual Desktop Environments (e.g., Ubuntu Desktops w/ Apache Guacamole, VNC, Xpra) CyVerse hosts the recipes of its featured apps on GitHub: https://github.com/cyverse-vice/ . These images are built from other official projects and are maintained by CyVerse staff. From the Home tab in the DE, there are several apps that have an Instant Launch feature which allows you to start the app with a single click. These apps launch with their default number of cores, amount of RAM, and timeout, and without input data. You can always import data using HTTPS protocols or iCommands after launch.","title":"Interactive Analysis in the Discovery Environment"},{"location":"vice/about/#getting-vice-access","text":"Since VICE (the Visual Interactive Computing Environment) is a target for cryptocurrency miners, we require an additional verification. To get access to VICE, your CyVerse account must be associated with a valid email address from an organization, an educational institution, or a government; e.g., an email ending with .org , .edu , or .gov . We do not grant VICE access to commercial email addresses, e.g., @gmail.com , @yahoo.com , @msn.com , etc. To request VICE access, visit the User Portal and Services ; look for DE VICE and select the REQUEST ACCESS link. You will be asked for a description of your intended VICE use: please give non-technical scientific details, and if you can, link an external resource (like a workshop or lab website) and funding agency.","title":"Getting VICE Access"},{"location":"vice/about/#launching-a-vice-application","text":"Quick Launch VICE Apps CyVerse maintains featured apps from the Rocker-Project , Project Jupyter , and Visual Studio Code Quick Launch Base Images Rocker-Project Project Jupyter Visual Studio Code These containers are built from community-maintained container stacks, with a few additonal packages for use in CyVerse DE. Log into the Discovery Environment . Click the Data Icon and navigate to your /iplant/home/<your-username> folder; click the (Add Folder button) and create a folder called demo_rocker/ inside your work space. Use this Quick Launch link or click on Apps to launch the featured Rocker RStudio Latest App. You can also use the DE Search bar to search for this application in Apps. Launch the application and adjust the following: Under \"Analysis Info\", for Output Folder click Browse and navigate to and select your new /demo_rocker/ folder, or leave it as the default analyses/ folder, then click Next ; For \"Parameters\", under \"Input Folder\" click Browse and navigate to any folder you own or is shared with you, or leave it as the default (empty), then click Next ; In Advanced Settings you can modify the resources used by the container (e.g., more cores, more RAM, or disk space for larger analyses) or leave the default settings, then click Next ; Click Launch Analysis to launch your application. Your new Featured App should be available within one minute. In the navigation bar, click on the Analyses view. Your application will be listed as \"Submitted\" (this takes a minute or two; maybe more depending on both the size of the container and any additional imported data). When the Status of the launch is \"Running\", click on the running App under \"Analyses\"; a new tab will open in your browser. Please be patient Even when the application has entered 'Running' status, it may take additional time for input data to be transferred onto the resource with the new container.","title":"Launching a VICE application"},{"location":"vice/about/#accessing-data-from-vice-apps","text":"VICE apps have web access, so you can import data using methods like curl or querying external databases. You can also access your Data Store home and shared directories directly from a VICE app. Your home directory is found via the path work/home/cyverse_username/ . You will also have access to any data shared with you in the Data Store via the path work/home/shared/ . You will be able to read, write, and delete data from the Data Store from a VICE app, just as you would on a local filesystem. Working with many files Read/write speeds for single files are quite fast, but can slow down when accessing many files. If you are working with many small files, it may be faster to keep your data in the Data Store in a compressed format (such as .tgz or .zip), then use cp to copy the data from ~/work/home/username/ to ~/work . Working with many small files within the VICE app's container will be faster than accessing them directly from the Data Store. Speed benchmark for moving a folder with many CSV files: moving storms_by_year/ folder: 23.5s moving storms_by_year.zip: 0.07s unzipping: 0.063s","title":"Accessing data from VICE apps"},{"location":"vice/about/#using-git-and-github-from-vice","text":"The core VICE apps (RStudio, JupyterLab, and Cloud Shell) also have the GitHub command line interface installed. You can run gh auth login and follow the prompts to log in to your GitHub account, which will give you HTTPS access to push and pull from your GitHub repositories. You can read more about the GitHub CLI on their manual page . You will also need to run git config user.email \"your.email\"; git config user.name \"Your Name\" to configure Git to be able to make commits. Working with Git repositories For the time being, we recommend cloning repositories into ~/work rather than into ~/work/home/username , because the large number of files in a Git repository can make transfers to the Data Store slow. We are working on optimizing the git clone process to address this issue.","title":"Using Git and GitHub from VICE"},{"location":"vice/about/#instant-launches","text":"From the Home tab in the DE, there are several apps that have an Instant Launch feature which allows you to start the app with a single click. These apps launch with their default number of cores, amount of RAM, and timeout, and without input data. You can always import data using HTTPS protocols or iCommands after launch.","title":"Instant Launches"},{"location":"vice/about/#quick-launches","text":"Quick launch buttons are directed URLs that allow you to share an app with pre-set configurations. After selecting an app, you will be taken to the app launcher where you can select input data sets, and then set size and time parameters. Any public app can have a quick launch URL generated for it. To use one of the Featured Launches listed below in the table, copy the badge (button link) to add to wherever you collaborate (a webpage, project notes, documentation, etc.). To create your own Saved Launch, start by launching the app you want to use. This will be a good time to Favorite the app. In the \"Review & Launch\" panel, click the \"Create Saved Launch\" button. You will be asked to name your Saved Launch and check the box when prompted if you would like it to be public. Remember which app you saved, you will find the link under Details of the app you saved.","title":"Quick Launches"},{"location":"vice/extend_apps/","text":"Extending VICE Tools and Apps \u00b6 There are several options to extend VICE for your specific use(s): Options Hypothetical use case Copy an Existing App You want to create a Quick Launch Button which has a different set of input data, specific to a course you're teaching Modify an Existing Tool You need to add new packages or libraries to an existing Featured App and Tool that requires building a new Docker Container Create a New Tool & App There are no existing App types which fit your needs. You need to develop your own Docker container and integrate it from start to finish Depending on your specific needs, it may be easiest to copy an existing app or modify an existing tool. If you cannot find any existing Apps which suit your use case, do not hesitate to contact us via Intercom to ask about the availability of your favorite development environment. Definitions Tool - the Discovery Environment refers to Docker container templates as \"Tools\". The tool builder allows you to set the environment, UID, entrypoint, working directory, and computational requirements of your Docker container. Apps - Applications, or \"Apps\", are the user interface that you build in the Discovery Environment to interact with our Tools. Apps are designed using a template builder. Types of Tools include: executable , HPC , OSG (OpenScienceGrid), or interactive . Apps may require input data, parameters, settings, and flags which the user selects each time they are run. executable , HPC , and OSG apps run non-interactively until they complete. For interactive VICE apps, the App template may only include a set of input data files and folders, or nothing at all. VICE Apps use Kubernetes to orchestrate their launch. Adding interactive Tools and Apps is different from adding executable Tools. VICE applications like Jupyter and RStudio run on open ports, enabling their User Interface (UI) in the browser. Copy an Existing App \u00b6 Navigating the Discovery Environment : Apps - Applications (including VICE interactive applications) Under \"Apps\" you will see \"Tools\" and \"Instant Launches\" -- for this section, we are interested in \"Tools\". Analyses - Status and history of analysis jobs Analyses will be where you can test your new App to ensure it is functioning properly. If necessary, log into the Discovery Environment Click the Apps icon in the left side of the navigation view. Or use the search bar to search existing public Apps for what you're interested in. When you've found the app you want, click on the three vertical dots on the right side of the selection field and select \"Copy App\". You will be taken to the App editor, where you can now give the Copy of App Name a new name. You can also change the App's Description and the Tool used by the App. Modify the Parameters as you see fit. Save your new app. The app will be private, and is available under your \"Apps Under Development\" tab in Apps Modify an Existing Tool \u00b6 Copying an App does not change the underlying Tool (Docker image). You may need to install some new system packages or software libraries that are too complex or take too long to compile on any of the public featured apps. If you find that one of the existing public Apps, e.g. our Featured Apps, is useful but may be missing some key packages, you can take the next step of building a new container from our featured images. Why use our Featured Images? Some of the managed features that CyVerse provides for you are not available on publicly maintained Docker images of popular data science development environments. For example, CyVerse adds a reverse proxy to allow RStudio to work behind our authenticated systems, and we install iRODS iCommands and other popular package managers and editors on all of our featured images. By building a new container from our featured image set, you are assured that your new Docker image will work immediately in the Discovery Environment. It is strongly recommended if you're using common IDEs like RStudio, Jupyter Lab, VS Code, Remote Desktops, or web-based applications like Shiny, Flask, or Streamlit, that you use one of our featured Docker images, or at least view our public Dockerfiles on GitHub , to ensure your new Container is compatible with the Discovery Environment. Select a Featured Base Image \u00b6 Each of these featured Apps have a public GitHub repository where their Dockerfile is available. The containers are hosted on CyVerse Harbor public/private Docker container registry. Name Dockerfile JupyterLab Datascience RStudio Verse CloudShell Xpra VS Code Write your new Dockerfile \u00b6 Create your own Dockerfile. We suggest using GitHub, and setting up a GitHub Action for building your container and pushing it to a public Docker Registry. If you select a Featured App image, it will be pulled from our public Harbor Registry , which uses a different naming convention than Docker Hub containers. For example, for the Rocker Project's featured RStudio Verse Latest image, the FROM statement would be: FROM harbor.cyverse.org/vice/rstudio/verse:latest You can then follow with your own ENV and RUN commands to do your own package installations. Build your container as you normally would: $ docker build -t <dockerhub-username>/rstudio/verse:custom-latest . Selecting tag names By default Docker gives the latest tag to containers without a : and trailing tagname. You can modify your tagname in any way you see fit, but names like dev and latest should only be used for development or activities that do not require rigorous reproducability. It is a good practice to use versioned tag names when preparing for peer-reviewed scientific publication. Push your new image to a public container registry \u00b6 After you have built your new image, you need to push it to a public Docker registry. We recommend Dockerhub or quay.io . The Discovery Environment can pull any public Docker image from any public/private registry. We currently do not allow private Docker images to be pulled, but do contact us about special private container hosting in our Harbor registry if you have sensitive data or software needs. Alternatively, you can provide us the Dockerfile of your requested image and we will build the Docker image for you. If there is no Dockerfile for the tool that you are interested in, contact us via Intercom and tell us what tool you are interesting in having us make as a VICE app. Create a new Tool \u00b6 Add Tool \u00b6 If necessary, log into the Discovery Environment . Click the Apps and click on the \"Manage Tools\" wrench icon. You'll see a list of all of the tools in the DE. Click on \"More Actions\" and select \"Add Tool\". Add Tool Tool name is the name of the tool. This will appear in the DE's tool listing dialog. This is mandatory field. description is a brief description of the tool. This will appear in the DE's tool listing dialog. version is the version of the tool. This will appear in the DE's tool listing dialog. This is mandatory field. Type is the type of tool. For VICE apps, choose \"interactive\"; for command line applications, choose \"executable\". Container Image Image name is the name of the image and its public registry. This is mandatory field. Tag is the image tag. If you don't specify the tag, the DE will look for the latest tag which is the default tag. Docker Hub URL is the URL of the image on Dockerhub. Entrypoint is the Entrypoint for your tool. Entrypoint should be present in the Docker image, and if not, you should specify it here. Working Directory is the working directory of the tool and must be filled in with the value you gathered above, e.g., /home/jovyan/work . UID is a number and must be filled in with the value you gathered from above. Typically root is 0 and default users are 1000 . Container Ports Ports select the external port address that your graphic interface needs. Restrictions Max CPU Cores is the number of cores for your tool, e.g., 16 Memory Limit is the memory for your tool, e.g., 64 GB Min Disk Space is the minimum disk space for your tool, e.g., 200 GB Required settings \u00b6 Set the WORKDIR \u00b6 Executable apps to not require a working directory. The container needs to have a set working directory (for interactive apps), typically this is the home folder, e.g., /home/jovyan or /home/rstudio . Set the WORKDIR in the Dockerfile; if there is no set WORKDIR , you can set it in the Tool Builder. Your Data in Your Container We recommend that you set the working directory of your tool to the username home path in a new folder called work , e.g., /home/jovyan/work or /home/rstudio/work . This is because the Discovery Environment's interactive apps use a Kubernetes container storage interface (CSI) driver that connects the CyVerse Data Store to your working directory in the running container. This new mount can clobber any pre-existing files in the the container's WORKDIR . Set the ENTRYPOINT \u00b6 The container must have an ENTRYPOINT set in the Dockerfile, otherwise you must set it in the Tool itself. All commonly needed dependencies are installed in the container image - you will not have root privileges later. The default user set. Disable any additional authentication (CyVerse provides CAS authentication and authorization). URLs will work sanely behind a reverse proxy. If they don't, you may need to add nginx to the container. Set the PORT \u00b6 Interactive Apps rely on open ports to send display information to the browser. Ensure the listen port for the web UI has a sane default and is set in the Dockerfile, e.g. PORT 8888 . You must set the port in the tool to the external port that the container is listening. Understanding ports in Docker containers For interactive containers like RStudio and JupyterLab, a conventional docker run execution will have the port set as -p 8888:8888 where the port number on the left side of the : is the external port, and on the right the internal port. For VICE apps you need only be concerned about the external port number. Using a reverse proxy The Discovery Environment has its own authentication system, which requires us to use a reverse proxy for some containers. Our RStudio Server uses nginx to enable reverse proxy and thus we have changed the external port to 80 instead of the Rocker-Project default 8787 port number. Managing ports in your new tool Featured VICE apps have default port options based on the app: JupyterLab apps use port 8888 , RStudio apps use port 80 , and Shiny apps use port 3838 . It is strongly recommended you do not set the bind to host as true for your added ports when creating a new App. Creating a VICE app for your new tool \u00b6 After your tool template has been saved, you can create an App for connecting your tool to the Discovery Environment. You can copy an existing app and select your tool if you like an existing App's layout. Alternatively, you can create a new app from a blank template. Input data For VICE apps, be sure to check the box \"Do not pass this argument to the command line\" for each option you add (for VICE, this is usually just input files and folders.","title":"Extend VICE apps"},{"location":"vice/extend_apps/#extending-vice-tools-and-apps","text":"There are several options to extend VICE for your specific use(s): Options Hypothetical use case Copy an Existing App You want to create a Quick Launch Button which has a different set of input data, specific to a course you're teaching Modify an Existing Tool You need to add new packages or libraries to an existing Featured App and Tool that requires building a new Docker Container Create a New Tool & App There are no existing App types which fit your needs. You need to develop your own Docker container and integrate it from start to finish Depending on your specific needs, it may be easiest to copy an existing app or modify an existing tool. If you cannot find any existing Apps which suit your use case, do not hesitate to contact us via Intercom to ask about the availability of your favorite development environment. Definitions Tool - the Discovery Environment refers to Docker container templates as \"Tools\". The tool builder allows you to set the environment, UID, entrypoint, working directory, and computational requirements of your Docker container. Apps - Applications, or \"Apps\", are the user interface that you build in the Discovery Environment to interact with our Tools. Apps are designed using a template builder. Types of Tools include: executable , HPC , OSG (OpenScienceGrid), or interactive . Apps may require input data, parameters, settings, and flags which the user selects each time they are run. executable , HPC , and OSG apps run non-interactively until they complete. For interactive VICE apps, the App template may only include a set of input data files and folders, or nothing at all. VICE Apps use Kubernetes to orchestrate their launch. Adding interactive Tools and Apps is different from adding executable Tools. VICE applications like Jupyter and RStudio run on open ports, enabling their User Interface (UI) in the browser.","title":"Extending VICE Tools and Apps"},{"location":"vice/extend_apps/#copy-an-existing-app","text":"Navigating the Discovery Environment : Apps - Applications (including VICE interactive applications) Under \"Apps\" you will see \"Tools\" and \"Instant Launches\" -- for this section, we are interested in \"Tools\". Analyses - Status and history of analysis jobs Analyses will be where you can test your new App to ensure it is functioning properly. If necessary, log into the Discovery Environment Click the Apps icon in the left side of the navigation view. Or use the search bar to search existing public Apps for what you're interested in. When you've found the app you want, click on the three vertical dots on the right side of the selection field and select \"Copy App\". You will be taken to the App editor, where you can now give the Copy of App Name a new name. You can also change the App's Description and the Tool used by the App. Modify the Parameters as you see fit. Save your new app. The app will be private, and is available under your \"Apps Under Development\" tab in Apps","title":"Copy an Existing App"},{"location":"vice/extend_apps/#modify-an-existing-tool","text":"Copying an App does not change the underlying Tool (Docker image). You may need to install some new system packages or software libraries that are too complex or take too long to compile on any of the public featured apps. If you find that one of the existing public Apps, e.g. our Featured Apps, is useful but may be missing some key packages, you can take the next step of building a new container from our featured images. Why use our Featured Images? Some of the managed features that CyVerse provides for you are not available on publicly maintained Docker images of popular data science development environments. For example, CyVerse adds a reverse proxy to allow RStudio to work behind our authenticated systems, and we install iRODS iCommands and other popular package managers and editors on all of our featured images. By building a new container from our featured image set, you are assured that your new Docker image will work immediately in the Discovery Environment. It is strongly recommended if you're using common IDEs like RStudio, Jupyter Lab, VS Code, Remote Desktops, or web-based applications like Shiny, Flask, or Streamlit, that you use one of our featured Docker images, or at least view our public Dockerfiles on GitHub , to ensure your new Container is compatible with the Discovery Environment.","title":"Modify an Existing Tool"},{"location":"vice/extend_apps/#select-a-featured-base-image","text":"Each of these featured Apps have a public GitHub repository where their Dockerfile is available. The containers are hosted on CyVerse Harbor public/private Docker container registry. Name Dockerfile JupyterLab Datascience RStudio Verse CloudShell Xpra VS Code","title":"Select a Featured Base Image"},{"location":"vice/extend_apps/#write-your-new-dockerfile","text":"Create your own Dockerfile. We suggest using GitHub, and setting up a GitHub Action for building your container and pushing it to a public Docker Registry. If you select a Featured App image, it will be pulled from our public Harbor Registry , which uses a different naming convention than Docker Hub containers. For example, for the Rocker Project's featured RStudio Verse Latest image, the FROM statement would be: FROM harbor.cyverse.org/vice/rstudio/verse:latest You can then follow with your own ENV and RUN commands to do your own package installations. Build your container as you normally would: $ docker build -t <dockerhub-username>/rstudio/verse:custom-latest . Selecting tag names By default Docker gives the latest tag to containers without a : and trailing tagname. You can modify your tagname in any way you see fit, but names like dev and latest should only be used for development or activities that do not require rigorous reproducability. It is a good practice to use versioned tag names when preparing for peer-reviewed scientific publication.","title":"Write your new Dockerfile"},{"location":"vice/extend_apps/#push-your-new-image-to-a-public-container-registry","text":"After you have built your new image, you need to push it to a public Docker registry. We recommend Dockerhub or quay.io . The Discovery Environment can pull any public Docker image from any public/private registry. We currently do not allow private Docker images to be pulled, but do contact us about special private container hosting in our Harbor registry if you have sensitive data or software needs. Alternatively, you can provide us the Dockerfile of your requested image and we will build the Docker image for you. If there is no Dockerfile for the tool that you are interested in, contact us via Intercom and tell us what tool you are interesting in having us make as a VICE app.","title":"Push your new image to a public container registry"},{"location":"vice/extend_apps/#create-a-new-tool","text":"","title":"Create a new Tool"},{"location":"vice/extend_apps/#add-tool","text":"If necessary, log into the Discovery Environment . Click the Apps and click on the \"Manage Tools\" wrench icon. You'll see a list of all of the tools in the DE. Click on \"More Actions\" and select \"Add Tool\". Add Tool Tool name is the name of the tool. This will appear in the DE's tool listing dialog. This is mandatory field. description is a brief description of the tool. This will appear in the DE's tool listing dialog. version is the version of the tool. This will appear in the DE's tool listing dialog. This is mandatory field. Type is the type of tool. For VICE apps, choose \"interactive\"; for command line applications, choose \"executable\". Container Image Image name is the name of the image and its public registry. This is mandatory field. Tag is the image tag. If you don't specify the tag, the DE will look for the latest tag which is the default tag. Docker Hub URL is the URL of the image on Dockerhub. Entrypoint is the Entrypoint for your tool. Entrypoint should be present in the Docker image, and if not, you should specify it here. Working Directory is the working directory of the tool and must be filled in with the value you gathered above, e.g., /home/jovyan/work . UID is a number and must be filled in with the value you gathered from above. Typically root is 0 and default users are 1000 . Container Ports Ports select the external port address that your graphic interface needs. Restrictions Max CPU Cores is the number of cores for your tool, e.g., 16 Memory Limit is the memory for your tool, e.g., 64 GB Min Disk Space is the minimum disk space for your tool, e.g., 200 GB","title":"Add Tool"},{"location":"vice/extend_apps/#required-settings","text":"","title":"Required settings"},{"location":"vice/extend_apps/#set-the-workdir","text":"Executable apps to not require a working directory. The container needs to have a set working directory (for interactive apps), typically this is the home folder, e.g., /home/jovyan or /home/rstudio . Set the WORKDIR in the Dockerfile; if there is no set WORKDIR , you can set it in the Tool Builder. Your Data in Your Container We recommend that you set the working directory of your tool to the username home path in a new folder called work , e.g., /home/jovyan/work or /home/rstudio/work . This is because the Discovery Environment's interactive apps use a Kubernetes container storage interface (CSI) driver that connects the CyVerse Data Store to your working directory in the running container. This new mount can clobber any pre-existing files in the the container's WORKDIR .","title":"Set the WORKDIR"},{"location":"vice/extend_apps/#set-the-entrypoint","text":"The container must have an ENTRYPOINT set in the Dockerfile, otherwise you must set it in the Tool itself. All commonly needed dependencies are installed in the container image - you will not have root privileges later. The default user set. Disable any additional authentication (CyVerse provides CAS authentication and authorization). URLs will work sanely behind a reverse proxy. If they don't, you may need to add nginx to the container.","title":"Set the ENTRYPOINT"},{"location":"vice/extend_apps/#set-the-port","text":"Interactive Apps rely on open ports to send display information to the browser. Ensure the listen port for the web UI has a sane default and is set in the Dockerfile, e.g. PORT 8888 . You must set the port in the tool to the external port that the container is listening. Understanding ports in Docker containers For interactive containers like RStudio and JupyterLab, a conventional docker run execution will have the port set as -p 8888:8888 where the port number on the left side of the : is the external port, and on the right the internal port. For VICE apps you need only be concerned about the external port number. Using a reverse proxy The Discovery Environment has its own authentication system, which requires us to use a reverse proxy for some containers. Our RStudio Server uses nginx to enable reverse proxy and thus we have changed the external port to 80 instead of the Rocker-Project default 8787 port number. Managing ports in your new tool Featured VICE apps have default port options based on the app: JupyterLab apps use port 8888 , RStudio apps use port 80 , and Shiny apps use port 3838 . It is strongly recommended you do not set the bind to host as true for your added ports when creating a new App.","title":"Set the PORT"},{"location":"vice/extend_apps/#creating-a-vice-app-for-your-new-tool","text":"After your tool template has been saved, you can create an App for connecting your tool to the Discovery Environment. You can copy an existing app and select your tool if you like an existing App's layout. Alternatively, you can create a new app from a blank template. Input data For VICE apps, be sure to check the box \"Do not pass this argument to the command line\" for each option you add (for VICE, this is usually just input files and folders.","title":"Creating a VICE app for your new tool"},{"location":"vice/quick-cloudshell/","text":"Cloud Shell in 6 Steps \u00b6 1. Log into the Discovery Environment \u00b6 Log into https://de.cyverse.org If you have not yet created an account, go to the User Portal and sign up. 2. Launch the App \u00b6 The Cloud Shell icon is found in the left-side navigation bar in the Discovery Environment. Click on the Apps grid icon Cloud Shell is listed at the top of \"Featured Apps\". Instant Launches start Apps immediately when clicked. The conventional launch menu allows you to modify the App parameters. You can add input data, increase the amount of RAM or CPU cores, and change the analysis directory. 3. Open the Analysis \u00b6 After you have started a VICE app, a new tab will automatically open in your browser and show the app's loading screen. Once the app is ready, it will transition to the user interface (in this example, a Linux terminal). You should see a \"message of the day\", information about the machine you're using, and your CyVerse username for when you initiate an iCommands connection. Note Normal wait time for a featured VICE app to launch is less than 2 minutes. If you're experiencing a significantly longer wait, consider terminating the Analysis and starting a new one. 4. Activate a conda environment \u00b6 The Cloud Shell comes with multiple languages and package managers pre-installed. These include go , python , and rust . Package managers include conda and cargo , in addition to linux apt and apt-get . Your identity inside the container is user and you have limited sudo privileges to install new packages into the container. These changes are not saved after the analyses ends, or when you start a new Cloud Shell Analysis later. Note The Cloud Shell is running a terminal multiplexer called tmux which keeps your session active even after you've closed your browser tab. tmux key bindings are active One side effect of using tmux is that you cannot scroll up in the Terminal to see previous outputs. This can make it difficult to view long outputs. If your output doesn't fit on the screen and you still want to see the whole thing, you can pipe the results of the command into pager . For instance, if you run head big_file.csv -n 100 to view the first 100 lines of a CSV, it probably won't all fit on screen. If you run head big_file.csv -n 100 | pager , you will be able to move through the entire output. In the pager , you use the J key to scroll down, the K key to scroll up, and the Q key to exit. To activate conda: conda init and then: conda activate base If you receive a message about refreshing your screen, you can exit the Cloud Shell by typing \"exit\" and then clicking the refresh button on your browser tab. 5. Using icommands \u00b6 To connect to the CyVerse Data Store, you can initiate an iRODS iCommands iinit . You should now be connected to your /iplant/home/username home directory. ils \u00b6 ils /iplant/home/username/ To view the 'shared' directory, type: ils /iplant/home/shared iget \u00b6 Download data into your Cloud Shell with iCommands by running iget : iget -KPbvrf /iplant/home/shared/cyverse_training/ iput \u00b6 After you finish your analyses, you can save the outputs to Data Store. Use iput to copy your new files back to your user space, or if you've left your new work in the /home/user/work/data/outputs folder, it will be copied back to your /iplant/home/username/Analyses/ directory. To find the outputs you generated (if any), use the same steps as before, but this time select the 'Go To Output Folder'. 6. Terminate your app \u00b6 The Discovery Environment is a shared system. In fairness to the community, users should \"Terminate\" any apps that are no longer actively running analyses. In the Analyses window, select the app (by clicking the checkbox next to it), select \"More Actions\", and then \"Terminate\" to shut down the app. Any new data in the /home/user/work/data/output directory will begin copying back to your folder at this time. Any input data which you added when the app started using the conventional launch feature will not be copied. Warning VICE apps run for a pre-determined amount of time, typically between 4 and 48 hours. If you have opted for email notifications from DE, you'll get a notification 1 day before and another 1 hour before the app gets terminated. To extend the time, go to your analysis, then click the hour glass icon which automatically extends the app run time.","title":"Cloud Shell in 6 steps"},{"location":"vice/quick-cloudshell/#cloud-shell-in-6-steps","text":"","title":"Cloud Shell in 6 Steps"},{"location":"vice/quick-cloudshell/#1-log-into-the-discovery-environment","text":"Log into https://de.cyverse.org If you have not yet created an account, go to the User Portal and sign up.","title":"1. Log into the Discovery Environment"},{"location":"vice/quick-cloudshell/#2-launch-the-app","text":"The Cloud Shell icon is found in the left-side navigation bar in the Discovery Environment. Click on the Apps grid icon Cloud Shell is listed at the top of \"Featured Apps\". Instant Launches start Apps immediately when clicked. The conventional launch menu allows you to modify the App parameters. You can add input data, increase the amount of RAM or CPU cores, and change the analysis directory.","title":"2. Launch the App"},{"location":"vice/quick-cloudshell/#3-open-the-analysis","text":"After you have started a VICE app, a new tab will automatically open in your browser and show the app's loading screen. Once the app is ready, it will transition to the user interface (in this example, a Linux terminal). You should see a \"message of the day\", information about the machine you're using, and your CyVerse username for when you initiate an iCommands connection. Note Normal wait time for a featured VICE app to launch is less than 2 minutes. If you're experiencing a significantly longer wait, consider terminating the Analysis and starting a new one.","title":"3. Open the Analysis"},{"location":"vice/quick-cloudshell/#4-activate-a-conda-environment","text":"The Cloud Shell comes with multiple languages and package managers pre-installed. These include go , python , and rust . Package managers include conda and cargo , in addition to linux apt and apt-get . Your identity inside the container is user and you have limited sudo privileges to install new packages into the container. These changes are not saved after the analyses ends, or when you start a new Cloud Shell Analysis later. Note The Cloud Shell is running a terminal multiplexer called tmux which keeps your session active even after you've closed your browser tab. tmux key bindings are active One side effect of using tmux is that you cannot scroll up in the Terminal to see previous outputs. This can make it difficult to view long outputs. If your output doesn't fit on the screen and you still want to see the whole thing, you can pipe the results of the command into pager . For instance, if you run head big_file.csv -n 100 to view the first 100 lines of a CSV, it probably won't all fit on screen. If you run head big_file.csv -n 100 | pager , you will be able to move through the entire output. In the pager , you use the J key to scroll down, the K key to scroll up, and the Q key to exit. To activate conda: conda init and then: conda activate base If you receive a message about refreshing your screen, you can exit the Cloud Shell by typing \"exit\" and then clicking the refresh button on your browser tab.","title":"4. Activate a conda environment"},{"location":"vice/quick-cloudshell/#5-using-icommands","text":"To connect to the CyVerse Data Store, you can initiate an iRODS iCommands iinit . You should now be connected to your /iplant/home/username home directory.","title":"5. Using icommands"},{"location":"vice/quick-cloudshell/#ils","text":"ils /iplant/home/username/ To view the 'shared' directory, type: ils /iplant/home/shared","title":"ils"},{"location":"vice/quick-cloudshell/#iget","text":"Download data into your Cloud Shell with iCommands by running iget : iget -KPbvrf /iplant/home/shared/cyverse_training/","title":"iget"},{"location":"vice/quick-cloudshell/#iput","text":"After you finish your analyses, you can save the outputs to Data Store. Use iput to copy your new files back to your user space, or if you've left your new work in the /home/user/work/data/outputs folder, it will be copied back to your /iplant/home/username/Analyses/ directory. To find the outputs you generated (if any), use the same steps as before, but this time select the 'Go To Output Folder'.","title":"iput"},{"location":"vice/quick-cloudshell/#6-terminate-your-app","text":"The Discovery Environment is a shared system. In fairness to the community, users should \"Terminate\" any apps that are no longer actively running analyses. In the Analyses window, select the app (by clicking the checkbox next to it), select \"More Actions\", and then \"Terminate\" to shut down the app. Any new data in the /home/user/work/data/output directory will begin copying back to your folder at this time. Any input data which you added when the app started using the conventional launch feature will not be copied. Warning VICE apps run for a pre-determined amount of time, typically between 4 and 48 hours. If you have opted for email notifications from DE, you'll get a notification 1 day before and another 1 hour before the app gets terminated. To extend the time, go to your analysis, then click the hour glass icon which automatically extends the app run time.","title":"6. Terminate your app"},{"location":"vice/quick-jupyter/","text":"JupyterLab in 6 Steps \u00b6 1. Log into Discovery Environment \u00b6 Log into https://de.cyverse.org . If you have not yet created an account, go to the User Portal to sign up. 2. Launch the App \u00b6 Click on the Apps grid icon. Jupyter Lab Datascience is in \"Featured Apps\". Instant Launches start Apps immediately when clicked. The conventional launch menu allows you to modify the App parameters. You can add input data, increase the amount of RAM or CPU cores, and change the analysis directory. 3. Open the Analysis \u00b6 After you have started a VICE app, a new tab will automatically open in your browser and take you to the loading screen. Once the app is ready, it will transition to the user interface. The Jupyter Lab Interface: While Jupyter Lab has many features found in traditional integrated development environments (IDEs), it remains focused on interactive, exploratory computing. The Jupyter Lab interface consists of a main work area containing tabs of documents and activities, a collapsible left sidebar, and a menu bar. The left sidebar contains a file browser, the list of running kernels and terminals, the command palette, the notebook cell tools inspector, and the tabs list. More information about the Jupyter Lab can be found here . Note Normal wait time for a featured VICE App to launch is less than 2 minutes. If you're experiencing a significantly longer wait, consider terminating the Analysis and starting a new one. 4. Create a new conda environment \u00b6 From Jupyter's Launch menu, select the black Terminal console icon. This will take you to a command line shell. Change directory, or download a sample environment.yml file: $ cd /home/jovyan/work/home/shared/cyverse_training/platform_guide/discovery_environment/jupyter/ $ conda create env -f environment.yml or $ curl https://data.cyverse.org/dav-anon/iplant/commons/community_released/cyverse_training/platform_guides/discovery_environment/jupyterlab/environment.yml $ conda create env -f environment.yml and then: $ conda activate python39 5. Create Jupyter notebook \u00b6 Jupyter notebooks ( .ipynb ) combine code with narrative text (Markdown), equations (LaTeX), images and interactive visualizations. To create a notebook, click the + button which opens the new Launcher tab. The JupyterLab Datascience containers have three pre-installed kernels: Python3, Julia, and R. Official Jupyter Notebooks To open the classic Notebook view from JupyterLab, select \"Launch Classic Notebook\" from the Help Menu. 6. Terminate your app \u00b6 The Discovery Environment is a shared system. In fairness to the community, users should \"Terminate\" any apps that are no longer actively running analyses. In the Analyses window, select the app (by clicking the checkbox next to it), select \"More Actions\", then \"Terminate\" to shut down the app. Any new data in the /home/jovyan/work/data/outputs directory will begin copying back to your folder at this time. Any input data which you added when the app started using the conventional launch feature will not be copied. Warning VICE apps run for a pre-determined amount of time, typically between 4 and 48 hours. If you have opted for email notifications from DE, then you'll get a notification 1 day before and another 1 hour before the app gets terminated. To extend the time, go to your analysis and click the hour glass icon which automatically extends the app run time.","title":"JupyterLab in 6 steps"},{"location":"vice/quick-jupyter/#jupyterlab-in-6-steps","text":"","title":"JupyterLab in 6 Steps"},{"location":"vice/quick-jupyter/#1-log-into-discovery-environment","text":"Log into https://de.cyverse.org . If you have not yet created an account, go to the User Portal to sign up.","title":"1. Log into Discovery Environment"},{"location":"vice/quick-jupyter/#2-launch-the-app","text":"Click on the Apps grid icon. Jupyter Lab Datascience is in \"Featured Apps\". Instant Launches start Apps immediately when clicked. The conventional launch menu allows you to modify the App parameters. You can add input data, increase the amount of RAM or CPU cores, and change the analysis directory.","title":"2. Launch the App"},{"location":"vice/quick-jupyter/#3-open-the-analysis","text":"After you have started a VICE app, a new tab will automatically open in your browser and take you to the loading screen. Once the app is ready, it will transition to the user interface. The Jupyter Lab Interface: While Jupyter Lab has many features found in traditional integrated development environments (IDEs), it remains focused on interactive, exploratory computing. The Jupyter Lab interface consists of a main work area containing tabs of documents and activities, a collapsible left sidebar, and a menu bar. The left sidebar contains a file browser, the list of running kernels and terminals, the command palette, the notebook cell tools inspector, and the tabs list. More information about the Jupyter Lab can be found here . Note Normal wait time for a featured VICE App to launch is less than 2 minutes. If you're experiencing a significantly longer wait, consider terminating the Analysis and starting a new one.","title":"3. Open the Analysis"},{"location":"vice/quick-jupyter/#4-create-a-new-conda-environment","text":"From Jupyter's Launch menu, select the black Terminal console icon. This will take you to a command line shell. Change directory, or download a sample environment.yml file: $ cd /home/jovyan/work/home/shared/cyverse_training/platform_guide/discovery_environment/jupyter/ $ conda create env -f environment.yml or $ curl https://data.cyverse.org/dav-anon/iplant/commons/community_released/cyverse_training/platform_guides/discovery_environment/jupyterlab/environment.yml $ conda create env -f environment.yml and then: $ conda activate python39","title":"4. Create a new conda environment"},{"location":"vice/quick-jupyter/#5-create-jupyter-notebook","text":"Jupyter notebooks ( .ipynb ) combine code with narrative text (Markdown), equations (LaTeX), images and interactive visualizations. To create a notebook, click the + button which opens the new Launcher tab. The JupyterLab Datascience containers have three pre-installed kernels: Python3, Julia, and R. Official Jupyter Notebooks To open the classic Notebook view from JupyterLab, select \"Launch Classic Notebook\" from the Help Menu.","title":"5. Create Jupyter notebook"},{"location":"vice/quick-jupyter/#6-terminate-your-app","text":"The Discovery Environment is a shared system. In fairness to the community, users should \"Terminate\" any apps that are no longer actively running analyses. In the Analyses window, select the app (by clicking the checkbox next to it), select \"More Actions\", then \"Terminate\" to shut down the app. Any new data in the /home/jovyan/work/data/outputs directory will begin copying back to your folder at this time. Any input data which you added when the app started using the conventional launch feature will not be copied. Warning VICE apps run for a pre-determined amount of time, typically between 4 and 48 hours. If you have opted for email notifications from DE, then you'll get a notification 1 day before and another 1 hour before the app gets terminated. To extend the time, go to your analysis and click the hour glass icon which automatically extends the app run time.","title":"6. Terminate your app"},{"location":"vice/quick-rstudio/","text":"RStudio in 6 Steps \u00b6 1. Log into Discovery Environment \u00b6 Log into https://de.cyverse.org If you have not yet created an account, go to the User Portal and sign up. 2. Launch the App \u00b6 Click on the Apps grid icon RStudio Verse is in \"Featured Apps\". Instant Launches start Apps immediately when clicked. The conventional launch menu allows you to modify the App parameters. You can add input data, increase the amount of RAM or CPU cores, and change the analysis directory. 3. Open the Analysis \u00b6 After you have started a VICE app, a new tab will automatically open in your browser and take you to the loading screen. Once the app is ready, it will transition to the user interface. RStudio Interface: RStudio is a free, open source IDE (integrated development environment) for R. Its interface is organized so that the user can clearly view graphs, data tables, R code and ouput at the same time. It also offers an Import-Wizard-like feature that allows users to import CSV, Excel, SAS ( .sas7bdat), SPSS ( .sav), and Stata (*.dta) files into R without having to write the code to do so. More information about RStudio can be found here . Note Normal wait time for a featured VICE app to launch is less than 2 minutes. If you're experiencing a significantly longer wait, consider terminating the Analysis and starting a new one. 4. Create an RStudio Project \u00b6 You can create RStudio projects using local data, or from Git. This example uses Leaflet Maps in RStudio. You can then run R commands and install packages. 5. Using icommands \u00b6 Open RStudio's Terminal. To connect to the CyVerse Data Store, you can initiate an iRODS iCommands iinit . You should now be connected to your /iplant/home/username home directory. ils \u00b6 ils /iplant/home/username/ To view the 'shared' directory, type: ils /iplant/home/shared iget \u00b6 Download data into your Cloud Shell with iCommands by running iget . iget -KPbvrf /iplant/home/shared/cyverse_training/ iput \u00b6 After finishing your analyses, you can save the outputs back to your Data Store. Use iput to copy your new files back to your user space, or if you've left your new work in the /home/user/work/data/outputs folder, it will be copied back to your /iplant/home/username/Analyses/ directory. You can find the outputs you generated (if any) using the same steps as before, but this time select the 'Go To Output Folder'. 6. Terminate your app \u00b6 The Discovery Environment is a shared system. In fairness to the community, users should \"Terminate\" any apps that are no longer actively running analyses. In the Analyses window, select the app (by clicking the checkbox next to it), then select \"More Actions\", then \"Terminate\" to shut down the app. Any new data in the /home/rstudio/work/data/output directory will begin copying back to your folder at this time. Any input data which you added when the app started using the conventional launch feature will not be copied. Warning VICE apps run for a pre-determined amount of time, typically between 4 and 48 hours. If you have opted for email notifications from the DE, then you'll get a notification 1 day before and another 1 hour before the app will terminate. To extend the pre-set run time, go to your analysis and click the hour glass icon which automatically extends the app run time.","title":"RStudio in 6 steps"},{"location":"vice/quick-rstudio/#rstudio-in-6-steps","text":"","title":"RStudio in 6 Steps"},{"location":"vice/quick-rstudio/#1-log-into-discovery-environment","text":"Log into https://de.cyverse.org If you have not yet created an account, go to the User Portal and sign up.","title":"1. Log into Discovery Environment"},{"location":"vice/quick-rstudio/#2-launch-the-app","text":"Click on the Apps grid icon RStudio Verse is in \"Featured Apps\". Instant Launches start Apps immediately when clicked. The conventional launch menu allows you to modify the App parameters. You can add input data, increase the amount of RAM or CPU cores, and change the analysis directory.","title":"2. Launch the App"},{"location":"vice/quick-rstudio/#3-open-the-analysis","text":"After you have started a VICE app, a new tab will automatically open in your browser and take you to the loading screen. Once the app is ready, it will transition to the user interface. RStudio Interface: RStudio is a free, open source IDE (integrated development environment) for R. Its interface is organized so that the user can clearly view graphs, data tables, R code and ouput at the same time. It also offers an Import-Wizard-like feature that allows users to import CSV, Excel, SAS ( .sas7bdat), SPSS ( .sav), and Stata (*.dta) files into R without having to write the code to do so. More information about RStudio can be found here . Note Normal wait time for a featured VICE app to launch is less than 2 minutes. If you're experiencing a significantly longer wait, consider terminating the Analysis and starting a new one.","title":"3. Open the Analysis"},{"location":"vice/quick-rstudio/#4-create-an-rstudio-project","text":"You can create RStudio projects using local data, or from Git. This example uses Leaflet Maps in RStudio. You can then run R commands and install packages.","title":"4. Create an RStudio Project"},{"location":"vice/quick-rstudio/#5-using-icommands","text":"Open RStudio's Terminal. To connect to the CyVerse Data Store, you can initiate an iRODS iCommands iinit . You should now be connected to your /iplant/home/username home directory.","title":"5. Using icommands"},{"location":"vice/quick-rstudio/#ils","text":"ils /iplant/home/username/ To view the 'shared' directory, type: ils /iplant/home/shared","title":"ils"},{"location":"vice/quick-rstudio/#iget","text":"Download data into your Cloud Shell with iCommands by running iget . iget -KPbvrf /iplant/home/shared/cyverse_training/","title":"iget"},{"location":"vice/quick-rstudio/#iput","text":"After finishing your analyses, you can save the outputs back to your Data Store. Use iput to copy your new files back to your user space, or if you've left your new work in the /home/user/work/data/outputs folder, it will be copied back to your /iplant/home/username/Analyses/ directory. You can find the outputs you generated (if any) using the same steps as before, but this time select the 'Go To Output Folder'.","title":"iput"},{"location":"vice/quick-rstudio/#6-terminate-your-app","text":"The Discovery Environment is a shared system. In fairness to the community, users should \"Terminate\" any apps that are no longer actively running analyses. In the Analyses window, select the app (by clicking the checkbox next to it), then select \"More Actions\", then \"Terminate\" to shut down the app. Any new data in the /home/rstudio/work/data/output directory will begin copying back to your folder at this time. Any input data which you added when the app started using the conventional launch feature will not be copied. Warning VICE apps run for a pre-determined amount of time, typically between 4 and 48 hours. If you have opted for email notifications from the DE, then you'll get a notification 1 day before and another 1 hour before the app will terminate. To extend the pre-set run time, go to your analysis and click the hour glass icon which automatically extends the app run time.","title":"6. Terminate your app"},{"location":"vice/teaching/","text":"Teach using CyVerse \u00b6 Workshops and Courses \u00b6 The User Portal provides a mechanism for rapidly onboarding entire workshops or class courses, by granting your students immediate access to CyVerse platforms and services. Start by completing the CyVerse Resources for Training Request Form here and you will be able to enroll your entire course with access to CyVerse in a few minutes. Avoid conflicts with Maintenance days! When scheduling your workshop or class, note that CyVerse conducts regular maintenance of its platforms typically on the first Tuesday of the month, with most services unavailabe during that time. Select your services \u00b6 In the workshop form, choose which services you want to use for your teaching. Enrollees will then have access to those services without needing to request them. Common platforms are: Data Store (data management), Discovery Environment (analyses), VICE (integrated environments and visualization), DNA Subway (genomics), Atmosphere (cloud computing), BisQue (image analysis), and CoGe (comparative genomics). Select your Host, Instructor(s) / Organizer(s) \u00b6 You can make other CyVerse users Instructors or Organizers of your workshop; these users will have administrative rights to modify the workshop template and to add and approve student/attendee accounts. Enroll your participants \u00b6 In the workshop builder, you can enroll existing CyVerse users by using their first/lastname or email address or username. You can pre-enroll new email addresses as well. We recommend using .edu, .gov, or .org email addresses. Students can also use the URL for the workshop/class to enroll themselves. Anyone who self-enrolls subsequently must be approved by the Workshop/Class Admin or Instructor. Create documentation \u00b6 The CyVerse Learning Center provides templates for creating documentation for your class, e.g., Quick Starts, Guides, Tutorials, and Manuals on its GitHub Organization .","title":"Teach using CyVerse"},{"location":"vice/teaching/#teach-using-cyverse","text":"","title":"Teach using CyVerse"},{"location":"vice/teaching/#workshops-and-courses","text":"The User Portal provides a mechanism for rapidly onboarding entire workshops or class courses, by granting your students immediate access to CyVerse platforms and services. Start by completing the CyVerse Resources for Training Request Form here and you will be able to enroll your entire course with access to CyVerse in a few minutes. Avoid conflicts with Maintenance days! When scheduling your workshop or class, note that CyVerse conducts regular maintenance of its platforms typically on the first Tuesday of the month, with most services unavailabe during that time.","title":"Workshops and Courses"},{"location":"vice/teaching/#select-your-services","text":"In the workshop form, choose which services you want to use for your teaching. Enrollees will then have access to those services without needing to request them. Common platforms are: Data Store (data management), Discovery Environment (analyses), VICE (integrated environments and visualization), DNA Subway (genomics), Atmosphere (cloud computing), BisQue (image analysis), and CoGe (comparative genomics).","title":"Select your services"},{"location":"vice/teaching/#select-your-host-instructors-organizers","text":"You can make other CyVerse users Instructors or Organizers of your workshop; these users will have administrative rights to modify the workshop template and to add and approve student/attendee accounts.","title":"Select your Host, Instructor(s) / Organizer(s)"},{"location":"vice/teaching/#enroll-your-participants","text":"In the workshop builder, you can enroll existing CyVerse users by using their first/lastname or email address or username. You can pre-enroll new email addresses as well. We recommend using .edu, .gov, or .org email addresses. Students can also use the URL for the workshop/class to enroll themselves. Anyone who self-enrolls subsequently must be approved by the Workshop/Class Admin or Instructor.","title":"Enroll your participants"},{"location":"vice/teaching/#create-documentation","text":"The CyVerse Learning Center provides templates for creating documentation for your class, e.g., Quick Starts, Guides, Tutorials, and Manuals on its GitHub Organization .","title":"Create documentation"},{"location":"workshops/","text":"Current Offerings \u00b6 CyVerse's popular in-person and virtual trainings are intensive, providing hands-on learning and application of cutting edge, open source technologies. Come with questions, leave with solutions. Professional Education Series \u00b6 Workshop Info & Reg What's Covered Container Camp Basics Website Syllabus Advanced Container Camp Website Syllabus Foundational Open Science Skills workshops Website Syllabus Teach your Workshops on our resources \u00b6 Cyverse also helps facilitate external workshops through the User Portal Request a Workshop sign-up form be here You can request a workshop that uses specific CyVerse platforms like the Data Store, the Discovery Environment, or CACAO and Jetstream-2. By using the form, your students will be automatically granted access to these platforms when they enroll. Read more detailed instructions on setting up a class or workshop . Questions? Email us !","title":"Current Offerings"},{"location":"workshops/#current-offerings","text":"CyVerse's popular in-person and virtual trainings are intensive, providing hands-on learning and application of cutting edge, open source technologies. Come with questions, leave with solutions.","title":"Current Offerings"},{"location":"workshops/#professional-education-series","text":"Workshop Info & Reg What's Covered Container Camp Basics Website Syllabus Advanced Container Camp Website Syllabus Foundational Open Science Skills workshops Website Syllabus","title":"Professional Education Series"},{"location":"workshops/#teach-your-workshops-on-our-resources","text":"Cyverse also helps facilitate external workshops through the User Portal Request a Workshop sign-up form be here You can request a workshop that uses specific CyVerse platforms like the Data Store, the Discovery Environment, or CACAO and Jetstream-2. By using the form, your students will be automatically granted access to these platforms when they enroll. Read more detailed instructions on setting up a class or workshop . Questions? Email us !","title":"Teach your Workshops on our resources"},{"location":"workshops/container_camp/","text":"Container Camp \u00b6 CyVerse teaches in-person and virtual workshops on the use of software containers for scientific research. Currently, we teach both a 'beginning' and 'advanced' format for new and advanced users. Introductory camps are offered prior to advanced camps to allow users to level up or refresh their container skills. View the schedule and sign up for the next camp here: Container Camp Announcements Name Dates Description Container Camp 2021 Advanced Aug 2-4, 2021 Virtual Camp Container Camp 2021 Basics July 26-28, 2021 Virtual Camp Container Camp 2020 Mar 10-13, 2020 Third camp, in person at UArizona Container Camp 2019 Mar 6-8 2019 Second camp, in person at UArizona Container Camp 2018 Mar 7-9, 2018 First camp, in person at UArizona","title":"Container Camp"},{"location":"workshops/container_camp/#container-camp","text":"CyVerse teaches in-person and virtual workshops on the use of software containers for scientific research. Currently, we teach both a 'beginning' and 'advanced' format for new and advanced users. Introductory camps are offered prior to advanced camps to allow users to level up or refresh their container skills. View the schedule and sign up for the next camp here: Container Camp Announcements Name Dates Description Container Camp 2021 Advanced Aug 2-4, 2021 Virtual Camp Container Camp 2021 Basics July 26-28, 2021 Virtual Camp Container Camp 2020 Mar 10-13, 2020 Third camp, in person at UArizona Container Camp 2019 Mar 6-8 2019 Second camp, in person at UArizona Container Camp 2018 Mar 7-9, 2018 First camp, in person at UArizona","title":"Container Camp"},{"location":"workshops/foss/","text":"Foundational Open Science Skills \u00b6 CyVerse's 10-week virtual workshop teaches you the principles, practices, and how-tos for doing collaborative open science using cutting-edge, open source cyberinfrastructure. To see how our FOSS workshop can support your work, check out the workshop curriculum: Name Dates Description Fall FOSS 2021 Sep 7 - Nov 18, 2021 Third virtual workshop series Spring FOSS 2021 Feb 9 - Apr 21, 2021 Second virtual workshop series Summer FOSS 2020 July 28 - Nov 3, 2020 First virtual workshop series Spring FOSS 2020 Feb 17 - 21, 2020 Second in-person workshop at UArizona Spring FOSS 2019 Jun 3-7, 2019 First in-person workshop at UArizona","title":"Foundational Open Science Skills"},{"location":"workshops/foss/#foundational-open-science-skills","text":"CyVerse's 10-week virtual workshop teaches you the principles, practices, and how-tos for doing collaborative open science using cutting-edge, open source cyberinfrastructure. To see how our FOSS workshop can support your work, check out the workshop curriculum: Name Dates Description Fall FOSS 2021 Sep 7 - Nov 18, 2021 Third virtual workshop series Spring FOSS 2021 Feb 9 - Apr 21, 2021 Second virtual workshop series Summer FOSS 2020 July 28 - Nov 3, 2020 First virtual workshop series Spring FOSS 2020 Feb 17 - 21, 2020 Second in-person workshop at UArizona Spring FOSS 2019 Jun 3-7, 2019 First in-person workshop at UArizona","title":"Foundational Open Science Skills"}]}